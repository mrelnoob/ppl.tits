########################## *--------------------------------------------------* ########################
########################## Inferential modelling for all tit nestlings (ntits)  ########################
########################## *--------------------------------------------------* ########################

# The functions of this R file are meant to wrap all formal inference modelling related to both species
# together, as opposed to per-species models, "preparation modelling" (cf. previous scripts) and
# "exploratory modelling" that will perhaps be made afterwards; i.e. after we have formally tested our
# research hypotheses in a robust inferential framework. The so-called "exploratory modelling" is related
# to additional questions and perspectives that will have, by nature, far less support as the data have
# already been used for formal testing (so type-I error rates cannot be guaranteed anymore)!

# For now, this script should be run after having sourced the EDA script (because no function yet)!!!





# -------------------------------- #
##### 1. Modelling clutch size #####
# -------------------------------- #

##### * 1.1. Clutch size: COM-Poisson GLMM -------------------------------------
# ---------------------------------------------------------------------------- #
### ** 1.1.1. Initial model fit ----
# __________________________________

## Fitting a regular Poisson regression:
ttCy_glm1 <- stats::glm(clutch_size ~ logged_woodyveg + logged_Fmetric + species +
                          urban_intensity + manag_low + manag_high + light_pollution + noise_m +
                          cumdd_30 + year,
                        data = ntits2, family = "poisson")

## Fitting a regular Poisson GLMM:
ttCy_glmm1 <- glmmTMB::glmmTMB(clutch_size ~ logged_woodyveg + logged_Fmetric + species +
                                     urban_intensity + manag_low + manag_high + light_pollution + noise_m +
                                     cumdd_30 + year + (1|id_nestbox),
                                   data = ntits2, family = "poisson")

## Fitting a regular Conway-Maxwell (COM) Poisson regression (GLM):
ttCy_comglm1 <- glmmTMB::glmmTMB(clutch_size ~ logged_woodyveg + logged_Fmetric + species +
                                          urban_intensity + manag_low + manag_high + light_pollution + noise_m +
                                          cumdd_30 + year,
                                        data = ntits2, family = glmmTMB::compois(link = "log"),
                                        dispformula = ~1) # Intercept only 'nu' (default).
# OR:
ttCy_comglm1b <- COMPoissonReg::glm.cmp(formula.lambda =
                                       clutch_size ~ logged_woodyveg + logged_Fmetric + species +
                                       urban_intensity + manag_low + manag_high + light_pollution + noise_m +
                                       cumdd_30 + year,
                                     data = ntits2, formula.nu = ~1) # Intercept only 'nu' (default).

## Fitting a regular Conway-Maxwell (COM) Poisson mixed model (GLMM):
ttCy_comglmm1 <- glmmTMB::glmmTMB(clutch_size ~ logged_woodyveg + logged_Fmetric + species +
                                   urban_intensity + manag_low + manag_high + light_pollution + noise_m +
                                   cumdd_30 + year + (1|id_nestbox),
                                 data = ntits2, family = glmmTMB::compois(link = "log"),
                                 dispformula = ~1) # Rather long to fit.
summary(ttCy_glm1) # AIC = 1758.2
summary(ttCy_glmm1) # AIC = 1760.2
summary(ttCy_comglm1) # AIC = 1624.7
summary(ttCy_comglm1b) # AIC = 1624.5 (so it's not exactly the same?!).
summary(ttCy_comglmm1) # AIC = 1626.7.
# It seems that, if the inclusion of a random effect (RE) did not improve the fit, but accounting for a
# likely underdispersion quite strongly improved the fit! I will thus carry on with the last model to the
# diagnostic part and assess whether the use of the RE is truly justified or not and if the model behaves
# as expected.
# UPDATE: diagnostics ran for 'ttCy_comglmm1' (initial model) indicated that the model fit the data
# relatively well although several modelling assumptions were slightly violated. They also confirmed that
# the RE were not truly useful for this model. Importantly, diagnostics showed that the model was slightly
# off likely because there was true outliers in the data as the very low clutch sizes observed were probably
# generated by another process. Consequently, in a second step, we removed them and explored a few
# reasonable variations of the same model by trying different proxies of the same variable ("noise_iq"
# instead of "noise_m"; "Fmetric_d2b1" instead of "Fmetric_d2b0"; and "woody_area" instead of "woodyveg_vw"),
# using "site" as RE, and slightly tuning the (nu) dispersion model (see below).
# I also tried interaction models, but interaction effects were not significant.

# Below, code and comments will show the diagnostics of one or several of these improved models, but you
# can re-run the diagnostics for the initial model by replacing the model name in the code chunks and to
# change ntits3 by ntits2 (i.e. the dataset with the deleted outliers).





### ** 1.1.2. Improved model (exploration) ----
# _____________________________________________

## To remove probable outliers (see 'ttCy_comglmm1' diagnostics):
ntits3 <- ntits2[-c(156,170,181,210,227,314,362,367),]

## Replacement of the beta0 "F-metric" (by the beta1 version):
ttCy_comglmm1b <- glmmTMB::glmmTMB(clutch_size ~ logged_woodyveg + logged_Fmetric_d2b1 + species +
                                     urban_intensity + manag_low + manag_high + light_pollution + noise_iq +
                                     cumdd_30 + year + (1|site),
                                   data = ntits3, family = glmmTMB::compois(link = "log"),
                                   dispformula = ~1)
## Addition of an improved dispersion model:
ttCy_comglmm1c <- glmmTMB::glmmTMB(clutch_size ~ logged_woodyveg + logged_Fmetric_d2b1 + species +
                                     urban_intensity + manag_low + manag_high + light_pollution + noise_iq +
                                     cumdd_30 + year + (1|site),
                                   data = ntits3, family = glmmTMB::compois(link = "log"),
                                   dispformula = ~cumdd_30+min_t_before) # Rather long to fit.
## Replacement of the woody vegetation volume (by its area):
ttCy_comglmm1d <- glmmTMB::glmmTMB(clutch_size ~ logged_woody_area + logged_Fmetric_d2b1 + species +
                                     urban_intensity + manag_low + manag_high + light_pollution + noise_iq +
                                     cumdd_30 + year + (1|site),
                                   data = ntits3, family = glmmTMB::compois(link = "log"),
                                   dispformula = ~cumdd_30+min_t_before) # Rather long to fit.
summary(ttCy_comglmm1b) # AIC = 1391.3.
summary(ttCy_comglmm1c) # AIC = 1390.5.
summary(ttCy_comglmm1d) # AIC = 1388.1.





### ** 1.1.3. Diagnostics and assumption checks ----
# __________________________________________________

### *** 1.1.3.1. Residuals extraction, autocorrelation and collinearity ----
## Traditional residuals:
par(.pardefault)
resid <- stats::resid(ttCy_comglmm1b, type = 'response')
plot(resid, id = 0.05, idLabels = ~.obs) # Ok-ish but there are a few low residuals.
# performance::check_outliers(ttCy_comglmm1b) # Does not work for this type of model.
ntits3[which(resid < -4),] # Lowest residuals are nestboxes with very small clutch sizes.

# To further investigate patterns, I can plot the residuals against some predictors:
plot(x = ntits3$year, y = resid) # Seems rather ok although we once again find patterns linked to the
# sometimes odd distribution of some predictors. However, be reminded that simulated residuals will be
# more useful).
# plot(ttCy_comglmm1b, id_nestbox~stats::resid(.)) # Does not work for this type of model.
# plot(ttCy_comglmm1b, site~stats::resid(.)) # Does not work for this type of model.

## Simulation-based scaled residuals computation ({DHARMa} method):
simu.resid <- DHARMa::simulateResiduals(fittedModel = ttCy_comglmm1b, n = 1000, re.form = NULL) # The
# 're.form' argument is to base simulations on the model unconditional of the random effects (and only works
# for {lme4} formulations). It is useful for testing dispersion (see below) but can be omitted eventually.
plot(simu.resid) # Significant deviations and outliers detected!
DHARMa::outliers(simu.resid) # No potential outliers.
ntits2[c(156,170,181,210,227,314,362,367),] # They have surprisingly low clutch sizes with regards to their
# locations and their adjacent observations. They may well be true outliers (whose clutch sizes are function
# of other processes).

## Autocorrelation and collinearity:
DHARMa::testSpatialAutocorrelation(simulationOutput = simu.resid,
                                   x = ntits3$coord_x, y = ntits3$coord_y, plot = TRUE) # Ok for B, C and D.
performance::check_autocorrelation(ttCy_comglmm1b) # Ok.
performance::check_collinearity(ttCy_comglmm1b) # Ok-ish, but "urban_intensity" and "F" > 3 (for B,C)! For
# the D improved model, VIF > 4 for "woody_area", "urban_intensity" and >5 for the "F-metric"!
  stats::vcov(ttCy_comglmm1b) # But values of the covariance matrix seem ok.

## Heteroscedasticity and possible model misspecifications:
par(.pardefault)
DHARMa::plotResiduals(simu.resid, form = ntits3$logged_woodyveg)
DHARMa::plotResiduals(simu.resid, form = ntits3$logged_Fmetric)
DHARMa::plotResiduals(simu.resid, form = ntits3$urban_intensity)
DHARMa::plotResiduals(simu.resid, form = ntits3$manag_intensity)
DHARMa::plotResiduals(simu.resid, form = ntits3$light_pollution)
DHARMa::plotResiduals(simu.resid, form = ntits3$noise_iq)
DHARMa::plotResiduals(simu.resid, form = ntits3$cumdd_30)
DHARMa::plotResiduals(simu.resid, form = ntits3$species)
DHARMa::plotResiduals(simu.resid, form = ntits3$year)
# All these plots are ok for B, C and D models.



### *** 1.1.3.2. Distribution (family, ZI, dispersion) ----
## Assessing over or under-dispersion:
AER::dispersiontest(object = ttCy_glm1, alternative = c("less")) # Significant underdispersion!
DHARMa::testDispersion(simu.resid, alternative = "less") # Ok.

## Theoretical count distribution:
theo_count <- COMPoissonReg::rcmp(n = nrow(ntits3), lambda = mean(ntits3$clutch_size), nu = 1.1) # The 'nu'
# parameter should be chosen by trial-and-errors.
tc_df <- data.frame(theo_count)

ggplot2::ggplot(ntits3, ggplot2::aes(clutch_size)) +
  ggplot2::geom_bar(fill = "#1E90FF") +
  ggplot2::geom_bar(data = tc_df, ggplot2::aes(theo_count, fill="#1E90FF", alpha=0.5)) +
  ggplot2::theme_classic() +
  ggplot2::theme(legend.position = "none") # Blue = observed counts; red = simulated.
# This plot suggests that clutch_size could be following a COM-Poisson distribution of parameter nu~1.1!

## Distribution of the predicted counts:
pred_counts <- stats::predict(object = ttCy_comglmm1b, type = "response") # Extract the predicted counts.
par(mfrow= c(1,2))
hist(pred_counts, main = "Predicted counts", xlab = "Number of layed eggs")
hist(ntits3$clutch_size, main = "Observed counts", xlab = "Number of layed eggs") # The models' predictions
# are very similar and relatively acceptable (although too narrow).



### *** 1.1.3.3. Linearity ----
# For the sake of further exploration, I also plot variants of our predictors:
ntits3 %>% dplyr::select(woodyveg_vw, woody_area, woodyveg_sd,
                         F_metric_d2b0, F_metric_d1b0, F_metric_d3b0, F_metric_d1b1, F_metric_d2b1,
                         urban_intensity, herbaceous_area, built_area, traffic,
                         light_pollution, noise_m, noise_iq,
                         cumdd_30, min_t_before) %>%
  dplyr::mutate("Fmetric" = F_metric_d2b0,
                "Fmetric (sqrt)" = sqrt(F_metric_d2b0),
                "Fmetric (log)" = log10(F_metric_d2b0),
                "woodyveg_vw" = woodyveg_vw,
                "woodyveg_vw (sqrt)" = sqrt(woodyveg_vw),
                "woodyveg_vw (log)" = log10(woodyveg_vw), .keep = "unused") -> mydata
predictors <- colnames(mydata)
# Bind log(Y) and tidying the data for plot (ggplot2, so long format):
mydata <- mydata %>%
  dplyr::mutate(log_y = log(ntits3$clutch_size)) %>%
  tidyr::gather(key = "predictors", value = "predictor.value", -log_y)
# Create scatterplot
ggplot2::ggplot(mydata, ggplot2::aes(y = log_y, x = predictor.value))+
  ggplot2::geom_point(size = 0.5, alpha = 0.5) +
  ggplot2::geom_smooth(method = "loess") +
  ggplot2::theme_bw() +
  ggplot2::facet_wrap(~predictors, scales = "free_x") # Linearity seems respected.



### *** 1.1.3.4. Model goodness-of-fit (GOF) and performances ----
# GOF test of Pearson's Chi2 residuals:
dat.resid <- sum(stats::resid(ttCy_comglmm1b, type = "pearson")^2)
1 - stats::pchisq(dat.resid, stats::df.residual(ttCy_comglmm1b)) # All p > 0.5, indicating that there is no
# significant lack of fit. Keep in mind though that GOF measures for mixed models is an extremely complicated
# topic and interpretations are not straightforward.

# Computing a pseudo-R2:
performance::r2_nakagawa(ttCy_comglmm1b) # [Additive model]: Marg_R2_glmm = 0.09; Cond_R2_glmm = 0.1.
# Does not work for C and D models because it cannot account for the dispersion model.

## Likelihood-ration tests (LRT) of GOF:
# For the "site" random-effects (RE):
ttCy_comglmm2 <- glmmTMB::glmmTMB(clutch_size ~ logged_woodyveg + logged_Fmetric + species +
                                    urban_intensity + manag_low + manag_high + light_pollution + noise_m +
                                    cumdd_30 + year + (1|id_nestbox) + (1|site),
                                  data = ntits2, family = glmmTMB::compois(link = "log"),
                                  dispformula = ~1) # Rather long to fit (~3-4 min)!
summary(ttCy_comglmm2) # AIC = 1628.7.
# The non-mixed model gives AIC = 1624 so approximatively equal to the mixed-model (AIC = 1626.7) with only
# "id_nestbox" as RE. The mixed model with only "site" as a RE gives AIC = 1626.7. The one with both RE gives
# AIC = 1628.7. So it seems like the use of mixed models is here not supported by the data!

## For the whole model:
ttCy_comglmm0 <- glmmTMB::glmmTMB(clutch_size ~ 1 + (1|id_nestbox),
                                  data = ntits2, family = glmmTMB::compois(link = "log"),
                                  dispformula = ~1)
res.LRT_null <- stats::anova(object = ttCy_comglmm0, ttCy_comglmm1b, test = "LRT")
# The test is significant, confirming that the model is useful to explain the data.



### *** 1.1.3.5. Posterior predictive simulations ----
# Predicted counts:
par(.pardefault)
obsprop <- prop.table(table(ntits3$clutch_size))
sims <- stats::simulate(ttCy_comglmm1b, nsim = 1000)
nsim4 <- colSums(sims == 4) # Number of fours (min obs value)
par(las=4,bty="l")
plot(pt <- prop.table(table(nsim4)),
     ylab="Probability", xlab="Number of fours")
(obs4 <- sum(ntits3$clutch_size == 4))
points(obs4, 0.005, col="red", pch=16, cex=2) # See y values in obsprop

nsim9 <- colSums(sims == 9) # Number of nines (modal obs value).
par(las=1,bty="l")
plot(pt <- prop.table(table(nsim9)),
     ylab="Probability", xlab="Number of nines")
(obs9 <- sum(ntits3$clutch_size == 9))
points(obs9, 0.21, col="red", pch=16, cex=2)

nsim14 <- colSums(sims == 14) # Number of fourteens (max obs value).
par(las=1,bty="l")
plot(pt <- prop.table(table(nsim14)),
     ylab="Probability", xlab="Number of fourteens")
(obs14 <- sum(ntits3$clutch_size == 14))
points(obs14, 0.013, col="red", pch=16, cex=2)
# These three examples confirm that the model still predicts values that are too dispersed compared to the
# true observed values, but it's not that bad.





### ** 1.1.4. Inference and predictions ----
# __________________________________________

##### TO BE RUN §§§ ----

### *** 1.1.4.1. Hypotheses testing: LRT for the additive and interactive effect of the F-metric ----
## Parametric bootstrap to test the additive effect of the connectivity metric:
ttCy_comglmm0 <- stats::update(ttCy_comglmm1, .~. -logged_Fmetric)
ttCy_comglmm0b <- stats::update(ttCy_comglmm1b, .~. -logged_Fmetric_d2b1)
ttCy_comglmm0c <- stats::update(ttCy_comglmm1c, .~. -logged_Fmetric_d2b1)
ttCy_comglmm0d <- stats::update(ttCy_comglmm1d, .~. -logged_Fmetric_d2b1)
summary(ttCy_comglmm0)$AIC # AIC = 1624.8 vs 1626.6 (hypothesis likely not validated)!
summary(ttCy_comglmm0b)$AIC # AIC = 1392 vs 1391.3 (hypothesis likely not validated)!
summary(ttCy_comglmm0c)$AIC # AIC = 1391.6 vs 1390.5 (hypothesis likely not validated)!
summary(ttCy_comglmm0d)$AIC # AIC = 1392.4 vs 1388.1 (hypothesis likely validated)!
# I do not run PB-based LRT for now as they take too long to run.

# tictoc::tic("Parametric bootstrap LRT for the additive effect")
# res.LRT_inteff <- DHARMa::simulateLRT(m0 = ttCy_comglmm0, m1 = ttCy_comglmm1b, n = 500, seed = 10)
# tt <- as.data.frame(cbind(res.LRT_inteff$method,
#                           res.LRT_inteff$data.name,
#                           res.LRT_inteff$statistic,
#                           res.LRT_inteff$p.value))
# rownames(tt) <- NULL
# tt %>% dplyr::rename("Method" = V1,
#                      "Models" = V2,
#                      "Log Likelihood (M1/M0)" = V3,
#                      "p-value" = V4) -> tt
# readr::write_csv2(x = tt, file = here::here("output", "tables", "res.ttCy_LRT_addeff.csv"))
# tictoc::toc() # DISCLAIMER: took >25h to run!!!!
# The PB-based LRT is ...
# NOTE: initially, normally I would use the more efficient 'pbkrtest::PBmodcomp()' instead of the
# 'DHARMa::simulateLRT()' function, but it doesn't work with {glmmTMB} objects.


## Parametric bootstrap to test the interactive effect of the connectivity metric:
# To save some time, I don"t even bother computing the PB-based LRT for the interaction effect, it won't be
# significant. I should improve my proxies and my models first.



### *** 1.1.4.2. Bootstrapped confidence intervals for estimated parameters ----
tictoc::tic("Bootstrap CI for the additive COM-Poisson GLMM parameters")
res.ttCy_addeff_CI_boot <- confint(ttCy_comglmm1b, method="boot")
tt <- as.data.frame(res.ttCy_addeff_CI_boot)
tt$parameters <- rownames(tt)
readr::write_csv2(x = tt,
                  file = here::here("output", "tables", "res.ttCy_bootCI_addeff.csv"))
tictoc::toc() # DISCLAIMER: took ~2h10 to run!



### *** 1.1.4.3. Conclusion ----
# For the initial model:
summary(ttCy_comglmm1) # AIC = 1626.7 and both R2_glmm = 0.05.
# Diagnostics ran for 'ttCy_comglmm1' (initial model) indicated that the model fit the data relatively well
# although several modelling assumptions were slightly violated. They also confirmed that the RE were not
# truly useful for this model while the use of a COM-Poisson distribution was relevant.
# Importantly, diagnostics showed that the model was slightly off likely because there was true outliers
# in the data as the very low clutch sizes observed were probably generated by another process: i.e. some
# observations had surprisingly low clutch sizes with regards to their locations and adjacent broods.
## Significant variables: species, cumdd_30, year2021.
## Almost significant variables: logged_woodyveg, year2020 and year2022.
## Hypothesis 1 likely not validated!

# For the exploratory models:
summary(ttCy_comglmm1b) # AIC = 1391.3 and Marg_R2_glmm = 0.09; Cond_R2_glmm = 0.1.
## Significant variables: woodyveg, species, light_pollution, noise_iq, cumdd_30, year2021.
## Almost significant variables: Fmetric_d2b1, year2020.
## Hypothesis 1 likely not validated (AIC = 1392 vs 1391.3)!
summary(ttCy_comglmm1c) # AIC = 1390.5 and no R2 for dispersion models.
## Significant variables: woodyveg, species, light_pollution, noise_iq, cumdd_30, year2020, year2021.
## Almost significant variables: Fmetric_d2b1.
## Hypothesis 1 likely not validated (AIC = 1391.6 vs 1390.5)!
summary(ttCy_comglmm1d) # AIC = 1388.1 and no R2 for dispersion models.
## Significant variables: woodyveg, Fmetric_d2b1, species, noise_iq, cumdd_30, year2020, year2021.
## Almost significant variables: light_pollution.
## Hypothesis 1 likely validated (AIC = 1392.4 vs 1388.1)!

# Diagnostics for these models were mostly ok, there was no outliers, deviations or residual autocorrelation.
# However, as could be expected, some VIF values for the D model ('ttCy_comglmm1d') were rather high even
# though the covariance values were ok.
# It also appears that the data could be following a COM-Poisson distribution with a nu ~ 1.1.
# Predictions are fairly ok but still too narrow (and extremely similar between B, C, D)!

# Hypothesis 2 (interaction) seems rejected for all specifications.





########################## ************************************************* ###############################
# -------------------------------------- #
##### 2. Modelling hatching success #####
# -------------------------------------- #

##### * 2.1. Hatching success: Binomial GLMM ------------------------------------
# ---------------------------------------------------------------------------- #
### ** 2.1.1. Initial model fit ----
# __________________________________

## Fitting a regular binomial GLM:
ttHSy_glm1 <- stats::glm(brood_size/clutch_size ~ logged_woodyveg + logged_Fmetric + species +
                           urban_intensity + manag_low + manag_high + light_pollution + noise_iq +
                           cumdd_30 + year,
                         weights = clutch_size, # Prior weights!
                         data = ntits2, family = "binomial") # Weights should not be forgotten. Otherwise, the
# formulation should be: cbind(brood_size, clutch_size-brood_size)!

## Fitting a binomial GLMM:
ttHSy_glmm1 <- glmmTMB::glmmTMB(brood_size/clutch_size ~ logged_woodyveg + logged_Fmetric + species +
                                  urban_intensity + manag_low + manag_high + light_pollution + noise_iq +
                                  cumdd_30 + year + (1|id_nestbox),
                           weights = clutch_size, data = ntits2, family = "binomial")

## Fitting a zero-inflated (ZI) binomial GLMM:
ttHSy_ziglmm1 <- glmmTMB::glmmTMB(brood_size/clutch_size ~ logged_woodyveg + logged_Fmetric + species +
                                  urban_intensity + manag_low + manag_high + light_pollution + noise_iq +
                                  cumdd_30 + year + (1|id_nestbox),
                                weights = clutch_size, data = ntits2, family = "binomial",
                                ziformula = ~1) # Intercept only.

summary(ttHSy_glm1) # AIC = 1698.3.
summary(ttHSy_glmm1) # AIC = 1229.6.
summary(ttHSy_ziglmm1) # AIC = 912.
# It seems that, if the inclusion of a random effect (RE) strongly improves the fit and so does accounting
# for the zero-inflation (ZI)! I will thus carry on with the last model to the diagnostic part and assess
# whether the use of the RE is truly justified or not and if the model behaves as expected.





### ** 2.1.2. Improved model (exploration) ----
# _____________________________________________

## To remove probable outliers (see 'ttHSy_ziglmm1' diagnostics):
ntits3 <- ntits2[-c(which(ntits2$brood_size == 0)),] # I delete the 28 observations for which no eggs
# hatched as they were likely generated by another process than the one controlling overall hatching
# success (e.g. desertion, predation).

## Fitting a binomial GLMM:
ttHSy_glmm1a <- glmmTMB::glmmTMB(brood_size/clutch_size ~ logged_woodyveg + logged_Fmetric + species +
                                  urban_intensity + manag_low + manag_high + light_pollution + noise_iq +
                                  cumdd_30 + year + (1|id_nestbox),
                                weights = clutch_size, data = ntits3, family = "binomial")

## Replacement of the beta0 "F-metric" (by the beta1 version):
ttHSy_glmm1b <- glmmTMB::glmmTMB(brood_size/clutch_size ~ logged_woodyveg + logged_Fmetric_d2b1 + species +
                                   urban_intensity + manag_low + manag_high + light_pollution + noise_iq +
                                   cumdd_30 + year + (1|id_nestbox),
                                 weights = clutch_size, data = ntits3, family = "binomial")

## Replacement of the woody vegetation volume (by its area) but not the "F-metric':
ttHSy_glmm1c <- glmmTMB::glmmTMB(brood_size/clutch_size ~ logged_woody_area + logged_Fmetric + species +
                                   urban_intensity + manag_low + manag_high + light_pollution + noise_iq +
                                   cumdd_30 + year + (1|id_nestbox),
                                 weights = clutch_size, data = ntits3, family = "binomial")

## Replacement of both:
ttHSy_glmm1d <- glmmTMB::glmmTMB(brood_size/clutch_size ~ logged_woody_area + logged_Fmetric_d2b1 + species +
                                   urban_intensity + manag_low + manag_high + light_pollution + noise_iq +
                                   cumdd_30 + year + (1|id_nestbox),
                                 weights = clutch_size, data = ntits3, family = "binomial")
## Replacement of "urban_intensity" by "logged_herby_area" but not the "F-metric':
ttHSy_glmm1e <- glmmTMB::glmmTMB(brood_size/clutch_size ~ logged_woody_area + logged_Fmetric + species +
                                   logged_herby_area + manag_low + manag_high + light_pollution + noise_iq +
                                   cumdd_30 + year + (1|id_nestbox),
                                 weights = clutch_size, data = ntits3, family = "binomial")
summary(ttHSy_glmm1a) # AIC = 709.9 vs 1229.6 (no-ZI) or 912 (ZI) for the initial models!
summary(ttHSy_glmm1b) # AIC = 710.3.
summary(ttHSy_glmm1c) # AIC = 701.5.
summary(ttHSy_glmm1d) # AIC = 700.4.
summary(ttHSy_glmm1e) # AIC = 701.2 (works also for clutch_size)!


##### A FINIR§§§ ----
##### A FINIR§§§ ----
##### A FINIR§§§ ----



# IMPROVEEEDEEDED
# UPDATE: diagnostics ran for 'ttCy_comglmm1' (initial model) indicated that the model fit the data
# relatively well although several modelling assumptions were slightly violated. They also confirmed that
# the RE were not truly useful for this model. Importantly, diagnostics showed that the model was slightly
# off likely because there was true outliers in the data as the very low clutch sizes observed were probably
# generated by another process. Consequently, in a second step, we removed them and explored a few
# reasonable variations of the same model by trying different proxies of the same variable ("noise_iq"
# instead of "noise_iq"; "Fmetric_d2b1" instead of "Fmetric_d2b0"; and "woody_area" instead of "woodyveg_vw"),
# using "site" as RE, and slightly tuning the (nu) dispersion model (see below).
# I also tried interaction models, but interaction effects were not significant.

# Below, code and comments will show the diagnostics of one or several of these improved models, but you
# can re-run the diagnostics for the initial model by replacing the model name in the code chunks and to
# change ntits3 by ntits2 (i.e. the dataset with the deleted outliers).




# INTERACTIONNNNN
# ## Fitting interactive (mediated) GLMMs:
# ttHSy_glmm3 <- lme4::glmer(brood_size/clutch_size ~
#                              scale(logged_woodyveg, scale = F) * scale(logged_Fmetric, scale = F) +
#                              urban_intensity + manag_low + manag_high + light_pollution + noise_iq +
#                              cumdd_30 + year + (1|id_nestbox),
#                            weights = clutch_size, data = ntits2, family = "binomial",
#                            control=lme4::glmerControl(optimizer="bobyqa",
#                                                       optCtrl=list(maxfun=2e5))) # Yields an AIC = 713.7.
# # IMPORTANT NOTE: as will be seen further down the diagnostic process, the true model should probably be
# # zero-inflated (AIC = 563.4)!









### ** 2.1.3. Diagnostics and assumption checks ----
# __________________________________________________

### *** 2.1.3.1. Residuals extraction, autocorrelation and collinearity ----
## Traditional residuals:
par(.pardefault)
resid <- stats::resid(ttHSy_ziglmm1, type = 'response')
plot(resid, id = 0.05, idLabels = ~.obs) # Very strange distribution and clear outliers!
# performance::check_outliers(ttHSy_ziglmm1) # Does not work for this type of model.
ntits2[which(resid < -0.4),] # Nestboxes with the lowest residuals = ~0% hatching success! Interestingly,
# they may belong to the same nestbox, suggesting a strong year effect.

# To further investigate patterns, I can plot the residuals against some predictors:
plot(x = ntits2$year, y = resid) # Seems rather ok although we once again find patterns linked to the
# sometimes odd distribution of some predictors. However, be reminded that simulated residuals will be
# more useful).
# plot(ttHSy_ziglmm1, id_nestbox~stats::resid(.)) # Does not work for this type of model.
# plot(ttHSy_ziglmm1, site~stats::resid(.)) # Does not work for this type of model.

## Simulation-based scaled residuals computation ({DHARMa} method):
simu.resid <- DHARMa::simulateResiduals(fittedModel = ttHSy_ziglmm1, n = 1000, re.form = NULL) # The
# 're.form' argument is to base simulations on the model unconditional of the random effects (and only works
# for {lme4} formulations). It is useful for testing dispersion (see below) but can be omitted eventually.
plot(simu.resid) # Ok.
DHARMa::outliers(simu.resid) # No potential outliers (wtf?).
# ntits2[c(156,170,181,210,227,314,362,367),] # They have surprisingly low clutch sizes with regards to their
# # locations and their adjacent observations. They may well be true outliers (whose clutch sizes are function
# # of other processes).

## Autocorrelation and collinearity:
DHARMa::testSpatialAutocorrelation(simulationOutput = simu.resid,
                                   x = ntits2$coord_x, y = ntits2$coord_y, plot = TRUE) # Ok.
performance::check_autocorrelation(ttHSy_ziglmm1) # Ok.
performance::check_collinearity(ttHSy_ziglmm1) # Too high!
stats::vcov(ttHSy_ziglmm1) # But values of the covariance matrix seem ok.

## Heteroscedasticity and possible model misspecifications:
par(.pardefault)
DHARMa::plotResiduals(simu.resid, form = ntits2$logged_woodyveg) # Quantile deviation detected!
DHARMa::plotResiduals(simu.resid, form = ntits2$logged_Fmetric) # Quantile deviation detected!
DHARMa::plotResiduals(simu.resid, form = ntits2$urban_intensity)
DHARMa::plotResiduals(simu.resid, form = ntits2$manag_intensity)
DHARMa::plotResiduals(simu.resid, form = ntits2$light_pollution)
DHARMa::plotResiduals(simu.resid, form = ntits2$noise_iq)
DHARMa::plotResiduals(simu.resid, form = ntits2$cumdd_30)
DHARMa::plotResiduals(simu.resid, form = ntits2$species)
DHARMa::plotResiduals(simu.resid, form = ntits2$year)



### *** 2.1.3.2. Distribution and dispersion ----
## Assessing over or under-dispersion:
DHARMa::testDispersion(simu.resid) # Ok.
performance::check_overdispersion(x = ttHSy_ziglmm1) # Overdispersion detected!

## Distribution of the predicted probabilities:
probabilities <- stats::predict(object = ttHSy_ziglmm1, type = "response") # Extract the predicted
# probabilities.
par(mfrow= c(1,2))
hist(probabilities, main = "Predicted proportions", xlab = "Hatching success")
hist(ntits2$brood_size/ntits2$clutch_size, main = "Observed proportions", xlab = "Hatching success")
# The model seems to fit the observed proportions rather nicely although it under-predict success and
# failures!

## Zero-inflation:
DHARMa::testZeroInflation(simu.resid) # Ok (normal since we already accounted for it)!
# Testing with the non-ZI GLMM:
simu.resid_nozi <- DHARMa::simulateResiduals(fittedModel = ttHSy_glmm1, n = 1000)
plot(simu.resid_nozi) # Clear deviations detected!
probabilities <- stats::predict(object = ttHSy_glmm1, type = "response") # Extract the predicted
# probabilities.
par(mfrow= c(1,2))
hist(probabilities)
hist(ntits2$brood_size/ntits2$clutch_size) # Surprisingly, the model seems to better fit the observed
# proportions, even though it still under-predicts the proportion of failures.



### *** 2.1.3.3. Linearity ----
## Plotting the response on the logit scale (= log odds) against predictors:
# Format data:
ntits2 %>% dplyr::select(woodyveg_vw, woody_area, woodyveg_sd,
                         F_metric_d2b0, F_metric_d1b0, F_metric_d3b0, F_metric_d1b1, F_metric_d2b1,
                         urban_intensity, herbaceous_area, built_area, traffic,
                         light_pollution, noise_m, noise_iq,
                         cumdd_30, min_t_before) %>%
  dplyr::mutate("Fmetric" = F_metric_d2b0,
                "Fmetric (sqrt)" = sqrt(F_metric_d2b0),
                "Fmetric (log)" = log10(F_metric_d2b0),
                "woodyveg_vw" = woodyveg_vw,
                "woodyveg_vw (sqrt)" = sqrt(woodyveg_vw),
                "woodyveg_vw (log)" = log10(woodyveg_vw), .keep = "unused") -> mydata
predictors <- colnames(mydata)
# Bind the logit and tidying the data for plot (ggplot2, so long format):
mydata <- mydata %>%
  dplyr::mutate(logit = log(probabilities/(1-probabilities))) %>%
  tidyr::gather(key = "predictors", value = "predictor.value", -logit)
# Create scatterplot:
ggplot2::ggplot(mydata, ggplot2::aes(y = logit, x = predictor.value))+
  ggplot2::geom_point(size = 0.5, alpha = 0.5) +
  ggplot2::geom_smooth(method = "loess") +
  ggplot2::theme_bw() +
  ggplot2::facet_wrap(~predictors, scales = "free_x") # Ok.



### *** 2.1.3.4. Goodness-of-fit (GOF) and performances ----
## GOF test of Pearson's Chi2 residuals:
dat.resid <- sum(stats::resid(ttHSy_ziglmm1, type = "pearson")^2)
1 - stats::pchisq(dat.resid, stats::df.residual(ttHSy_ziglmm1)) # p = 0, likely a mistake?

## Computing a pseudo-R2:
performance::r2_nakagawa(ttHSy_glmm1) # [Additive model]: Marg_R2_glmm = 0.05; Cond_R2_glmm = 0.61.
performance::r2_nakagawa(ttHSy_ziglmm1) # [Additive model]: Marg_R2_glmm = 0.07; Cond_R2_glmm = 0.29 (but
# strange warning, so probably a mistake).

## Likelihood-ration tests (LRT) of GOF:
# Importance of the "id_nestbox" random-effect (RE):
ttHSy_ziglm0 <- glmmTMB::glmmTMB(brood_size/clutch_size ~ logged_woodyveg + logged_Fmetric + species +
                                    urban_intensity + manag_low + manag_high + light_pollution + noise_iq +
                                    cumdd_30 + year,
                                  weights = clutch_size, data = ntits2, family = "binomial",
                                  ziformula = ~1)
summary(ttHSy_ziglm0) # The non-mixed model gives AIC = 957.6 while the mixed-model gave AIC = 912, so
# the use of the mixed model seems warranted by the data!

# Importance of the fixed effects:
ttHSy_ziglmm0 <- glmmTMB::glmmTMB(brood_size/clutch_size ~ 1 + (1|id_nestbox),
                                  weights = clutch_size, data = ntits2, family = "binomial",
                                  ziformula = ~1)
summary(ttHSy_ziglmm0) # AIC = 928.7 vs 912, so the model is likely slightly better but not that much!





### ** 2.1.4. Inference and predictions ----
# __________________________________________

##### TO BE RUN §§§ ----

### *** 2.1.4.1. Hypotheses testing: LRT for the additive and interactive effect of the F-metric ----
## Parametric bootstrap to test the additive effect of the connectivity metric:
ttHSy_ziglmm0 <- stats::update(ttHSy_ziglmm1, .~. -logged_Fmetric)
summary(ttHSy_ziglmm0)$AIC # AIC = 910.5 vs 912 (hypothesis likely not validated)!
# I do not run PB-based LRT for now as they take too long to run.

# tictoc::tic("Parametric bootstrap LRT for the interaction model")
# res.LRT_inteff <- DHARMa::simulateLRT(m0 = ttHSy_ziglmm0, m1 = ttHSy_ziglmm1, n = 500, seed = 21)
# tt <- as.data.frame(cbind(res.LRT_inteff$method,
#                           res.LRT_inteff$data.name,
#                           res.LRT_inteff$statistic,
#                           res.LRT_inteff$p.value))
# rownames(tt) <- NULL
# tt %>% dplyr::rename("Method" = V1,
#                      "Models" = V2,
#                      "Log Likelihood (M1/M0)" = V3,
#                      "p-value" = V4) -> tt
# readr::write_csv2(x = tt, file = here::here("output", "tables", "res.ttHSy_LRT_addeff.csv"))
# tictoc::toc() # DISCLAIMER: took ~3h35 to run!
# # NOTE: initially, normally I would use the more efficient 'pbkrtest::PBmodcomp()' instead of the
# # 'DHARMa::simulateLRT()' function, but it doesn't work with {glmmTMB} objects.


## Parametric bootstrap to test the interactive effect of the connectivity metric:
# To save some time, I don"t even bother computing the PB-based LRT for the interaction effect, it won't be
# significant. I should improve my proxies and my models first.



### *** 2.1.4.2. Bootstrapped confidence intervals for estimated parameters ----
tictoc::tic("Bootstrap CI for additive GLMM parameters")
res.ttHSy_addeff_CI_boot <- confint(ttHSy_ziglmm1, method="boot")
tt <- as.data.frame(res.ttHSy_addeff_CI_boot)
tt$parameters <- rownames(tt)
readr::write_csv2(x = tt,
                  file = here::here("output", "tables", "res.ttHSy_bootCI_addeff.csv"))
tictoc::toc() # DISCLAIMER: took ~2h10 to run!



### *** 2.1.4.3. Conclusion ----
# For the initial model:
summary(ttHSy_ziglmm1) # AIC = 912 and Marg_R2_glmm = 0.07; Cond_R2_glmm = 0.29.
# Diagnostics ran for 'ttHSy_ziglmm1' (initial model) indicated that the model fit the data relatively well
# although several problems have been detected:
# - The raw residuals are very oddly distributed, showing a signs for the existence of several different
#   processes and thus, possible outliers (albeit formal test did not find any).
# - Some significant quantile deviations have been detected.
# - A significant overdispersion has been detected.
# - The model under-predicts total successes and failures and, surprisingly, the non-ZI model was better!
# - Most importantly, "species" was not found significant (yet, as here we model a proportion and not raw
#   counts, it is possible).
# On the other hand, diagnostics also indicated that the use of a RE was appropriate.
## Significant variables: woodyveg, and all 3 years.
## Almost significant variables: none.
## Hypothesis 1 likely not validated (AIC = 910.5 vs 912)!









par(.pardefault)
colnames(ntits3)
ppl.tits::uni.dotplots(ntits3[,15:ncol(ntits3)])
ppl.tits::uni.dotplots(as.data.frame(cbind(ntits3$F_metric_d1b0, log10(ntits3$F_metric_d1b0),
                                           ntits3$woody_area, log10(ntits3$woody_area),
                                           ntits3$herbaceous_area, log10(ntits3$herbaceous_area))))





########## *-------------------------------------------------------* ###########
##### * 2.2. Brood size: ZICOM-Poisson GLMM ------------------------------------
# ---------------------------------------------------------------------------- #
### ** 2.2.1. Initial model fit ----
# __________________________________

# Given the look of the response variable and my previous diagnostics, I chose to directly compare various
# structural model types before even starting the dedicated diagnostics.

## Fitting a regular Poisson GLM:
ntitsBSy_glm1 <- stats::glm(brood_size ~ logged_woodyveg + logged_Fmetric +
                           urban_intensity + manag_low + manag_high + light_pollution + noise_iq +
                           cumdd_30 + father_cond + mother_cond + year,
                         data = ntits2, family = "poisson")

## Fitting a regular Poisson GLMM:
ntitsBSy_glmm1 <- glmmTMB::glmmTMB(brood_size ~ logged_woodyveg + logged_Fmetric + urban_intensity +
                                  manag_low + manag_high + light_pollution + noise_iq +
                                  cumdd_30 + father_cond + mother_cond + year + (1|id_nestbox),
                                data = ntits2, family = "poisson")

## Fitting a Zero-Inflated (ZI) Poisson GLMM:
ntitsBSy_ziglmm1 <- glmmTMB::glmmTMB(brood_size ~ logged_woodyveg + logged_Fmetric + urban_intensity +
                                    manag_low + manag_high + light_pollution + noise_iq +
                                    cumdd_30 + father_cond + mother_cond + year + (1|id_nestbox),
                                  data = ntits2, family = "poisson",
                                  ziformula = ~1)

## Fitting a Zero-Inflated (ZI) COM-Poisson GLMM:
ntitsBSy_zicomglmm1 <- glmmTMB::glmmTMB(brood_size ~ logged_woodyveg + logged_Fmetric + urban_intensity +
                                       manag_low + manag_high + light_pollution + noise_iq +
                                       cumdd_30 + father_cond + mother_cond + year + (1|id_nestbox),
                                     data = ntits2, family = glmmTMB::compois(link = "log"),
                                     dispformula = ~1,
                                     ziformula = ~1) # Rather long to fit.

summary(ntitsBSy_glm1) # AIC = 1293.3
summary(ntitsBSy_glmm1) # AIC = 1295.3
summary(ntitsBSy_ziglmm1) # AIC = 1180.3
summary(ntitsBSy_zicomglmm1) # AIC = 1072.2
# It seems that, if the inclusion of a random effect (RE) did not improve the fit, accounting for both the
# zero-inflation and the likely underdispersion strongly improved the fit! I will thus carry on with the last
# model to the diagnostic part and assess whether the use of the RE is truly justified or not and if the
# model behaves as expected.
ntitsBSy_zicomglmm2 <- glmmTMB::glmmTMB(brood_size ~ logged_woodyveg + logged_Fmetric + urban_intensity +
                                       manag_low + manag_high + light_pollution + noise_iq +
                                       cumdd_30 + father_cond + mother_cond + year + (1|id_nestbox),
                                     data = ntits2, family = glmmTMB::compois(link = "log"),
                                     dispformula = ~father_cond,
                                     ziformula = ~father_cond+cumdd_30) # Rather long to fit.
summary(ntitsBSy_zicomglmm2) # AIC = 1065.9 vs 1072.2, so slightly better.
# NOTE: After a few attempts to tune the model, I found that this specification slightly improved the model.
# But as it is a kind of data-dredging, I prefer carry on with my initially intended model. Still, I will
# perform diagnostics on both models. This 2nd model will be sometimes called ""exploratory improved model".

# # The interactive (mediated) model:
# ntitsBSy_zicomglmm3 <- glmmTMB::glmmTMB(brood_size ~
#                                        scale(logged_woodyveg, scale = F) * scale(logged_Fmetric, scale = F) +
#                                        urban_intensity + manag_low + manag_high + light_pollution + noise_iq +
#                                        cumdd_30 + father_cond + mother_cond + year + (1|id_nestbox),
#                                      data = ntits2, family = glmmTMB::compois(link = "log"),
#                                      dispformula = ~1,
#                                      ziformula = ~1) # Rather long to fit.
# summary(ntitsBSy_zicomglmm3) # AIC = 1074.2, doesn't seem supported by the data.





### ** 2.2.2. Diagnostics and assumption checks ----
# __________________________________________________

### *** 2.2.2.1. Residuals extraction, autocorrelation and collinearity ----
## Traditional residuals:
par(.pardefault)
resid <- stats::resid(ntitsBSy_zicomglmm1, type = 'response')
plot(resid, id = 0.05, idLabels = ~.obs) # Ok-ish but there are a few potential outliers.
# performance::check_outliers(ntitsBSy_zicomglmm1) # Does not work for this type of model.
ntits2[which(resid < -4),] # As could have been guessed from the plot, the 2nd group (with the lowest
# residuals) consist of all the observations where "brood_size" ~ 0. It could be a sign that the zero-part of
# the model should indeed be modelled with relevant predictors. However, we do not seem to have the relevant
# predictors since the patterns still exist even with the "exploratory improved model" (i.e.
# 'ntitsBSy_zicomglmm2').

# To further investigate patterns, I can plot the residuals against some predictors:
plot(x = ntits2$logged_Fmetric, y = resid) # There may be signs of heteroscedasticity for the "F-metric".
# Otherwise, it seems ok (but, once again, simulated residuals will be more useful).
# plot(ntitsBSy_zicomglmm1, id_nestbox~stats::resid(.)) # Does not work for this type of model.
# plot(ntitsBSy_zicomglmm1, site~stats::resid(.)) # Does not work for this type of model.

## Simulation-based scaled residuals computation ({DHARMa} method):
simu.resid <- DHARMa::simulateResiduals(fittedModel = ntitsBSy_zicomglmm1, n = 1000, re.form = NULL) # The
# 're.form' argument is to base simulations on the model unconditional of the random effects (and only works
# for {lme4} formulations). It is useful for testing dispersion (see below) but can be omitted eventually.
plot(simu.resid) # Quantile deviation detected (but better for 'ntitsBSy_zicomglmm2')!
DHARMa::outliers(simu.resid) # None.

## Autocorrelation and collinearity:
DHARMa::testSpatialAutocorrelation(simulationOutput = simu.resid,
                                   x = ntits2$coord_x, y = ntits2$coord_y, plot = TRUE) # Slightly significant
# spatial autocorrelation detected. Add a "site" RE?
performance::check_autocorrelation(ntitsBSy_zicomglmm1) # Ok-ish!
performance::check_collinearity(ntitsBSy_zicomglmm1) # Ok-ish, but "urban_intensity" > 3!
stats::vcov(ntitsBSy_zicomglmm1) # But values of the covariance matrix seem ok.

## Heteroscedasticity and possible model misspecifications:
par(.pardefault)
DHARMa::plotResiduals(simu.resid, form = ntits2$logged_woodyveg)
DHARMa::plotResiduals(simu.resid, form = ntits2$logged_Fmetric)
DHARMa::plotResiduals(simu.resid, form = ntits2$urban_intensity)
DHARMa::plotResiduals(simu.resid, form = ntits2$manag_intensity)
DHARMa::plotResiduals(simu.resid, form = ntits2$light_pollution)
DHARMa::plotResiduals(simu.resid, form = ntits2$noise_iq)
DHARMa::plotResiduals(simu.resid, form = ntits2$cumdd_30)
DHARMa::plotResiduals(simu.resid, form = ntits2$father_cond)
DHARMa::plotResiduals(simu.resid, form = ntits2$mother_cond)
DHARMa::plotResiduals(simu.resid, form = ntits2$year)
# All these plots are ok, so the slight quantile deviations may perhaps be due to: i) spatial autocorrelation
# (and insufficient RE), ii) missing variables, or iii) the misspecification of the zero-response?



### *** 2.2.2.2. Distribution (family, ZI, dispersion) ----
## Assessing over or under-dispersion:
aods3::gof(ntitsBSy_zicomglmm1) # Does not work for this type of model!
AER::dispersiontest(object = ntitsBSy_zicomglmm1, alternative = c("less")) # Does not work for this model type!
DHARMa::testDispersion(simu.resid) # Ok.

## Theoretical count distribution:
theo_count <- COMPoissonReg::rzicmp(n = nrow(ntits2), lambda = mean(ntits2$brood_size),
                                    nu = 1.1,  # The 'nu' parameter should be chosen by trial-and-errors.
                                    p = 0.05) # And so does the probability of 0.
tc_df <- data.frame(theo_count)

ggplot2::ggplot(pm, ggplot2::aes(brood_size)) +
  ggplot2::geom_bar(fill = "#1E90FF") +
  ggplot2::geom_bar(data = tc_df, ggplot2::aes(theo_count, fill="#1E90FF", alpha=0.5)) +
  ggplot2::theme_classic() +
  ggplot2::theme(legend.position = "none") # Blue = observed counts; red = simulated.
# This plot suggests that brood_size could be following a COM-Poisson distribution of parameter nu~1.1,
# especially if we consider that the zero-inflation (ZI) is generated by another process.

## Distribution of the predicted counts:
pred_counts <- stats::predict(object = ntitsBSy_zicomglmm2, type = "response") # Extract the predicted counts.
par(mfrow= c(1,2))
hist(pred_counts)
hist(ntits2$brood_size) # Compared to the predictions from "ntitsBSy_zicomglmm1", the ones from
# "ntitsBSy_zicomglmm2" seem more accurate but predictions are still too narrow and the model still fails to
# predict small brood sizes!

## Zero-inflation (ZI):
simu.resid_woZI <- DHARMa::simulateResiduals(fittedModel = ntitsBSy_glmm1, n = 1000) # Model without ZI.
DHARMa::testZeroInflation(simu.resid) # Nope.
DHARMa::testZeroInflation(simu.resid_woZI) # Yes, so there truly is a ZI. Yet, this model accounts for it but
# cannot predict it.
# I made a few attempts at improving the ZI part of the model, but I mostly failed (cf. 'ntitsBSy_zicomglmm2').



### *** 2.2.2.3. Linearity ----
## Plotting the response on the log scale against predictors:
ntits2 %>% dplyr::select(woodyveg_vw, pmF_d60_beta0, urban_intensity, light_pollution, noise_iq, cumdd_30,
                      father_cond, mother_cond) %>%
  dplyr::mutate("Fmetric" = pmF_d60_beta0,
                "Fmetric (sqrt)" = sqrt(pmF_d60_beta0),
                "Fmetric (log)" = log10(pmF_d60_beta0),
                "woodyveg_vw" = woodyveg_vw,
                "woodyveg_vw (sqrt)" = sqrt(woodyveg_vw),
                "woodyveg_vw (log)" = log10(woodyveg_vw), .keep = "unused") -> mydata
predictors <- colnames(mydata)
# Bind log(Y) and tidying the data for plot (ggplot2, so long format):
mydata <- mydata %>%
  dplyr::mutate(log_y = log(ntits2$brood_size+1)) %>%
  tidyr::gather(key = "predictors", value = "predictor.value", -log_y)
# Create scatterplot
ggplot2::ggplot(mydata, ggplot2::aes(y = log_y, x = predictor.value))+
  ggplot2::geom_point(size = 0.5, alpha = 0.5) +
  ggplot2::geom_smooth(method = "loess") +
  ggplot2::theme_bw() +
  ggplot2::facet_wrap(~predictors, scales = "free_x") # Linearity seems respected.



### *** 2.2.2.4. Model goodness-of-fit (GOF) and performances ----
# GOF test of Pearson's Chi2 residuals:
dat.resid <- sum(stats::resid(ntitsBSy_zicomglmm1, type = "pearson")^2)
1 - stats::pchisq(dat.resid, stats::df.residual(ntitsBSy_zicomglmm1)) # p = 0.42, indicating that there is no
# significant lack of fit. Keep in mind though that GOF measures for mixed models is an extremely complicated
# topic and interpretations are not straightforward.

# Computing a pseudo-R2:
performance::r2_nakagawa(ntitsBSy_zicomglmm1) # [Additive model]: Marg_R2_glmm = 0.03; Cond_R2_glmm = 0.05.
performance::r2(ntitsBSy_zicomglmm2) # Yields NA.

## Likelihood-ration tests (LRT) of GOF:
# For the random-effects (RE):
ntitsBSy_zicomglm1 <- glmmTMB::glmmTMB(brood_size ~ logged_woodyveg + logged_Fmetric + urban_intensity +
                                      manag_low + manag_high + light_pollution + noise_iq +
                                      cumdd_30 + father_cond + mother_cond + year,
                                    data = ntits2, family = glmmTMB::compois(link = "log"),
                                    dispformula = ~1,
                                    ziformula = ~1)
summary(ntitsBSy_zicomglm1) # The non-mixed model gives AIC = 1072.9 while the mixed-model with "id_nestbox"
# as RE gives AIC = 963.2. The one with both RE gives something similar, so it seems like the use of only
# one RE is warranted by the data. The same is true for the "exploratory improved model" (not shown here).

## For the whole model:
ntitsBSy_comglm0 <- glmmTMB::glmmTMB(brood_size ~ 1,
                                  data = ntits2, family = glmmTMB::compois(link = "log"),
                                  dispformula = ~ cumdd_30, # Specifies a more complex dispersion model.
                                  ziformula = ~ 1)
res.LRT_null <- stats::anova(object = ntitsBSy_comglm0, ntitsBSy_zicomglm1, test = "LRT")
# The test is significant, confirming that the model is useful to explain the data.




### *** 2.2.2.5. Posterior predictive simulations ----
# Predicted counts:
par(.pardefault)
obsprop <- prop.table(table(ntits2$brood_size))
sims <- stats::simulate(ntitsBSy_zicomglmm1, nsim = 1000)

nsim0 <- colSums(sims == 0) # Number of zeros (min obs value)
par(las=1,bty="l")
plot(pt <- prop.table(table(nsim0)),
     ylab="Probability", xlab="Number of zeros")
(obs0 <- sum(ntits2$brood_size == 0))
points(obs0, 0.06, col="red", pch=16, cex=2) # See the y (0.06) values in 'obsprop'!

nsim8 <- colSums(sims == 8) # Number of eights (modal obs value).
par(las=1,bty="l")
plot(pt <- prop.table(table(nsim8)),
     ylab="Probability", xlab="Number of eights")
(obs8 <- sum(ntits2$brood_size == 8))
points(obs8, 0.24, col="red", pch=16, cex=2)

nsim12 <- colSums(sims == 12) # Number of twelves (max obs value).
par(las=1,bty="l")
plot(pt <- prop.table(table(nsim12)),
     ylab="Probability", xlab="Number of twelves")
(obs12 <- sum(ntits2$brood_size == 12))
points(obs12, 0.004, col="red", pch=16, cex=2)
# These three examples indicate that the model(s) is not that bad. The range of zero predictions are in line
# with observations, yet the mode could be better predicted and so does the right-tail of the distribution.



### ** 2.2.3. Inference and predictions ----
# __________________________________________

##### TO BE RUN §§§ -----

### *** 2.2.3.1. Hypotheses testing: LRT for the additive and interactive effect of the F-metric ----
## Parametric bootstrap to test the additive effect of the connectivity metric:
ntitsBSy_zicomglmm0 <- stats::update(ntitsBSy_zicomglmm1, .~. -logged_Fmetric)

tictoc::tic("Parametric bootstrap LRT for the additive effect")
res.LRT_inteff <- DHARMa::simulateLRT(m0 = ntitsBSy_zicomglmm0, m1 = ntitsBSy_zicomglmm1, n = 500, seed = 107)
tt <- as.data.frame(cbind(res.LRT_inteff$method,
                          res.LRT_inteff$data.name,
                          res.LRT_inteff$statistic,
                          res.LRT_inteff$p.value))
rownames(tt) <- NULL
tt %>% dplyr::rename("Method" = V1,
                     "Models" = V2,
                     "Log Likelihood (M1/M0)" = V3,
                     "p-value" = V4) -> tt
readr::write_csv2(x = tt, file = here::here("output", "tables", "res.ntitsBSy_LRT_addeff.csv"))
tictoc::toc() # DISCLAIMER: took ~??? to run!
# The PB-based LRT is non-significant, indicating that our connectivity metric does not improve the
# description of the data here.
# NOTE: initially, normally I would use the more efficient 'pbkrtest::PBmodcomp()' instead of the
# 'DHARMa::simulateLRT()' function, but it doesn't work with {glmmTMB} objects.


## Parametric bootstrap to test the interactive effect of the connectivity metric:
# To save some time, I don"t even bother computing the PB-based LRT for the interaction effect, it won't be
# significant. I should improve my proxies and my models first.



### *** 2.2.3.2. Bootstrapped confidence intervals for estimated parameters ----
tictoc::tic("Bootstrap CI for the additive COM-Poisson GLMM parameters")
res.ntitsBSy_addeff_CI_boot <- confint(ntitsBSy_zicomglmm1, method="boot")
tt <- as.data.frame(res.ntitsBSy_addeff_CI_boot)
tt$parameters <- rownames(tt)
readr::write_csv2(x = tt,
                  file = here::here("output", "tables", "res.ntitsBSy_bootCI_addeff.csv"))
tictoc::toc() # DISCLAIMER: took ~2h10 to run!



### *** 2.2.3.3. Conclusion ----

summary(ntitsBSy_zicomglmm1)
summary(ntitsBSy_zicomglmm2)
# Our diagnostics show that the use of a ZICOM-Poisson regression strongly improves models predictive
# accuracy, and our models seem to fit the data fairly well. However, there is still room for improvements
# as the models still tend to predict a higher count-range than the observed one and the mode is not
# satisfyingly predicted. Interestingly, for this response variable, the use of RE does not seem useful.
# Possible leads for improvement could be to remove the zeros (as it may stem from a distinct process), merge
# observations, and try to improve the modelling of the dispersion (nu) parameter, although previous attempts
# were not very conclusive: still, the "exploratory improved model" showed that "father_cond" and "cumdd_30"
# could be useful to better model the ZI and the dispersion (cf. 'ntitsBSy_zicomglmm2').
# As they are, unfortunately, the models do not support our hypotheses and only four predictors turned out
# significant: "cumdd_30", "manag_high", "year2022" and either "mother_cond" or "woodyveg", depending on the
# model specification; while the lowest value of AIC = 1065.9. Here, our current "F-metric" is useless!





########################## ************************************************* ###############################
# ------------------------------------- #
##### 3. Modelling fledging success #####
# ------------------------------------- #

##### * 3.1. Fledging success: Binomial GLMM ------------------------------------
# ---------------------------------------------------------------------------- #
### ** 3.1.1. Initial model fit ----
# __________________________________

## Fitting a binomial GLM:
ntitsFSy_glm1 <- stats::glm(fledgling_nb/clutch_size ~ logged_woodyveg + logged_Fmetric +
                           urban_intensity + manag_low + manag_high + light_pollution + noise_iq +
                           cumdd_30 + father_cond + mother_cond + year,
                         weights = clutch_size, # Prior weights!
                         data = ntits2, family = "binomial") # Weights should not
# be forgotten. Otherwise, the formulation should be: cbind(fledgling_nb, clutch_size-fledgling_nb)!

## Fitting an additive GLMM:
ntitsFSy_glmm1 <- lme4::glmer(fledgling_nb/clutch_size ~ logged_woodyveg + logged_Fmetric + urban_intensity +
                             manag_low + manag_high + light_pollution + noise_iq +
                             cumdd_30 + father_cond + mother_cond + year + (1|id_nestbox),
                           weights = clutch_size, data = ntits2, family = "binomial")
# As there are convergence issues, I change the optimizer and increase iterations:
ss <- lme4::getME(ntitsFSy_glmm1, c("theta", "fixef"))
ntitsFSy_glmm2 <- stats::update(ntitsFSy_glmm1, start=ss,
                             control=lme4::glmerControl(optimizer="bobyqa",
                                                        optCtrl=list(maxfun=2e5))) # Convergence ok.

# # *** FURTHER TESTS *** #
# # So I'll try using the Gauss-Hermite quadrature (GHQ) for estimation:
# ntitsFSy_glmm2_bGHQ <- stats::update(ntitsFSy_glmm2, nAGQ = 10)
# summary(ntitsFSy_glmm2_bGHQ) # Same!
# # Remember that GHQ compute things differently!
# # Try all optimizers:
# ntitsFSy_glmm2_all <- lme4::allFit(ntitsFSy_glmm2)
# summary(ntitsFSy_glmm2_all) # All optimizers converge but give rather similar results, even though Nelder-
# # Mead appears to disagree.

# ## Fitting interactive (mediated) GLMMs:
# ntitsFSy_glmm3 <- lme4::glmer(fledgling_nb/clutch_size ~
#                              scale(logged_woodyveg, scale = F) * scale(logged_Fmetric, scale = F) +
#                              urban_intensity + manag_low + manag_high + light_pollution + noise_iq +
#                              cumdd_30 + father_cond + mother_cond + year + (1|id_nestbox),
#                            weights = clutch_size, data = ntits2, family = "binomial",
#                            control=lme4::glmerControl(optimizer="bobyqa",
#                                                       optCtrl=list(maxfun=2e5))) # Doesn't seem supported
# by the data.
summary(ntitsFSy_glm1) # AIC = 1569.9.
summary(ntitsFSy_glmm2) # AIC = 1248.4.

# # Test by removing possible overly influential observations:
# ntits2_wo <- ntits2[-c(49,58,50,143),]
# ntitsFSy_glmm3_wo <- stats::update(ntitsFSy_glmm3, data=ntits2_wo)
# summary(ntitsFSy_glmm3)$AIC
# summary(ntitsFSy_glmm3_wo)$AIC # Strongly improved AIC, BIC, and deviance. However, it yields lower R2_glmm!





### ** 3.1.2. Diagnostics and assumption checks ----
# __________________________________________________

### *** 3.1.2.1. Residuals extraction, autocorrelation and collinearity ----
## Traditional residuals:
par(.pardefault)
plot(ntitsFSy_glmm2, id = 0.05, idLabels = ~.obs) # Strange pattern. Many extreme residuals.
ntits2[c(45,49,234),] # Nestboxes with the highest residuals = ~100% fledging success!
ntits2[c(50,58,143),] # Nestboxes with the lowest residuals = ~0% fledging success!
# Interestingly, they may belong to the same nestbox, suggesting a strong year effect.
performance::check_outliers(ntitsFSy_glmm2) # Detected 25 potential outliers.

# To further investigate patterns, I can plot the residuals against some predictors:
resid <- stats::resid(ntitsFSy_glmm2, type = 'deviance')
plot(x = ntits2$noise_iq, y = resid) # Only "light_pollution" and "noise_iq" show slightly strange patterns.
# Possibly because "noise_iq" should be transformed (standardisation?). Otherwise, most predictors only
# show a higher variability at medium values.
plot(ntitsFSy_glmm2, id_nestbox~stats::resid(.)) # Justification for the nestbox random effect (RE).
plot(ntitsFSy_glmm2, site~stats::resid(.)) # Interestingly, there are not that much among-sites variance.

## Simulation-based scaled residuals computation (DHARMa method):
simu.resid <- DHARMa::simulateResiduals(fittedModel = ntitsFSy_glmm2, n = 1000, seed = 37)
plot(simu.resid) # Significant deviations detected! There seems to be a clear zero-inflation!

## Autocorrelation and collinearity:
DHARMa::testSpatialAutocorrelation(simulationOutput = simu.resid,
                                   x = ntits2$coord_x, y = ntits2$coord_y, plot = TRUE) # Ok.
performance::check_autocorrelation(ntitsFSy_glmm2) # Significant autocorrelation, but the Durbin-Watson test
# is known to be very sensitive.
performance::check_collinearity(ntitsFSy_glmm2) # Ok-ish, but "urban_intensity" > 3!
stats::vcov(ntitsFSy_glmm2) # Ok.

## Heteroscedasticity and possible model misspecifications:
par(.pardefault)
DHARMa::plotResiduals(simu.resid, form = ntits2$logged_woodyveg)
DHARMa::plotResiduals(simu.resid, form = ntits2$logged_Fmetric)
DHARMa::plotResiduals(simu.resid, form = ntits2$urban_intensity)
DHARMa::plotResiduals(simu.resid, form = ntits2$manag_intensity)
DHARMa::plotResiduals(simu.resid, form = ntits2$light_pollution)
DHARMa::plotResiduals(simu.resid, form = ntits2$noise_iq)
DHARMa::plotResiduals(simu.resid, form = ntits2$cumdd_30)
DHARMa::plotResiduals(simu.resid, form = ntits2$father_cond) # Signs of heteroscedasticity?
DHARMa::plotResiduals(simu.resid, form = ntits2$mother_cond)
DHARMa::plotResiduals(simu.resid, form = ntits2$year) # Signs of heteroscedasticity?
# There are rather clear signs of heteroscedasticity that are possibly linked to the zero-inflation.



### *** 3.1.2.2. Distribution and dispersion ----
## Assessing over or under-dispersion:
aods3::gof(ntitsFSy_glmm2) # Note that this test is meant for count data! Overdispersion?
DHARMa::testDispersion(simu.resid, alternative = "greater") # Significant overdispersion detected!
performance::check_overdispersion(x = ntitsFSy_glmm2) # Same here!

## Distribution of the predicted probabilities:
probabilities <- stats::predict(object = ntitsFSy_glmm2, type = "response") # Extract the predicted
# probabilities.
par(mfrow= c(1,2))
hist(probabilities)
hist(ntits2$fledgling_nb/ntits2$clutch_size) # The model does not fit the data well! It over-predicts average
# probabilities and strongly under-predicts the number of failures!

## Zero-inflation:
DHARMa::testZeroInflation(simu.resid) # Significant inflation detected!
# Fitting a zero-inflated (ZI) model and compare it:
ntitsFSy_ziglmm1 <- glmmTMB::glmmTMB(fledgling_nb/clutch_size ~
                                    logged_woodyveg + logged_Fmetric +
                                    urban_intensity + manag_low + manag_high + light_pollution + noise_iq +
                                    cumdd_30 + father_cond + mother_cond + year + (1|id_nestbox),
                                  weights = clutch_size,
                                  data = ntits2, family = binomial,
                                  ziformula = ~ 1) # Specifies a null ZI model.
summary(ntitsFSy_glmm2) # AIC = 1248.4.
summary(ntitsFSy_ziglmm1) # AIC = 970.4!
simu.resid_zi <- DHARMa::simulateResiduals(fittedModel = ntitsFSy_ziglmm1, n = 1000)
plot(simu.resid_zi) # The use of the ZI-binomial model seem to have solved the problems. To verify, I will
# look at the predictions from this new model:
probabilities <- stats::predict(object = ntitsFSy_ziglmm1, type = "response") # Extract the predicted
# probabilities.
par(mfrow= c(1,2))
hist(probabilities)
hist(ntits2$fledgling_nb/ntits2$clutch_size) # Surprisingly, the model's predictions are perhaps even worse:
# it seems unable to predict extreme events, whether total successes or failures.



### *** 3.1.2.3. Linearity ----
## Plotting the response on the logit scale (= log odds) against predictors:
# Format data:
ntits2 %>% dplyr::select(woodyveg_vw, pmF_d60_beta0, urban_intensity, light_pollution, noise_iq, cumdd_30,
                      father_cond, mother_cond) %>%
  dplyr::mutate("Fmetric" = pmF_d60_beta0,
                "Fmetric (sqrt)" = sqrt(pmF_d60_beta0),
                "Fmetric (log)" = log10(pmF_d60_beta0),
                "woodyveg_vw" = woodyveg_vw,
                "woodyveg_vw (sqrt)" = sqrt(woodyveg_vw),
                "woodyveg_vw (log)" = log10(woodyveg_vw), .keep = "unused") -> mydata
predictors <- colnames(mydata)
# Bind the logit and tidying the data for plot (ggplot2, so long format):
mydata <- mydata %>%
  dplyr::mutate(logit = log(probabilities/(1-probabilities))) %>%
  tidyr::gather(key = "predictors", value = "predictor.value", -logit)
# Create scatterplot:
ggplot2::ggplot(mydata, ggplot2::aes(y = logit, x = predictor.value))+
  ggplot2::geom_point(size = 0.5, alpha = 0.5) +
  ggplot2::geom_smooth(method = "loess") +
  ggplot2::theme_bw() +
  ggplot2::facet_wrap(~predictors, scales = "free_x") # Ok.



### *** 3.1.2.4. Goodness-of-fit (GOF) and performances ----
## GOF test of Pearson's Chi2 residuals:
dat.resid <- sum(stats::resid(ntitsFSy_ziglmm1, type = "pearson")^2)
1 - stats::pchisq(dat.resid, stats::df.residual(ntitsFSy_ziglmm1)) # p = 0, likely a mistake?

## Computing a pseudo-R2:
performance::r2_nakagawa(ntitsFSy_glmm2) # [Additive model]: Marg_R2_glmm = 0.11; Cond_R2_glmm = 0.48.
performance::r2_nakagawa(ntitsFSy_ziglmm1) # [Additive model]: Marg_R2_glmm = 0.10; Cond_R2_glmm = 0.2 (but
# strange warning, so probably a mistake).

## Likelihood-ration tests (LRT) of GOF:
# Importance of the "id_nestbox" random-effect (RE):
ntitsFSy_ziglmm0 <- glmmTMB::glmmTMB(fledgling_nb/clutch_size ~
                                    logged_woodyveg + logged_Fmetric +
                                    urban_intensity + manag_low + manag_high + light_pollution + noise_iq +
                                    cumdd_30 + father_cond + mother_cond + year,
                                  weights = clutch_size,
                                  data = ntits2, family = binomial,
                                  ziformula = ~1)
summary(ntitsFSy_ziglmm0) # The non-mixed model gives AIC = 990.9 while the mixed-model gave AIC = 970.4, so
# the use of the mixed model seems warranted by the data!

# # Importance of the fixed effects:
# ntitsFSy_ziglmm0 <- lme4::glmer(fledgling_nb/clutch_size ~ 1 + (1|id_nestbox),
#                              weights = clutch_size, data = ntits2, family = "binomial",
#                              control=lme4::glmerControl(optimizer="bobyqa",
#                                                         optCtrl=list(maxfun=2e5)))
# tictoc::tic("Parametric bootstrap LRT")
# res.LRT_re <- DHARMa::simulateLRT(m0 = ntitsFSy_ziglmm0, m1 = ntitsFSy_ziglmm1, n = 500, seed = 85)
# tictoc::toc() # DISCLAIMER: took ~1h45 to run!
# # The LRT is highly significant, suggesting that M1 better describes the data than M0!





### ** 3.1.3. Inference and predictions ----
# __________________________________________

##### TO BE RUN §§§ -----

### *** 3.1.3.1. Hypotheses testing: LRT for the additive and interactive effect of the F-metric ----
## For the additive effect of the connectivity metric:
ntitsFSy_ziglmm0 <- stats::update(ntitsFSy_ziglmm1, .~. -logged_Fmetric)

res.LRT_addeff <- pbkrtest::PBmodcomp(ntitsFSy_ziglmm1,
                                      ntitsFSy_ziglmm0, nsim = 500, seed = 56) # Took ~??? to run!
readr::write_csv2(x = res.LRT_addeff$test, file = here::here("output", "tables",
                                                             "res.ntitsFSy_LRT_addeff.csv"))
# The LRT is not significant, indicating that our connectivity metric does not improve the description of
# the data here.

## For the interaction effect:
# Since even the additive model is NOT SIGNIFICANT, there is no point in testing the effect of the
# interactive (mediated) model.



### *** 3.1.3.2. Bootstrapped confidence intervals for estimated parameters ----
tictoc::tic("Bootstrap CI for additive GLMM parameters")
res.ntitsFSy_addeff_CI_boot <- confint(ntitsFSy_ziglmm1, method="boot")
tt <- as.data.frame(res.ntitsFSy_addeff_CI_boot)
tt$parameters <- rownames(tt)
readr::write_csv2(x = tt,
                  file = here::here("output", "tables", "res.ntitsFSy_bootCI_addeff.csv"))
tictoc::toc() # DISCLAIMER: took ~1h45 to run!



### *** 3.1.3.3. Conclusion ----

summary(ntitsFSy_ziglmm1) # AIC = 970.4!
# Our models does not fit the data adequately. Moreover, our hypotheses were not validated and only three
# variables turned out significant: "mother_cond", "year2020" and "year2022" (but "woodyveg" could be too).
# The best model so far gave an AIC = 970.4.
# ALSO I should redo full-diags for the ZI model to find improvements??? AND/OR model fledg/brood!!!???





##### *-----------------------------------------------------------------* ######
##### * 3.2. Fledgling number: ZICOM-Poisson GLMM ------------------------------
# ---------------------------------------------------------------------------- #
### ** 3.2.1. Initial model fit ----
# __________________________________

# Given the look of the response variable and my previous diagnostics, I chose to directly compare various
# structural model types before even starting the dedicated diagnostics.

## Fitting a regular Poisson GLM:
ntitsFNy_glm1 <- stats::glm(fledgling_nb ~ logged_woodyveg + logged_Fmetric +
                           urban_intensity + manag_low + manag_high + light_pollution + noise_iq +
                           cumdd_30 + father_cond + mother_cond + year,
                         data = ntits2, family = "poisson")

## Fitting a regular Poisson GLMM:
ntitsFNy_glmm1 <- glmmTMB::glmmTMB(fledgling_nb ~ logged_woodyveg + logged_Fmetric + urban_intensity +
                                  manag_low + manag_high + light_pollution + noise_iq +
                                  cumdd_30 + father_cond + mother_cond + year + (1|id_nestbox),
                                data = ntits2, family = "poisson")

## Fitting a Zero-Inflated (ZI) Poisson GLMM:
ntitsFNy_ziglmm1 <- glmmTMB::glmmTMB(fledgling_nb ~ logged_woodyveg + logged_Fmetric + urban_intensity +
                                    manag_low + manag_high + light_pollution + noise_iq +
                                    cumdd_30 + father_cond + mother_cond + year + (1|id_nestbox),
                                  data = ntits2, family = "poisson",
                                  ziformula = ~1)

## Fitting a Zero-Inflated (ZI) COM-Poisson GLMM:
ntitsFNy_zicomglmm1 <- glmmTMB::glmmTMB(fledgling_nb ~ logged_woodyveg + logged_Fmetric + urban_intensity +
                                       manag_low + manag_high + light_pollution + noise_iq +
                                       cumdd_30 + father_cond + mother_cond + year + (1|id_nestbox),
                                     data = ntits2, family = glmmTMB::compois(link = "log"),
                                     dispformula = ~1,
                                     ziformula = ~1) # Rather long to fit.

summary(ntitsFNy_glm1) # AIC = 1430.8.
summary(ntitsFNy_glmm1) # AIC = 1408.4.
summary(ntitsFNy_ziglmm1) # AIC = 1182.4.
summary(ntitsFNy_zicomglmm1) # AIC = 1151.9.
# It seems that all sequential additional specifications improved the fit, albeit the inclusion of the
# COM-Poisson distribution only produced a mild effect. I will still use that model for diagnostics and see
# how it behaves.
ntitsFNy_zicomglmm2 <- glmmTMB::glmmTMB(fledgling_nb ~ logged_woodyveg + logged_Fmetric + urban_intensity +
                                       manag_low + manag_high + light_pollution + noise_iq +
                                       cumdd_30 + father_cond + mother_cond + year + (1|id_nestbox),
                                     data = ntits2, family = glmmTMB::compois(link = "log"),
                                     dispformula = ~logged_Fmetric,
                                     ziformula = ~manag_low) # Rather long to fit.
summary(ntitsFNy_zicomglmm2) # AIC = 1144.8 vs 1151.9.
# NOTE: After a few attempts to tune the model, I found that this specification slightly improved the model.
# But as it is a kind of data-dredging, I prefer carry on with my initially intended model. Still, I will
# perform diagnostics on both models. This 2nd model will be sometimes called "exploratory improved model".

# # The interactive (mediated) model:
# ntitsFNy_zicomglmm3 <- glmmTMB::glmmTMB(fledgling_nb ~
#                                        scale(logged_woodyveg, scale = F) * scale(logged_Fmetric,
#                                                                                  scale = F) +
#                                        urban_intensity + manag_low + manag_high + light_pollution + noise_iq +
#                                        cumdd_30 + father_cond + mother_cond + year + (1|id_nestbox),
#                                      data = ntits2, family = glmmTMB::compois(link = "log"),
#                                      dispformula = ~1,
#                                      ziformula = ~1) # Rather long to fit.
# summary(ntitsFNy_zicomglmm3) # AIC = 1152, doesn't seem supported by the data.





### ** 3.2.2. Diagnostics and assumption checks ----
# __________________________________________________

# IMPORTANT NOTE: all diagnostics have been performed on both ZICOM_GLMMs (1 and 2)!

### *** 3.2.2.1. Residuals extraction, autocorrelation and collinearity ----
## Traditional residuals:
par(.pardefault)
resid <- stats::resid(ntitsFNy_zicomglmm1, type = 'response')
plot(resid, id = 0.05, idLabels = ~.obs) # Ok-ish but there are a few potential outliers.
# performance::check_outliers(ntitsFNy_zicomglmm1) # Does not work for this type of model.
ntits2[which(resid < -4),] # As could have been guessed from the plot, the 2nd group (with the lowest
# residuals) consist of all the observations where "fledgling_nb" ~ 0. It could be a sign that the zero-part
# of the model should indeed be modelled with more relevant predictors. But even the "exploratory improved
# model" does not erase this pattern.

# To further investigate patterns, I can plot the residuals against some predictors:
plot(x = ntits2$logged_Fmetric, y = resid) # There may be signs of heteroscedasticity for the "F-metric".
# Otherwise, it seems ok (but, once again, simulated residuals will be more useful).
# plot(ntitsFNy_zicomglmm1, id_nestbox~stats::resid(.)) # Does not work for this type of model.
# plot(ntitsFNy_zicomglmm1, site~stats::resid(.)) # Does not work for this type of model.

## Simulation-based scaled residuals computation ({DHARMa} method):
simu.resid <- DHARMa::simulateResiduals(fittedModel = ntitsFNy_zicomglmm1, n = 1000, re.form = NULL)
simu.resid2 <- DHARMa::simulateResiduals(fittedModel = ntitsFNy_zicomglmm2, n = 1000, re.form = NULL)
# The 're.form' argument is to base simulations on the model unconditional of the random effects (and only
# works for {lme4} formulations). It is useful for testing dispersion (see below) but can be omitted
# eventually.
plot(simu.resid) # Ok_ish (but very slight deviation?).
DHARMa::outliers(simu.resid) # None.

## Autocorrelation and collinearity:
DHARMa::testSpatialAutocorrelation(simulationOutput = simu.resid,
                                   x = ntits2$coord_x, y = ntits2$coord_y, plot = TRUE) # Ok.
performance::check_autocorrelation(ntitsFNy_zicomglmm1) # Ok.
performance::check_collinearity(ntitsFNy_zicomglmm1) # Ok-ish, but "urban_intensity" > 4!
stats::vcov(ntitsFNy_zicomglmm1) # Ok.

## Heteroscedasticity and possible model misspecifications:
par(.pardefault)
DHARMa::plotResiduals(simu.resid, form = ntits2$logged_woodyveg)
DHARMa::plotResiduals(simu.resid, form = ntits2$logged_Fmetric)
DHARMa::plotResiduals(simu.resid, form = ntits2$urban_intensity)
DHARMa::plotResiduals(simu.resid, form = ntits2$manag_intensity)
DHARMa::plotResiduals(simu.resid, form = ntits2$light_pollution)
DHARMa::plotResiduals(simu.resid, form = ntits2$noise_iq) # Slight quantile deviation (also true for "model2")!
DHARMa::plotResiduals(simu.resid, form = ntits2$cumdd_30)
DHARMa::plotResiduals(simu.resid, form = ntits2$father_cond) # Slight quantile deviation!
DHARMa::plotResiduals(simu.resid, form = ntits2$mother_cond)
DHARMa::plotResiduals(simu.resid, form = ntits2$year)



### *** 3.2.2.2. Distribution (family, ZI, dispersion) ----
## Assessing over or under-dispersion:
aods3::gof(ntitsFNy_zicomglmm1) # Does not work for this type of model!
AER::dispersiontest(object = ntitsFNy_zicomglmm1, alternative = c("less")) # Does not work for this model type!
DHARMa::testDispersion(simu.resid) # Ok.

## Theoretical count distribution:
theo_count <- COMPoissonReg::rzicmp(n = nrow(ntits2), lambda = mean(ntits2$fledgling_nb),
                                    nu = 0.95,  # The 'nu' parameter should be chosen by trial-and-errors.
                                    p = 0.15) # And so does the probability of 0.
tc_df <- data.frame(theo_count)

ggplot2::ggplot(pm, ggplot2::aes(fledgling_nb)) +
  ggplot2::geom_bar(fill = "#1E90FF") +
  ggplot2::geom_bar(data = tc_df, ggplot2::aes(theo_count, fill="#1E90FF", alpha=0.5)) +
  ggplot2::theme_classic() +
  ggplot2::theme(legend.position = "none") # Blue = observed counts; red = simulated.
# This plot suggests that fledgling_nb could be following a COM-Poisson distribution of parameter nu~0.95,
# although that means that the dispersion is approximately equal to that of a regular Poisson.

## Distribution of the predicted counts:
pred_counts <- stats::predict(object = ntitsFNy_zicomglmm1, type = "response") # Extract the predicted counts.
par(mfrow= c(1,2))
hist(pred_counts)
hist(ntits2$fledgling_nb) # The "ntitsFNy_zicomglmm2" model yields better predictions than the simpler model
# but neither fit is truly satisfactory. Both models overestimate lower counts but fail to properly model
# the ZI!

## Zero-inflation (ZI):
simu.resid_woZI <- DHARMa::simulateResiduals(fittedModel = ntitsFNy_glmm1, n = 1000) # Model without ZI.
DHARMa::testZeroInflation(simu.resid) # Nope.
DHARMa::testZeroInflation(simu.resid_woZI) # Yes, so there truly is a ZI. Yet, this model accounts for it but
# cannot predict it.



### *** 3.2.2.3. Linearity ----
## Plotting the response on the log scale against predictors:
ntits2 %>% dplyr::select(woodyveg_vw, pmF_d60_beta0, urban_intensity, light_pollution, noise_iq, cumdd_30,
                      father_cond, mother_cond) %>%
  dplyr::mutate("Fmetric" = pmF_d60_beta0,
                "Fmetric (sqrt)" = sqrt(pmF_d60_beta0),
                "Fmetric (log)" = log10(pmF_d60_beta0),
                "woodyveg_vw" = woodyveg_vw,
                "woodyveg_vw (sqrt)" = sqrt(woodyveg_vw),
                "woodyveg_vw (log)" = log10(woodyveg_vw), .keep = "unused") -> mydata
predictors <- colnames(mydata)
# Bind log(Y) and tidying the data for plot (ggplot2, so long format):
mydata <- mydata %>%
  dplyr::mutate(log_y = log(ntits2$fledgling_nb+1)) %>%
  tidyr::gather(key = "predictors", value = "predictor.value", -log_y)
# Create scatterplot
ggplot2::ggplot(mydata, ggplot2::aes(y = log_y, x = predictor.value))+
  ggplot2::geom_point(size = 0.5, alpha = 0.5) +
  ggplot2::geom_smooth(method = "loess") +
  ggplot2::theme_bw() +
  ggplot2::facet_wrap(~predictors, scales = "free_x") # The linearity assumptions seems violated by several
# predictors: both "parental condition" variables and "noise_iq"! But this violation does not seem responsible
# for the lack of fit.



### *** 3.2.2.4. Model goodness-of-fit (GOF) and performances ----
# GOF test of Pearson's Chi2 residuals:
dat.resid <- sum(stats::resid(ntitsFNy_zicomglmm2, type = "pearson")^2)
1 - stats::pchisq(dat.resid, stats::df.residual(ntitsFNy_zicomglmm2)) # p ~ 0.32 for both models, indicating
# that there is no significant lack of fit. Keep in mind though that GOF measures for mixed models is an
# extremely complicated topic and interpretations are not straightforward.

# Computing a pseudo-R2:
performance::r2_nakagawa(ntitsFNy_zicomglmm1) # [Additive model]: Marg_R2_glmm = 0.04; Cond_R2_glmm = 0.04.
performance::r2(ntitsFNy_zicomglmm2) # Yields NA.

## Likelihood-ration tests (LRT) of GOF:
# For the random-effects (RE):
ntitsFNy_zicomglm2 <- glmmTMB::glmmTMB(fledgling_nb ~ logged_woodyveg + logged_Fmetric + urban_intensity +
                                      manag_low + manag_high + light_pollution + noise_iq +
                                      cumdd_30 + father_cond + mother_cond + year,
                                    data = ntits2, family = glmmTMB::compois(link = "log"),
                                    dispformula = ~logged_Fmetric,
                                    ziformula = ~manag_low) # Rather long to fit.
summary(ntitsFNy_zicomglm2) # AIC = 1143 vs 1144.8, so the inclusion of the RE does not seem warranted by the
# data. Still, we will keep using it as it is the originally intended model.

## For the whole model:
ntitsFNy_zicomglm0 <- glmmTMB::glmmTMB(fledgling_nb ~ 1,
                                    data = ntits2, family = glmmTMB::compois(link = "log"),
                                    dispformula = ~logged_Fmetric,
                                    ziformula = ~manag_low)
res.LRT_null <- stats::anova(object = ntitsFNy_zicomglm0, ntitsFNy_zicomglm2, test = "LRT")
# The test is significant, confirming that the model is useful to explain the data.



### *** 3.2.2.5. Posterior predictive simulations ----
# Predicted counts:
par(.pardefault)
obsprop <- prop.table(table(ntits2$fledgling_nb))
sims <- stats::simulate(ntitsFNy_zicomglmm2, nsim = 1000)

nsim0 <- colSums(sims == 0) # Number of zeros (min obs value)
par(las=1,bty="l")
plot(pt <- prop.table(table(nsim0)),
     ylab="Probability", xlab="Number of zeros")
(obs0 <- sum(ntits2$fledgling_nb == 0))
points(obs0, 0.16, col="red", pch=16, cex=2) # See the y (0.06) values in 'obsprop'!

nsim5 <- colSums(sims == 5) # Number of fives (second modal obs value).
par(las=1,bty="l")
plot(pt <- prop.table(table(nsim5)),
     ylab="Probability", xlab="Number of fives")
(obs5 <- sum(ntits2$fledgling_nb == 5))
points(obs5, 0.11, col="red", pch=16, cex=2)

nsim11 <- colSums(sims == 11) # Number of elevens (max obs value).
par(las=1,bty="l")
plot(pt <- prop.table(table(nsim11)),
     ylab="Probability", xlab="Number of elevens")
(obs11 <- sum(ntits2$fledgling_nb == 11))
points(obs11, 0.004, col="red", pch=16, cex=2)
# These three examples confirm that the model still predicts values that are too wide and overestimated
# compared to the true observed values. Small successes are not correctly predicted!



### ** 3.2.3. Inference and predictions ----
# __________________________________________

##### TO BE RUN §§§ -----

### *** 3.2.3.1. Hypotheses testing: LRT for the additive and interactive effect of the F-metric ----
## Parametric bootstrap to test the additive effect of the connectivity metric:
ntitsFNy_zicomglmm0 <- stats::update(ntitsFNy_zicomglmm1, .~. -logged_Fmetric)

tictoc::tic("Parametric bootstrap LRT for the additive effect")
res.LRT_inteff <- DHARMa::simulateLRT(m0 = ntitsFNy_zicomglmm0, m1 = ntitsFNy_zicomglmm1, n = 500, seed = 97)
tt <- as.data.frame(cbind(res.LRT_inteff$method,
                          res.LRT_inteff$data.name,
                          res.LRT_inteff$statistic,
                          res.LRT_inteff$p.value))
rownames(tt) <- NULL
tt %>% dplyr::rename("Method" = V1,
                     "Models" = V2,
                     "Log Likelihood (M1/M0)" = V3,
                     "p-value" = V4) -> tt
readr::write_csv2(x = tt, file = here::here("output", "tables", "res.ntitsFNy_LRT_addeff.csv"))
tictoc::toc() # DISCLAIMER: took ~??? to run!
# The PB-based LRT is XXX, indicating that our connectivity metric (does not?) improve the
# description of the data here.
# NOTE: initially, normally I would use the more efficient 'pbkrtest::PBmodcomp()' instead of the
# 'DHARMa::simulateLRT()' function, but it doesn't work with {glmmTMB} objects.


## Parametric bootstrap to test the interactive effect of the connectivity metric:
# To save some time, I don"t even bother computing the PB-based LRT for the interaction effect, it won't be
# significant. I should improve my proxies and my models first.



### *** 3.2.3.2. Bootstrapped confidence intervals for estimated parameters ----
tictoc::tic("Bootstrap CI for the additive COM-Poisson GLMM parameters")
res.ntitsFNy_addeff_CI_boot <- confint(ntitsFNy_zicomglmm1, method="boot")
tt <- as.data.frame(res.ntitsFNy_addeff_CI_boot)
tt$parameters <- rownames(tt)
readr::write_csv2(x = tt,
                  file = here::here("output", "tables", "res.ntitsFNy_bootCI_addeff.csv"))
tictoc::toc() # DISCLAIMER: took ~??? to run!



### *** 3.2.3.3. Conclusion ----

summary(ntitsFNy_zicomglmm1)
summary(ntitsFNy_zicomglmm2) # Exploratory improved model!
# The "ntitsFNy_zicomglmm2" model yielded better results than the simpler model but neither fit is truly
# satisfying. Both models overestimate lower counts but fail to properly model the ZI (it could be a sign of
# missing predictors)! Moreover, the linearity assumptions seems violated by several predictors: i.e. both
# "parental condition" variables and "noise_iq"!
# If the use of a ZICOM-Poisson regression strongly improved models predictive accuracy, it seems clear that
# the ZI is caused by another process. Possible leads for improvement could be to remove the possible outliers,
# merge observations, and try to improve the modelling of the dispersion (nu) and ZI parameters (or remove the
# zeros).
# As they are, unfortunately, the models do not support our hypotheses and only two predictors turned out
# significant in "ntitsFNy_zicomglmm1": "cumdd_30", and "year2022" (with AIC = 1151.9). However, the
# exploratory improved model suggest that our "F-metric" could be important to model the ZI and that
# "manag_low" could be important to model the dispersion (AIC = 1144.8 with "woodyveg" also significant)!





########################## ************************************************* ###############################
# ----------------------------------------------- #
##### 4. Modelling the morphometric variables #####
# ----------------------------------------------- #

##### * 4.1. Morphometry: LMM ---------------------------------------------------
# ---------------------------------------------------------------------------- #
### ** 4.1.1. Initial model fit ----
# __________________________________

## Creating a synthetic morphometric variable:
ntits2 %>% dplyr::filter(is.na(wing_length) == FALSE) -> ntits3 # Only 141 observations left.
ntits3 %>% dplyr::select(id_nestbox, site, mass, tarsus_length, wing_length) -> xxx

# Normed-PCA:
res.pca <- FactoMineR::PCA(X = xxx[, 3:ncol(xxx)], scale.unit = TRUE, graph = FALSE)
# To plot results:
morpho_pm.varplot <- factoextra::fviz_pca_var(res.pca, col.var = "contrib",
                                              gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
                                              repel = TRUE)
morpho_pm.indplot <- plot(res.pca, choix = "ind", autoLab = "yes")
#gridExtra::grid.arrange(morpho_pm.varplot, morpho_pm.indplot, ncol = 2)

# As the first axis (PC) of my PCA satisfactorily synthesizes a large amount of the variance (84.5%)
# of my three variables, we can use the coordinates of observations on this axis as a synthetic variable:
zzz <- res.pca$ind$coord[,1]
ntits3$morphometry <- zzz # This variable opposes nestboxes that host "big" (potentially well-fed) nestlings.


## Fitting a regular linear model:
ntitsMMy_lm1 <- stats::lm(morphometry ~ logged_woodyveg + logged_Fmetric +
                         urban_intensity + cumdd_30 + father_cond + mother_cond + year, data = ntits3)
# ntitsMMy_lm2 <- stats::lm(morphometry ~ scale(logged_woodyveg, scale = F) * scale(logged_Fmetric,
#                                                                                   scale = F) +
#                            urban_intensity + year, data = ntits3) # Interaction not significant!


## Fitting an additive LMM:
ntitsMMy_lmm1 <- lme4::lmer(morphometry ~ logged_woodyveg + logged_Fmetric + urban_intensity +
                           cumdd_30 + year + (1|id_nestbox), data = ntits3)
# Gives a singular fit (RE variance = 0). I'll thus try setting a weak prior on the variance:
ntitsMMy_blmm1 <- blme::blmer(morphometry ~ logged_woodyveg + logged_Fmetric + urban_intensity +
                             cumdd_30 + year + (1|id_nestbox), data = ntits3)
# As there are convergence issues, I change the optimizer and increase iterations:
ntitsMMy_blmm2 <- stats::update(ntitsMMy_blmm1, control=lme4::lmerControl(optimizer="bobyqa",
                                                                    optCtrl=list(maxfun=2e5)))
# # Try all optimizers:
# ntitsMMy_blmm2_all <- lme4::allFit(ntitsMMy_blmm2)
# summary(ntitsMMy_blmm2_all) # Two optimizers failed to converge but give rather similar results, except the
# # "nloptwrap.NLOPT_LN_BOBYQA" optimizer that computes a larger RE variance and thus, lower coefficient
# # estimates. We will thus stick with "bobyqa".

## Fitting interactive (mediated) LMMs:
ntitsMMy_blmm3 <- blme::blmer(morphometry ~
                             scale(logged_woodyveg, scale = F) * scale(logged_Fmetric, scale = F) +
                             urban_intensity + cumdd_30 + year + (1|id_nestbox), data = ntits3,
                           control=lme4::lmerControl(optimizer="bobyqa",
                                                     optCtrl=list(maxfun=2e5)))
# # Test by removing possible overly influential observations:
# ntits2_wo <- ntits2[-c(49,58,50,143),]
# ntitsFSy_glmm3_wo <- stats::update(ntitsFSy_glmm3, data=ntits2_wo)
# summary(ntitsFSy_glmm3)$AIC
# summary(ntitsFSy_glmm3_wo)$AIC # Strongly improved AIC, BIC, and deviance. However, it yields lower R2_glmm!





### ** 4.1.2. Diagnostics and assumption checks ----
# __________________________________________________

### *** 4.1.2.1. Residuals extraction, autocorrelation and collinearity ----
## Extracting residuals (with the {redres}):
raw_cond <- redres::compute_redres(ntitsMMy_blmm3) # Computes the raw conditional residuals (conditional on
# the random effects (RE)).
pearson_mar <- redres::compute_redres(ntitsMMy_blmm3, type = "pearson_mar") # Computes the Pearson marginal
# (not accounting for the RE) residuals.
std_cond <- redres::compute_redres(ntitsMMy_blmm3, type = "std_cond") # Computes the studentised cond. ones.
# Joins the residuals to the paprika data:
xxx <- cbind(ntits3, raw_cond, pearson_mar, std_cond)

## Simulation-based scaled residuals computation (DHARMa method):
simu.resid <- DHARMa::simulateResiduals(fittedModel = ntitsMMy_blmm3, n = 1000, plot = FALSE)
par(.pardefault)
plot(simu.resid) # Ok.

## Autocorrelation and collinearity:
DHARMa::testSpatialAutocorrelation(simulationOutput = simu.resid,
                                   x = ntits3$coord_x, y = ntits3$coord_y, plot = TRUE) # Ok.
performance::check_autocorrelation(ntitsMMy_blmm3) # Ok.
performance::check_collinearity(ntitsMMy_blmm3) # Ok.
stats::vcov(ntitsMMy_blmm3) # Ok, but "cumdd_30" has a slightly high covariance with the intercept.



### *** 4.1.2.2. Distribution and homoscedasticity ----
## Assessing the normality of the residuals:
stats::shapiro.test(xxx$raw_cond) # Significant deviation from normality detected, but the Shapiro test is
# known to be extremely sensitive. So plotting would be better:
xxx %>%
  tidyr::gather(key = "type", value = "residual", 30:32) %>%
  ggplot2::ggplot(ggplot2::aes(x = residual)) +
  ggplot2::geom_histogram(bins = 20) +
  ggplot2::facet_grid(. ~ type, scales = "free") +
  ggplot2::theme_bw() # The residuals are indeed slightly left-skewed and possibly lack kurtosis but that
# could be acceptable.
redres::plot_resqq(ntitsMMy_blmm3) # As expected, the plot shows a substantial departure from Normality at the
# extreme ends of the quantiles, that is at the border of the parameters space. Overall, as almost all
# points stay within the 95% CI, we can say it is ok-ish.

## Assessing the normality if the random effect:
redres::plot_ranef(ntitsMMy_blmm3) # Same thing here.

## Assessing homogeneity of variance and influential observations:
plot(ntitsMMy_blmm3, type=c("p","smooth"), col.line = 2, id = 0.05, idLabels = ~.obs) # A slight curvature
# seem to exist and there are 5 possible outliers. Otherwise, there is no clear heteroscedasticity.
ntits3[c(10,86,46,97,61),] # RAS.

# Residuals vs leverage:
plot(ntitsMMy_blmm3, stats::rstudent(.) ~ stats::hatvalues(.))
cd <- stats::cooks.distance(ntitsMMy_blmm3)
plot(cd)
ntits3[which(cd>0.4),] # Ok, all observations are < 0.5, so no overly influential points.
ntits3[which(cd>0.15),] # If we pick very conservative values, we find the same obs as before.

## Residuals vs predictors:
redres::plot_redres(ntitsMMy_blmm3, xvar = "scale(logged_Fmetric, scale = F)") +
  ggplot2::geom_smooth(method = "loess") +
  ggplot2::theme_classic() +
  ggplot2::labs(title = "Residual vs F-metric (log scale)") # Plotting residuals against the predictors
# does not give much odd results, but emphasized the incomplete sampling of the predictor
# space for some variables such as the F-metric.
# plot(ntits3$logged_Fmetric, stats::residuals(ntitsMMy_blmm3)) # Same plot (I should create a
# custom function).
redres::plot_redres(ntitsMMy_blmm3, type = "raw_mar", xvar = "year")

## Distribution of the predicted values:
par(.pardefault)
predictions <- stats::predict(object = ntitsMMy_blmm3, type = "response") # Extract the predicted values.
par(mfrow= c(1,2))
hist(predictions)
plot(ecdf(predictions))
fitdistrplus::plotdist(data = ntits3$morphometry, histo = TRUE, demp = TRUE) # Ok-ish...



### *** 4.1.2.3. Linearity ----
## Plotting the response on the logit scale (= log odds) against predictors:
# Format data:
ntits3 %>% dplyr::select(woodyveg_vw, pmF_d60_beta0, urban_intensity, light_pollution, noise_iq, cumdd_30,
                      father_cond, mother_cond) %>%
  dplyr::mutate("Fmetric" = pmF_d60_beta0,
                "Fmetric (log)" = log10(pmF_d60_beta0),
                "woodyveg_vw" = woodyveg_vw,
                "woodyveg_vw (log)" = log10(woodyveg_vw), .keep = "unused") -> mydata
predictors <- colnames(mydata)
# Bind 'morphometry' and tidying the data for plot (ggplot2, so long format):
mydata <- mydata %>%
  dplyr::mutate(morphometry = ntits3$morphometry) %>%
  tidyr::gather(key = "predictors", value = "predictor.value", -morphometry)
# Create scatterplot
ggplot2::ggplot(mydata, ggplot2::aes(y = morphometry, x = predictor.value))+
  ggplot2::geom_point(size = 0.5, alpha = 0.5) +
  ggplot2::geom_smooth(method = "loess") +
  ggplot2::theme_bw() +
  ggplot2::facet_wrap(~predictors, scales = "free_x") # We can see that the slight curvature seems to come
# from "urban_intensity" and it seems that log-transforming "woodyveg_vw" might not be such a good idea here
# as it enables an abnormal distortion effect of its lowest value (try without?). Otherwise ok!



### *** 4.1.2.4. Goodness-of-fit (GOF) and performances ----
## Computing a pseudo-R2:
performance::r2_nakagawa(ntitsMMy_blmm2) # [Additive model]: Marg_R2_lmm = 0.31; Cond_R2_lmm = 0.38.
performance::r2_nakagawa(ntitsMMy_blmm3) # [Interact. model]: Marg_R2_lmm = 0.31; Cond_R2_lmm = 0.38.

## Likelihood-ration tests (LRT) of GOF:
# Importance of the "id_nestbox" random-effect (RE):
tictoc::tic("Parametric bootstrap LRT")
res.LRT_re <- DHARMa::simulateLRT(m0 = ntitsMMy_lm1, m1 = ntitsMMy_blmm2, n = 500, seed = 24)
tictoc::toc() # Took ~23s to run.
# The LRT is significant, suggesting that M1 better describes the data than M0, supporting the importance of
# the random effect!

# Importance of the fixed effects (only using the LM):
ntitsMMy_lm0 <- stats::lm(morphometry ~ 1, data = ntits3)
res.LRT_null <- stats::anova(object = ntitsMMy_lm0, ntitsMMy_lm1, test = "LRT")
# The test is highly significant, confirming that the model is useful to explain the data.





### ** 4.1.3. Inference and predictions ----
# __________________________________________

### *** 4.1.3.1. Hypotheses testing: LRT for the additive and interactive effect of the F-metric ----
## For the additive effect of the connectivity metric:
ntitsMMy_blmm1 <- stats::update(ntitsMMy_blmm2, .~. -logged_Fmetric)

res.LRT_addeff <- pbkrtest::PBmodcomp(ntitsMMy_blmm2,
                                      ntitsMMy_blmm1, nsim = 1000, seed = 399) # Took ~85s to run!
readr::write_csv2(x = res.LRT_addeff$test, file = here::here("output", "tables",
                                                             "res.ntitsMMy_LRT_addeff.csv"))
# The LRT is significant, indicating that our connectivity metric does improve the description of the data.


## For the interaction effect:
res.LRT_inteff <- pbkrtest::PBmodcomp(ntitsMMy_blmm3,
                                      ntitsMMy_blmm2, nsim = 1000, seed = 428) # Took ~67s to run!
readr::write_csv2(x = res.LRT_inteff$test, file = here::here("output", "tables",
                                                             "res.ntitsMMy_LRT_inteff.csv"))
# The LRT is NOT significant, indicating that our hypothesis of an interaction effect is not supported
# by the data.



### *** 4.1.3.2. Bootstrapped confidence intervals for estimated parameters ----
tictoc::tic("Bootstrap CI for additive LMM parameters")
res.ntitsMMy_addeff_CI_boot <- confint(ntitsMMy_blmm2, method="boot")
tt <- as.data.frame(res.ntitsMMy_addeff_CI_boot)
tt$parameters <- rownames(tt)
readr::write_csv2(x = tt,
                  file = here::here("output", "tables", "res.ntitsMMy_bootCI_addeff.csv"))
tictoc::toc() # DISCLAIMER: took ~17,7s to run!



### *** 4.1.3.3. Conclusion ----

summary(ntitsMMy_blmm2)
# Our models only moderately fit the observed data. Nonetheless, the importance of the additive effect of
# connectivity is supported by both the parametric bootstrap LRT and the CI on the parameters.
# Diagnostics indicated that removing some influential observations as well as the lowest "woodyveg_vw"
# value (or un-loging it) could perhaps have an impact on the results.
# REMINDER: there are less variables because the sample size is smaller!





######################### *----------------------* #############################
##### * 4.2. Mass: LMM ---------------------------------------------------------
# ---------------------------------------------------------------------------- #
### ** 4.2.1. Initial model fit ----
# __________________________________

## Fitting a regular linear model:
ntits2 %>% dplyr::filter(is.na(mass) == FALSE) -> ntits3 # Only 213 observations left.

ntitsMAy_lm1 <- stats::lm(mass ~ logged_woodyveg + logged_Fmetric +
                         urban_intensity + manag_low + manag_high + light_pollution + noise_iq +
                         cumdd_30 + father_cond + mother_cond + year, data = ntits3)
# ntitsMAy_lm2 <- stats::lm(mass ~ scale(logged_woodyveg, scale = F) * scale(logged_Fmetric, scale = F) +
#                          urban_intensity + manag_low + manag_high + light_pollution + noise_iq +
#                          cumdd_30 + father_cond + mother_cond + year, data = ntits3)
# # Interaction not significant!


## Fitting an additive LMM:
ntitsMAy_lmm1 <- lme4::lmer(mass ~ logged_woodyveg + logged_Fmetric +
                           urban_intensity + manag_low + manag_high + light_pollution + noise_iq +
                           cumdd_30 + father_cond + mother_cond + year + (1|id_nestbox), data = ntits3,
                         control=lme4::lmerControl(optimizer="bobyqa",
                                                   optCtrl=list(maxfun=2e5))) # Works even without
# increasing the number of iterations or changing the optimizer.
ntitsMAy_lmm2 <- ntitsMAy_lmm1 # Only to keep "model2" as my additive model and "model3" as my interactive one.

## Fitting interactive (mediated) LMMs:
ntitsMAy_lmm3 <- lme4::lmer(mass ~
                           scale(logged_woodyveg, scale = F) * scale(logged_Fmetric, scale = F) +
                           urban_intensity + manag_low + manag_high + light_pollution + noise_iq +
                           cumdd_30 + father_cond + mother_cond + year + (1|id_nestbox), data = ntits3,
                         control=lme4::lmerControl(optimizer="bobyqa",
                                                   optCtrl=list(maxfun=2e5)))
# # Test by removing possible overly influential observations:
# ntits2_wo <- ntits2[-c(49,58,50,143),]
# ntitsFSy_glmm3_wo <- stats::update(ntitsFSy_glmm3, data=ntits2_wo)
# summary(ntitsFSy_glmm3)$AIC
# summary(ntitsFSy_glmm3_wo)$AIC # Strongly improved AIC, BIC, and deviance. However, it yields lower R2_glmm!





### ** 4.2.2. Diagnostics and assumption checks ----
# __________________________________________________

### *** 4.2.2.1. Residuals extraction, autocorrelation and collinearity ----
## Extracting residuals (with the {redres}):
raw_cond <- redres::compute_redres(ntitsMAy_lmm3) # Computes the raw conditional residuals (conditional on
# the random effects (RE)).
pearson_mar <- redres::compute_redres(ntitsMAy_lmm3, type = "pearson_mar") # Computes the Pearson marginal
# (not accounting for the RE) residuals.
std_cond <- redres::compute_redres(ntitsMAy_lmm3, type = "std_cond") # Computes the studentised cond. ones.
# Joins the residuals to the paprika data:
xxx <- cbind(ntits3, raw_cond, pearson_mar, std_cond)

## Simulation-based scaled residuals computation (DHARMa method):
simu.resid <- DHARMa::simulateResiduals(fittedModel = ntitsMAy_lmm3, n = 1000, plot = FALSE)
par(.pardefault)
plot(simu.resid) # Ok.

## Autocorrelation and collinearity:
DHARMa::testSpatialAutocorrelation(simulationOutput = simu.resid,
                                   x = ntits3$coord_x, y = ntits3$coord_y, plot = TRUE) # Ok.
performance::check_autocorrelation(ntitsMAy_lmm3) # Ok.
performance::check_collinearity(ntitsMAy_lmm3) # Ok-ish but "urban_intensity" has a VIF of 4.2!
stats::vcov(ntitsMAy_lmm3) # Ok, but "cumdd_30" has a slightly high covariance with the intercept.



### *** 4.2.2.2. Distribution and homoscedasticity ----
## Assessing the normality of the residuals:
stats::shapiro.test(xxx$raw_cond) # Ok. But plotting would be better:
xxx %>%
  tidyr::gather(key = "type", value = "residual", 29:31) %>%
  ggplot2::ggplot(ggplot2::aes(x = residual)) +
  ggplot2::geom_histogram(bins = 20) +
  ggplot2::facet_grid(. ~ type, scales = "free") +
  ggplot2::theme_bw() # The residuals indeed look ok.
redres::plot_resqq(ntitsMAy_lmm3) # As expected, the plot shows a substantial departure from Normality at the
# extreme ends of the quantiles, that is at the border of the parameters space. Overall, as almost all
# points stay within the 95% CI, we can say it is ok-ish.

## Assessing the normality if the random effect:
redres::plot_ranef(ntitsMAy_lmm3) # Same thing here.

## Assessing homogeneity of variance and influential observations:
plot(ntitsMAy_lmm3, type=c("p","smooth"), col.line = 2, id = 0.05, idLabels = ~.obs) # It's ok but there
# seems to be 8 possible outliers:
ntits3[c(22,97),] # High residuals ~= heavy juveniles. RAS.
ntits3[c(156, 112, 169, 133, 110, 127),] # Low residuals ~= light juveniles. RAS.

# Residuals vs leverage:
plot(ntitsMAy_lmm3, stats::rstudent(.) ~ stats::hatvalues(.))
cd <- stats::cooks.distance(ntitsMAy_lmm3)
plot(cd)
ntits3[which(cd>0.4),] # Ok, all observations are < 0.5, so no overly influential points.
ntits3[which(cd>0.1),] # Even with very conservative values, we only find obs #127 (DIJ-168_2020).

## Residuals vs predictors:
redres::plot_redres(ntitsMAy_lmm3, xvar = "mother_cond") +
  ggplot2::geom_smooth(method = "loess") +
  ggplot2::theme_classic() +
  ggplot2::labs(title = "Residual vs predictor") # Ok for most, acceptable for some.
# plot(ntits3$logged_Fmetric, stats::residuals(ntitsMAy_lmm3)) # Same plot (I should create a
# custom function).
redres::plot_redres(ntitsMAy_lmm3, type = "raw_mar", xvar = "year") # Ok.

## Distribution of the predicted values:
par(.pardefault)
predictions <- stats::predict(object = ntitsMAy_lmm3, type = "response") # Extract the predicted values.
par(mfrow= c(1,2))
hist(predictions)
plot(ecdf(predictions))
fitdistrplus::plotdist(data = ntits3$mass, histo = TRUE, demp = TRUE) # Rather ok.



### *** 4.2.2.3. Linearity ----
## Plotting the response on the logit scale (= log odds) against predictors:
# Format data:
ntits3 %>% dplyr::select(woodyveg_vw, pmF_d60_beta0, urban_intensity, light_pollution, noise_iq, cumdd_30,
                      father_cond, mother_cond) %>%
  dplyr::mutate("Fmetric" = pmF_d60_beta0,
                "Fmetric (log)" = log10(pmF_d60_beta0),
                "woodyveg_vw" = woodyveg_vw,
                "woodyveg_vw (log)" = log10(woodyveg_vw),
                "woodyveg_vw (sqrt)" = sqrt(woodyveg_vw), .keep = "unused") -> mydata
predictors <- colnames(mydata)
# Bind 'mass' and tidying the data for plot (ggplot2, so long format):
mydata <- mydata %>%
  dplyr::mutate(mass = ntits3$mass) %>%
  tidyr::gather(key = "predictors", value = "predictor.value", -mass)
# Create scatterplot
ggplot2::ggplot(mydata, ggplot2::aes(y = mass, x = predictor.value))+
  ggplot2::geom_point(size = 0.5, alpha = 0.5) +
  ggplot2::geom_smooth(method = "loess") +
  ggplot2::theme_bw() +
  ggplot2::facet_wrap(~predictors, scales = "free_x") # Interestingly, we can see that for several
# predictors, extreme values tend to distort relationships that would perhaps otherwise be significant. It
# also appears here that the log-transformation of "woodyveg" is maybe counter-productive: a spline would
# certainly be better OR, as shown here, a square-root transformation!
# We can also see that "urban_intensity" present a curved relationship with "mass" (and so does "cumdd_30")!




### *** 4.2.2.4. Goodness-of-fit (GOF) and performances ----
## Computing a pseudo-R2:
performance::r2_nakagawa(ntitsMAy_lmm2) # [Additive model]: Marg_R2_lmm = 0.19; Cond_R2_lmm = 0.23.
performance::r2_nakagawa(ntitsMAy_lmm3) # [Interact. model]: Marg_R2_lmm = 0.20; Cond_R2_lmm = 0.22.

## Likelihood-ration tests (LRT) of GOF:
# Importance of the "id_nestbox" random-effect (RE):
tictoc::tic("Parametric bootstrap LRT")
res.LRT_re <- DHARMa::simulateLRT(m0 = ntitsMAy_lm1, m1 = ntitsMAy_lmm2, n = 500, seed = 762)
tictoc::toc() # Took ~11s to run.
# The LRT is significant, suggesting that M1 better describes the data than M0, supporting the importance of
# the random effect!

# Importance of the fixed effects (only using the LM):
ntitsMAy_lm0 <- stats::lm(mass ~ 1, data = ntits3)
res.LRT_null <- stats::anova(object = ntitsMAy_lm0, ntitsMAy_lm1, test = "LRT")
# The test is highly significant, confirming that the model is useful to explain the data.





### ** 4.2.3. Inference and predictions ----
# __________________________________________

### *** 4.2.3.1. Hypotheses testing: LRT for the additive and interactive effect of the F-metric ----
## For the additive effect of the connectivity metric:
ntitsMAy_lmm1 <- stats::update(ntitsMAy_lmm2, .~. -logged_Fmetric)

res.LRT_addeff <- pbkrtest::PBmodcomp(ntitsMAy_lmm2,
                                      ntitsMAy_lmm1, nsim = 1000, seed = 22) # Took ~34s to run!
readr::write_csv2(x = res.LRT_addeff$test, file = here::here("output", "tables",
                                                             "res.ntitsMAy_LRT_addeff.csv"))
# The LRT is significant, indicating that our connectivity metric does improve the description of the data.


## For the interaction effect:
res.LRT_inteff <- pbkrtest::PBmodcomp(ntitsMAy_lmm3,
                                      ntitsMAy_lmm2, nsim = 1000, seed = 253) # Took ~31s to run!
readr::write_csv2(x = res.LRT_inteff$test, file = here::here("output", "tables",
                                                             "res.ntitsMAy_LRT_inteff.csv"))
# The LRT is NOT significant, indicating that our hypothesis of an interaction effect is not supported
# by the data.



### *** 4.2.3.2. Bootstrapped confidence intervals for estimated parameters ----
tictoc::tic("Bootstrap CI for additive LMM parameters")
res.ntitsMAy_addeff_CI_boot <- confint(ntitsMAy_lmm2, method="boot")
tt <- as.data.frame(res.ntitsMAy_addeff_CI_boot)
tt$parameters <- rownames(tt)
readr::write_csv2(x = tt,
                  file = here::here("output", "tables", "res.ntitsMAy_bootCI_addeff.csv"))
tictoc::toc() # DISCLAIMER: took ~7s to run!



### *** 4.2.3.3. Conclusion ----

summary(ntitsMAy_lmm2)
# Our models fit the observed data relatively well. The importance of the additive effect of connectivity
# is supported by both the parametric bootstrap LRT and the CI on the parameters. An optimist would even
# say that the PB-based LRT for the interactive effect is close to be meaningful. We also saw, again, that
# there is a clear "year" effect!
# Anyway, diagnostics indicated that there are room for improvements: removing outliers, changing the
# transformation of some variables, accounting for possible curvature effects...





#################### *----------------------------------* ######################
##### * 4.3. Tarsus length: LMM ------------------------------------------------
# ---------------------------------------------------------------------------- #
### ** 4.3.1. Initial model fit ----
# __________________________________

## Fitting a regular linear model:
ntits2 %>% dplyr::filter(is.na(tarsus_length) == FALSE) -> ntits3 # Only 173 observations left.

ntitsTLy_lm1 <- stats::lm(tarsus_length ~ logged_woodyveg + logged_Fmetric +
                         urban_intensity + manag_low + manag_high + cumdd_30 + year, data = ntits3)
# ntitsTLy_lm2 <- stats::lm(tarsus_length ~ scale(logged_woodyveg, scale = F) * scale(logged_Fmetric,
#                                                                                     scale = F) +
#                          urban_intensity + manag_low + manag_high + cumdd_30 + year,
#                        data = ntits3) # Interaction not significant!


## Fitting an additive LMM:
ntitsTLy_lmm1 <- lme4::lmer(tarsus_length ~ logged_woodyveg + logged_Fmetric +
                           urban_intensity + manag_low + manag_high + cumdd_30 + year +
                           (1|id_nestbox), data = ntits3,
                         control=lme4::lmerControl(optimizer="bobyqa",
                                                   optCtrl=list(maxfun=2e5))) # Works even without
# increasing the number of iterations or changing the optimizer.
ntitsTLy_lmm2 <- ntitsTLy_lmm1 # Only to keep "model2" as my additive model and "model3" as my interactive one.

## Fitting interactive (mediated) LMMs:
ntitsTLy_lmm3 <- lme4::lmer(tarsus_length ~
                           scale(logged_woodyveg, scale = F) * scale(logged_Fmetric, scale = F) +
                           urban_intensity + manag_low + manag_high + cumdd_30 + year +
                           (1|id_nestbox), data = ntits3,
                         control=lme4::lmerControl(optimizer="bobyqa",
                                                   optCtrl=list(maxfun=2e5)))
# # Test by removing possible overly influential observations:
# ntits2_wo <- ntits2[-c(49,58,50,143),]
# ntitsFSy_glmm3_wo <- stats::update(ntitsFSy_glmm3, data=ntits2_wo)
# summary(ntitsFSy_glmm3)$AIC
# summary(ntitsFSy_glmm3_wo)$AIC # Strongly improved AIC, BIC, and deviance. However, it yields lower R2_glmm!





### ** 4.3.2. Diagnostics and assumption checks ----
# __________________________________________________

### *** 4.3.2.1. Residuals extraction, autocorrelation and collinearity ----
## Extracting residuals (with the {redres}):
raw_cond <- redres::compute_redres(ntitsTLy_lmm3) # Computes the raw conditional residuals (conditional on
# the random effects (RE)).
pearson_mar <- redres::compute_redres(ntitsTLy_lmm3, type = "pearson_mar") # Computes the Pearson marginal
# (not accounting for the RE) residuals.
std_cond <- redres::compute_redres(ntitsTLy_lmm3, type = "std_cond") # Computes the studentised cond. ones.
# Joins the residuals to the paprika data:
xxx <- cbind(ntits3, raw_cond, pearson_mar, std_cond)

## Simulation-based scaled residuals computation (DHARMa method):
simu.resid <- DHARMa::simulateResiduals(fittedModel = ntitsTLy_lmm3, n = 1000, plot = FALSE)
par(.pardefault)
plot(simu.resid) # Slight deviation and outliers detected!

## Autocorrelation and collinearity:
DHARMa::testSpatialAutocorrelation(simulationOutput = simu.resid,
                                   x = ntits3$coord_x, y = ntits3$coord_y, plot = TRUE) # Ok.
performance::check_autocorrelation(ntitsTLy_lmm3) # Ok.
performance::check_collinearity(ntitsTLy_lmm3) # Ok-ish but "urban_intensity" has a VIF of 3.8!
stats::vcov(ntitsTLy_lmm3) # Ok.



### *** 4.3.2.2. Distribution and homoscedasticity ----
## Assessing the normality of the residuals:
stats::shapiro.test(xxx$raw_cond) # Significant deviation from normality detected, but the Shapiro test is
# known to be extremely sensitive. So plotting would be better:
xxx %>%
  tidyr::gather(key = "type", value = "residual", 29:31) %>%
  ggplot2::ggplot(ggplot2::aes(x = residual)) +
  ggplot2::geom_histogram(bins = 20) +
  ggplot2::facet_grid(. ~ type, scales = "free") +
  ggplot2::theme_bw() # The residuals are indeed a bit left-skewed, but it may be acceptable.
redres::plot_resqq(ntitsTLy_lmm3) # As expected, the plot shows a substantial departure from Normality at the
# extreme ends of the quantiles, that is at the border of the parameters space. While it is acceptable for
# the upper quantiles, the departure is quite worrisome for the lower ones.

## Assessing the normality if the random effect:
redres::plot_ranef(ntitsTLy_lmm3) # Ok-ish.

## Assessing homogeneity of variance and influential observations:
plot(ntitsTLy_lmm3, type=c("p","smooth"), col.line = 2, id = 0.05, idLabels = ~.obs) # It's ok but there
# seems to be 3 possible outliers:
ntits3[c(13,129,82),] # Low residuals ~= short juveniles. RAS.

# Residuals vs leverage:
plot(ntitsTLy_lmm3, stats::rstudent(.) ~ stats::hatvalues(.))
cd <- stats::cooks.distance(ntitsTLy_lmm3)
plot(cd)
ntits3[which(cd>0.4),] # Ok, all observations are < 0.5, so no overly influential points.
ntits3[which(cd>0.1),] # Even with very conservative values, we find the same three observations.

## Residuals vs predictors:
redres::plot_redres(ntitsTLy_lmm3, xvar = "scale(logged_woodyveg, scale = F)") +
  ggplot2::geom_smooth(method = "loess") +
  ggplot2::theme_classic() +
  ggplot2::labs(title = "Residual vs predictor") # Ok for most, acceptable for some.
# plot(ntits3$logged_Fmetric, stats::residuals(ntitsTLy_lmm3)) # Same plot (I should create a
# custom function).
redres::plot_redres(ntitsTLy_lmm3, type = "raw_mar", xvar = "year") # Ok.

## Distribution of the predicted values:
par(.pardefault)
ntits3$predictions <- stats::predict(object = ntitsTLy_lmm3, type = "response") # Extract the predicted values.
fitdistrplus::plotdist(data = ntits3$predictions, histo = TRUE, demp = TRUE)
fitdistrplus::plotdist(data = ntits3$tarsus_length, histo = TRUE, demp = TRUE) # Could be better.



### *** 4.3.2.3. Linearity ----
## Plotting the response on the logit scale (= log odds) against predictors:
# Format data:
ntits3 %>% dplyr::select(woodyveg_vw, pmF_d60_beta0, urban_intensity, cumdd_30) %>%
  dplyr::mutate("Fmetric" = pmF_d60_beta0,
                "Fmetric (log)" = log10(pmF_d60_beta0),
                "woodyveg_vw" = woodyveg_vw,
                "woodyveg_vw (log)" = log10(woodyveg_vw),
                "woodyveg_vw (sqrt)" = sqrt(woodyveg_vw), .keep = "unused") -> mydata
predictors <- colnames(mydata)
# Bind 'tarsus_length' and tidying the data for plot (ggplot2, so long format):
mydata <- mydata %>%
  dplyr::mutate(tarsus_length = ntits3$tarsus_length) %>%
  tidyr::gather(key = "predictors", value = "predictor.value", -tarsus_length)
# Create scatterplot
ggplot2::ggplot(mydata, ggplot2::aes(y = tarsus_length, x = predictor.value))+
  ggplot2::geom_point(size = 0.5, alpha = 0.5) +
  ggplot2::geom_smooth(method = "loess") +
  ggplot2::theme_bw() +
  ggplot2::facet_wrap(~predictors, scales = "free_x") # Interestingly, we can see that for several
# predictors, extreme values tend to distort relationships that would perhaps otherwise be significant. It
# also appears here that the log-transformation of "woodyveg" is maybe counter-productive: a spline would
# certainly be better OR, as shown here, a square-root transformation!
# We can also see that "urban_intensity" present a curved relationship with "tarsus_length"!




### *** 4.3.2.4. Goodness-of-fit (GOF) and performances ----
## Computing a pseudo-R2:
performance::r2_nakagawa(ntitsTLy_lmm2) # [Additive model]: Marg_R2_lmm = 0.2; Cond_R2_lmm = 0.23.
performance::r2_nakagawa(ntitsTLy_lmm3) # [Interact. model]: Marg_R2_lmm = 0.2; Cond_R2_lmm = 0.23.

## Likelihood-ration tests (LRT) of GOF:
# Importance of the "id_nestbox" random-effect (RE):
tictoc::tic("Parametric bootstrap LRT")
res.LRT_re <- DHARMa::simulateLRT(m0 = ntitsTLy_lm1, m1 = ntitsTLy_lmm2, n = 500, seed = 762)
tictoc::toc() # Took ~10s to run.
# The LRT is significant, suggesting that M1 better describes the data than M0, supporting the importance of
# the random effect!

# Importance of the fixed effects (only using the LM):
ntitsTLy_lm0 <- stats::lm(tarsus_length ~ 1, data = ntits3)
res.LRT_null <- stats::anova(object = ntitsTLy_lm0, ntitsTLy_lm1, test = "LRT")
# The test is highly significant, confirming that the model is useful to explain the data.





### ** 4.3.3. Inference and predictions ----
# __________________________________________

### *** 4.3.3.1. Hypotheses testing: LRT for the additive and interactive effect of the F-metric ----
## For the additive effect of the connectivity metric:
ntitsTLy_lmm1 <- stats::update(ntitsTLy_lmm2, .~. -logged_Fmetric)

res.LRT_addeff <- pbkrtest::PBmodcomp(ntitsTLy_lmm2,
                                      ntitsTLy_lmm1, nsim = 1000, seed = 129) # Took ~42s to run!
readr::write_csv2(x = res.LRT_addeff$test, file = here::here("output", "tables",
                                                             "res.ntitsTLy_LRT_addeff.csv"))
# The LRT is ALMOST significant, indicating that our connectivity metric might be useful to improve the
# description of the data but that our models are not powerful enough to confirm it.


## For the interaction effect:
res.LRT_inteff <- pbkrtest::PBmodcomp(ntitsTLy_lmm3,
                                      ntitsTLy_lmm2, nsim = 1000, seed = 20) # Took ~32s to run!
readr::write_csv2(x = res.LRT_inteff$test, file = here::here("output", "tables",
                                                             "res.ntitsTLy_LRT_inteff.csv"))
# The LRT is NOT significant, indicating that our hypothesis of an interaction effect is not supported
# by the data.



### *** 4.3.3.2. Bootstrapped confidence intervals for estimated parameters ----
tictoc::tic("Bootstrap CI for additive LMM parameters")
res.ntitsTLy_addeff_CI_boot <- confint(ntitsTLy_lmm2, method="boot")
tt <- as.data.frame(res.ntitsTLy_addeff_CI_boot)
tt$parameters <- rownames(tt)
readr::write_csv2(x = tt,
                  file = here::here("output", "tables", "res.ntitsTLy_bootCI_addeff.csv"))
tictoc::toc() # DISCLAIMER: took ~7s to run!



### *** 4.3.3.3. Conclusion ----

# Our models does not fit the observed data very well, perhaps because it could be slightly overfitted.
# Our hypotheses are not supported by the models and no significant predictors came out.
# Anyway, diagnostics indicated that there are room for improvements: removing outliers, changing the
# transformation of some variables, accounting for possible curvature effects...





##################### *--------------------------------* #######################
##### * 4.4. Wing length: LMM --------------------------------------------------
# ---------------------------------------------------------------------------- #
### ** 4.4.1. Initial model fit ----
# __________________________________

## Fitting a regular linear model:
ntits2 %>% dplyr::filter(is.na(wing_length) == FALSE) -> ntits3 # Only 141 observations left.

ntitsWLy_lm1 <- stats::lm(wing_length ~ logged_woodyveg + logged_Fmetric +
                         urban_intensity + manag_low + cumdd_30 + year, data = ntits3)
# ntitsWLy_lm2 <- stats::lm(wing_length ~ scale(logged_woodyveg, scale = F) * scale(logged_Fmetric, scale = F) +
#                          urban_intensity + manag_low + cumdd_30 + year,
#                        data = ntits3) # Interaction not significant!


## Fitting an additive LMM:
ntitsWLy_lmm1 <- lme4::lmer(wing_length ~ logged_woodyveg + logged_Fmetric +
                           urban_intensity + manag_low + cumdd_30 + year +
                           (1|id_nestbox), data = ntits3,
                         control=lme4::lmerControl(optimizer="bobyqa",
                                                   optCtrl=list(maxfun=2e5)))
# Gives a singular fit (RE variance = 0). I'll thus try setting a weak prior on the variance:
ntitsWLy_blmm1 <- blme::blmer(wing_length ~ logged_woodyveg + logged_Fmetric +
                             urban_intensity + manag_low + cumdd_30 + year +
                             (1|id_nestbox), data = ntits3,
                           control=lme4::lmerControl(optimizer="bobyqa",
                                                     optCtrl=list(maxfun=2e5))) # Convergence issue.
# Try all optimizers:
ntitsWLy_blmm1_all <- lme4::allFit(ntitsWLy_blmm1)
summary(ntitsWLy_blmm1_all) # Two optimizers failed to converge but give rather similar results, except the
# "nloptwrap.NLOPT_LN_BOBYQA" optimizer that computes a larger RE variance and thus, lower coefficient
# estimates. We will thus stick with "bobyqa".
ntitsWLy_blmm2 <- ntitsWLy_blmm1 # Only to keep "model2" as my additive model and "model3" as my interactive one.

## Fitting interactive (mediated) LMMs:
ntitsWLy_blmm3 <- blme::blmer(wing_length ~
                             scale(logged_woodyveg, scale = F) * scale(logged_Fmetric, scale = F) +
                             urban_intensity + manag_low + cumdd_30 + year +
                             (1|id_nestbox), data = ntits3,
                           control=lme4::lmerControl(optimizer="bobyqa",
                                                     optCtrl=list(maxfun=2e5))) # Convergence issue.

# # Test by removing possible overly influential observations:
# ntits2_wo <- ntits2[-c(49,58,50,143),]
# ntitsFSy_glmm3_wo <- stats::update(ntitsFSy_glmm3, data=ntits2_wo)
# summary(ntitsFSy_glmm3)$AIC
# summary(ntitsFSy_glmm3_wo)$AIC # Strongly improved AIC, BIC, and deviance. However, it yields lower R2_glmm!





### ** 4.4.2. Diagnostics and assumption checks ----
# __________________________________________________

### *** 4.4.2.1. Residuals extraction, autocorrelation and collinearity ----
## Extracting residuals (with the {redres}):
raw_cond <- redres::compute_redres(ntitsWLy_blmm3) # Computes the raw conditional residuals (conditional on
# the random effects (RE)).
pearson_mar <- redres::compute_redres(ntitsWLy_blmm3, type = "pearson_mar") # Computes the Pearson marginal
# (not accounting for the RE) residuals.
std_cond <- redres::compute_redres(ntitsWLy_blmm3, type = "std_cond") # Computes the studentised cond. ones.
# Joins the residuals to the paprika data:
xxx <- cbind(ntits3, raw_cond, pearson_mar, std_cond)

## Simulation-based scaled residuals computation (DHARMa method):
simu.resid <- DHARMa::simulateResiduals(fittedModel = ntitsWLy_blmm3, n = 1000, plot = FALSE)
par(.pardefault)
plot(simu.resid) # Ok.

## Autocorrelation and collinearity:
DHARMa::testSpatialAutocorrelation(simulationOutput = simu.resid,
                                   x = ntits3$coord_x, y = ntits3$coord_y, plot = TRUE) # Ok.
performance::check_autocorrelation(ntitsWLy_blmm3) # Ok.
performance::check_collinearity(ntitsWLy_blmm3) # Ok-ish but "urban_intensity" has a VIF of 3.5!
stats::vcov(ntitsWLy_blmm2) # Some quite high covariances!



### *** 4.4.2.2. Distribution and homoscedasticity ----
## Assessing the normality of the residuals:
stats::shapiro.test(xxx$raw_cond) # Significant deviation from normality detected, but the Shapiro test is
# known to be extremely sensitive. So plotting would be better:
xxx %>%
  tidyr::gather(key = "type", value = "residual", 29:31) %>%
  ggplot2::ggplot(ggplot2::aes(x = residual)) +
  ggplot2::geom_histogram(bins = 20) +
  ggplot2::facet_grid(. ~ type, scales = "free") +
  ggplot2::theme_bw() # The residuals are indeed a bit left-skewed, but it may be acceptable.
redres::plot_resqq(ntitsWLy_blmm3) # Surprisingly, there are not much departure from the Normal quantiles in
# the upper part of the residuals, even though there is a quite strong departure in the lower one.

## Assessing the normality if the random effect:
redres::plot_ranef(ntitsWLy_blmm3) # Same thing here!

## Assessing homogeneity of variance and influential observations:
plot(ntitsWLy_blmm3, type=c("p","smooth"), col.line = 2, id = 0.05, idLabels = ~.obs) # It's ok-ish even though
# the fitted values are devided in 2 and there seems to be 7 possible outliers:
ntits3[c(8),] # High residuals ~= long-winged juveniles. RAS.
ntits3[c(10,110,46,97,61,137),] # Low residuals ~= rather short-winged juveniles. RAS.

# Residuals vs leverage:
plot(ntitsWLy_blmm3, stats::rstudent(.) ~ stats::hatvalues(.))
cd <- stats::cooks.distance(ntitsWLy_blmm3)
plot(cd)
ntits3[which(cd>0.4),] # Ok, all observations are < 0.5, so no overly influential points.
ntits3[which(cd>0.1),] # Even with very conservative values, we find the same three observations.

## Residuals vs predictors:
redres::plot_redres(ntitsWLy_blmm3, xvar = "scale(logged_woodyveg, scale = F)") +
  ggplot2::geom_smooth(method = "loess") +
  ggplot2::theme_classic() +
  ggplot2::labs(title = "Residual vs predictor") # Ok.
redres::plot_redres(ntitsWLy_blmm3, type = "raw_mar", xvar = "year") # Ok.

## Distribution of the predicted values:
par(.pardefault)
ntits3$predictions <- stats::predict(object = ntitsWLy_blmm3, type = "response") # Extract the predicted values.
fitdistrplus::plotdist(data = ntits3$predictions, histo = TRUE, demp = TRUE)
fitdistrplus::plotdist(data = ntits3$wing_length, histo = TRUE, demp = TRUE) # Very bad: clear bimodal
# prediction range and reduced total range!



### *** 4.4.2.3. Linearity ----
## Plotting the response on the logit scale (= log odds) against predictors:
# Format data:
ntits3 %>% dplyr::select(woodyveg_vw, pmF_d60_beta0, urban_intensity, cumdd_30) %>%
  dplyr::mutate("Fmetric" = pmF_d60_beta0,
                "Fmetric (log)" = log10(pmF_d60_beta0),
                "woodyveg_vw" = woodyveg_vw,
                "woodyveg_vw (log)" = log10(woodyveg_vw),
                "woodyveg_vw (sqrt)" = sqrt(woodyveg_vw), .keep = "unused") -> mydata
predictors <- colnames(mydata)
# Bind 'wing_length' and tidying the data for plot (ggplot2, so long format):
mydata <- mydata %>%
  dplyr::mutate(wing_length = ntits3$wing_length) %>%
  tidyr::gather(key = "predictors", value = "predictor.value", -wing_length)
# Create scatterplot
ggplot2::ggplot(mydata, ggplot2::aes(y = wing_length, x = predictor.value))+
  ggplot2::geom_point(size = 0.5, alpha = 0.5) +
  ggplot2::geom_smooth(method = "loess") +
  ggplot2::theme_bw() +
  ggplot2::facet_wrap(~predictors, scales = "free_x") # As before, we can see a few non-linearities that
# are caused by some extreme values.




### *** 4.4.2.4. Goodness-of-fit (GOF) and performances ----
## Computing a pseudo-R2:
performance::r2_nakagawa(ntitsWLy_blmm2) # [Additive model]: Marg_R2_lmm = 0.36; Cond_R2_lmm = 0.43.
performance::r2_nakagawa(ntitsWLy_blmm3) # [Interact. model]: Marg_R2_lmm = 0.36; Cond_R2_lmm = 0.43.

## Likelihood-ration tests (LRT) of GOF:
# Importance of the "id_nestbox" random-effect (RE):
tictoc::tic("Parametric bootstrap LRT")
res.LRT_re <- DHARMa::simulateLRT(m0 = ntitsWLy_lm1, m1 = ntitsWLy_blmm2, n = 500, seed = 762)
tictoc::toc() # Took ~34s to run.
# The LRT is significant, suggesting that M1 better describes the data than M0, supporting the importance of
# the random effect!

# Importance of the fixed effects (only using the LM):
ntitsWLy_lm0 <- stats::lm(wing_length ~ 1, data = ntits3)
res.LRT_null <- stats::anova(object = ntitsWLy_lm0, ntitsWLy_lm1, test = "LRT")
# The test is highly significant, confirming that the model is useful to explain the data.





### ** 4.4.3. Inference and predictions ----
# __________________________________________

### *** 4.4.3.1. Hypotheses testing: LRT for the additive and interactive effect of the F-metric ----
## For the additive effect of the connectivity metric:
ntitsWLy_blmm1 <- stats::update(ntitsWLy_blmm2, .~. -logged_Fmetric)

res.LRT_addeff <- pbkrtest::PBmodcomp(ntitsWLy_blmm2, ntitsWLy_blmm1,
                                      nsim = 1000, seed = 455) # Took ~104s to run!
readr::write_csv2(x = res.LRT_addeff$test, file = here::here("output", "tables",
                                                             "res.ntitsWLy_LRT_addeff.csv"))
# The LRT is significant, indicating that our connectivity metric might be useful to improve the
# description of the data.


## For the interaction effect:
res.LRT_inteff <- pbkrtest::PBmodcomp(ntitsWLy_blmm3,
                                      ntitsWLy_blmm2, nsim = 1000, seed = 99) # Took ~32s to run!
readr::write_csv2(x = res.LRT_inteff$test, file = here::here("output", "tables",
                                                             "res.ntitsWLy_LRT_inteff.csv"))
# The LRT is NOT significant, indicating that our hypothesis of an interaction effect is not supported
# by the data.



### *** 4.4.3.2. Bootstrapped confidence intervals for estimated parameters ----
tictoc::tic("Bootstrap CI for additive LMM parameters")
res.ntitsWLy_addeff_CI_boot <- confint(ntitsWLy_blmm2, method="boot")
tt <- as.data.frame(res.ntitsWLy_addeff_CI_boot)
tt$parameters <- rownames(tt)
readr::write_csv2(x = tt,
                  file = here::here("output", "tables", "res.ntitsWLy_bootCI_addeff.csv"))
tictoc::toc() # DISCLAIMER: took ~27s to run!



### *** 4.4.3.3. Conclusion ----

# Our models does not fit the observed data very well, perhaps because it could be slightly overfitted.
# Once again, only the additive effect of the connectivity metric was supported by the data, but results
# could be different with a more powerful set-up and by removing some possible outliers.





########################## ************************************************* ###############################
par(.pardefault)
############################################ TO DO LIST ####################################################
# - Refaire tourner tous les modèles avec NTITS --> Utiliser clutch_size et brood_size comme prédicteur, ou
#   la date de ponte??????? ASK JC??????????? Tester????
# - Explorer chaque modèle pour voir qu'est-ce qui marche le mieux et s'il y a une spécification unique qui
#   va bien!!! ATTENTION à la gamme des variables explorées (transformations???????)!!!!
# - Si rien de bien concluant, essayer en fusionnant les années pour supprimer les RE nichoirs.

# 3) Re-diagsnose models with inputs from the DHARMa vignette (including conditional simu)!!! Then:
# 4) Improve sub-conclusions! Saying that quasi is not a good option??? Or try anyway with a package that
#    does it OR BETA-BINOMIAL? --> But too many parameters (ZI+OI)!!! I should wait for the MERGE!
#    Or simply try modelling the counts with ZI+Comreg avec RE??? And/or PM+CC and/or MERGING years and
#    nestboxes and hope that it alleviates these problems?????
# 5) Move on to another Y: i) LMM_morpho; ii) LMM_mass, wing...; iii) COM-Poisson pour clutch_size; iv) ZI!
# 6) Try the Conway-Maxwell Poisson (Shmueli et al, 2005*) avec {COMPoissonReg} (Sellers & Lotze, 2015*),
#    but search first if that exist in Mixed Model! (Same for Zero-Inflated models)! Or quasi-likelihood,
#    or generalised-Poisson (but {VGAM} does not do it anymore). I could also try it without REs...
#    The problem with all that is that quasi-MLE, GP or COM-Poisson prevent mixed-models and possibly
#    LR-tests, right? At least the quasi-MLE does. Is bird breeding a Poisson process???

# 7) Reunite PM & CC while keeping other predictors (for exploratory research)! But beware of coding,
#    what does the intercept mean? Which reference group?

# 1) Consider removing overly influential observations?
# 2) Consider merging years and averaging nestboxes??? Some of the GLMs gave interesting results, sometimes
#    even more when "year" was removed.
# 8) Compare all methods of estimation and inference (cf. inference bolker example) for the **same
#    model** to see if any is making a difference?
# 9) Explore other predictors (and different scales)! E.g. AICc-based model selection?
########################## ************************************************* ###############################
