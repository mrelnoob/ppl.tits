# ########################## *--------------------------------------------------* ########################
# ########################## Inferential modelling for all tit nestlings (ntits)  ########################
# ########################## *--------------------------------------------------* ########################
#
# # The functions of this R file are meant to wrap all formal inference modelling related to both species
# # together, as opposed to per-species models, "preparation modelling" (cf. previous scripts) and
# # "exploratory modelling" that will perhaps be made afterwards; i.e. after we have formally tested our
# # research hypotheses in a robust inferential framework. The so-called "exploratory modelling" is related
# # to additional questions and perspectives that will have, by nature, far less support as the data have
# # already been used for formal testing (so type-I error rates cannot be guaranteed anymore)!
#
# # For now, this script should be run after having sourced the EDA script (because no function yet)!!!
#
#
#
#
#
# # -------------------------------- #
# ##### 1. Modelling clutch size #####
# # -------------------------------- #
#
# ##### * 1.1. Clutch size: COM-Poisson GLMM -------------------------------------
# # ---------------------------------------------------------------------------- #
# ### ** 1.1.1. Initial model fit ----
# # __________________________________
#
# ## Fitting a regular Poisson regression:
# ttCy_glm1 <- stats::glm(clutch_size ~ logged_woodyveg + logged_Fmetric + species +
#                           urban_intensity + manag_low + manag_high + light_pollution + noise_m +
#                           cumdd_30 + year,
#                         data = ntits2, family = "poisson")
#
# ## Fitting a regular Poisson GLMM:
# ttCy_glmm1 <- glmmTMB::glmmTMB(clutch_size ~ logged_woodyveg + logged_Fmetric + species +
#                                      urban_intensity + manag_low + manag_high + light_pollution + noise_m +
#                                      cumdd_30 + year + (1|id_nestbox),
#                                    data = ntits2, family = "poisson")
#
# ## Fitting a regular Conway-Maxwell (COM) Poisson regression (GLM):
# ttCy_comglm1 <- glmmTMB::glmmTMB(clutch_size ~ logged_woodyveg + logged_Fmetric + species +
#                                           urban_intensity + manag_low + manag_high + light_pollution + noise_m +
#                                           cumdd_30 + year,
#                                         data = ntits2, family = glmmTMB::compois(link = "log"),
#                                         dispformula = ~1) # Intercept only 'nu' (default).
# # OR:
# ttCy_comglm1b <- COMPoissonReg::glm.cmp(formula.lambda =
#                                        clutch_size ~ logged_woodyveg + logged_Fmetric + species +
#                                        urban_intensity + manag_low + manag_high + light_pollution + noise_m +
#                                        cumdd_30 + year,
#                                      data = ntits2, formula.nu = ~1) # Intercept only 'nu' (default).
#
# ## Fitting a regular Conway-Maxwell (COM) Poisson mixed model (GLMM):
# ttCy_comglmm1 <- glmmTMB::glmmTMB(clutch_size ~ logged_woodyveg + logged_Fmetric + species +
#                                    urban_intensity + manag_low + manag_high + light_pollution + noise_m +
#                                    cumdd_30 + year + (1|id_nestbox),
#                                  data = ntits2, family = glmmTMB::compois(link = "log"),
#                                  dispformula = ~1) # Rather long to fit.
# summary(ttCy_glm1) # AIC = 1758.2
# summary(ttCy_glmm1) # AIC = 1760.2
# summary(ttCy_comglm1) # AIC = 1624.7
# summary(ttCy_comglm1b) # AIC = 1624.5 (so it's not exactly the same?!).
# summary(ttCy_comglmm1) # AIC = 1626.7.
# # It seems that, if the inclusion of a random effect (RE) did not improve the fit, but accounting for a
# # likely underdispersion quite strongly improved the fit! I will thus carry on with the last model to the
# # diagnostic part and assess whether the use of the RE is truly justified or not and if the model behaves
# # as expected.
# # UPDATE: diagnostics ran for 'ttCy_comglmm1' (initial model) indicated that the model fit the data
# # relatively well although several modelling assumptions were slightly violated. They also confirmed that
# # the RE were not truly useful for this model. Importantly, diagnostics showed that the model was slightly
# # off likely because there was true outliers in the data as the very low clutch sizes observed were probably
# # generated by another process. Consequently, in a second step, we removed them and explored a few
# # reasonable variations of the same model by trying different proxies of the same variable ("noise_iq"
# # instead of "noise_m"; "Fmetric_d2b1" instead of "Fmetric_d2b0"; and "woody_area" instead of "woodyveg_vw"),
# # using "site" as RE, and slightly tuning the (nu) dispersion model (see below).
# # I also tried interaction models, but interaction effects were not significant.
#
# # Below, code and comments will show the diagnostics of one or several of these improved models, but you
# # can re-run the diagnostics for the initial model by replacing the model name in the code chunks and to
# # change ntits3 by ntits2 (i.e. the dataset with the deleted outliers).
#
#
#
#
#
# ### ** 1.1.2. Improved model (exploration) ----
# # _____________________________________________
#
# ## To remove probable outliers (see 'ttCy_comglmm1' diagnostics):
# ntits3 <- ntits2[-c(156,170,181,210,227,314,362,367),]
#
# ## Replacement of the beta0 "F-metric" (by the beta1 version):
# ttCy_comglmm1b <- glmmTMB::glmmTMB(clutch_size ~ logged_woodyveg + logged_Fmetric_d2b1 + species +
#                                      urban_intensity + manag_low + manag_high + light_pollution + noise_iq +
#                                      cumdd_30 + year + (1|site),
#                                    data = ntits3, family = glmmTMB::compois(link = "log"),
#                                    dispformula = ~1)
# ## Addition of an improved dispersion model:
# ttCy_comglmm1c <- glmmTMB::glmmTMB(clutch_size ~ logged_woodyveg + logged_Fmetric_d2b1 + species +
#                                      urban_intensity + manag_low + manag_high + light_pollution + noise_iq +
#                                      cumdd_30 + year + (1|site),
#                                    data = ntits3, family = glmmTMB::compois(link = "log"),
#                                    dispformula = ~cumdd_30+min_t_before) # Rather long to fit.
# ## Replacement of the woody vegetation volume (by its area):
# ttCy_comglmm1d <- glmmTMB::glmmTMB(clutch_size ~ logged_woody_area + logged_Fmetric_d2b1 + species +
#                                      urban_intensity + manag_low + manag_high + light_pollution + noise_iq +
#                                      cumdd_30 + year + (1|site),
#                                    data = ntits3, family = glmmTMB::compois(link = "log"),
#                                    dispformula = ~cumdd_30+min_t_before) # Rather long to fit.
# summary(ttCy_comglmm1b) # AIC = 1391.3.
# summary(ttCy_comglmm1c) # AIC = 1390.5.
# summary(ttCy_comglmm1d) # AIC = 1388.1.
# zzz <- glmmTMB::glmmTMB(clutch_size ~ logged_woody_area + logged_Fmetric + species +
#                                      urban_intensity + manag_low + manag_high + light_pollution + noise_iq +
#                                      cumdd_30 + year + (1|site),
#                                    data = ntits3, family = glmmTMB::compois(link = "log"),
#                                    dispformula = ~cumdd_30+min_t_before) # Rather long to fit.
# summary(zzz)
#
#
#
#
#
# ### ** 1.1.3. Diagnostics and assumption checks ----
# # __________________________________________________
#
# ### *** 1.1.3.1. Residuals extraction, autocorrelation and collinearity ----
# ## Traditional residuals:
# par(.pardefault)
# resid <- stats::resid(ttCy_comglmm1b, type = 'response')
# plot(resid, id = 0.05, idLabels = ~.obs) # Ok-ish but there are a few low residuals.
# # performance::check_outliers(ttCy_comglmm1b) # Does not work for this type of model.
# ntits3[which(resid < -4),] # Lowest residuals are nestboxes with very small clutch sizes.
#
# # To further investigate patterns, I can plot the residuals against some predictors:
# plot(x = ntits3$year, y = resid) # Seems rather ok although we once again find patterns linked to the
# # sometimes odd distribution of some predictors. However, be reminded that simulated residuals will be
# # more useful).
# # plot(ttCy_comglmm1b, id_nestbox~stats::resid(.)) # Does not work for this type of model.
# # plot(ttCy_comglmm1b, site~stats::resid(.)) # Does not work for this type of model.
#
# ## Simulation-based scaled residuals computation ({DHARMa} method):
# simu.resid <- DHARMa::simulateResiduals(fittedModel = ttCy_comglmm1b, n = 1000, re.form = NULL) # The
# # 're.form' argument is to base simulations on the model unconditional of the random effects (and only works
# # for {lme4} formulations). It is useful for testing dispersion (see below) but can be omitted eventually.
# plot(simu.resid) # Significant deviations and outliers detected!
# DHARMa::outliers(simu.resid) # No potential outliers.
# ntits2[c(156,170,181,210,227,314,362,367),] # They have surprisingly low clutch sizes with regards to their
# # locations and their adjacent observations. They may well be true outliers (whose clutch sizes are function
# # of other processes).
#
# ## Autocorrelation and collinearity:
# DHARMa::testSpatialAutocorrelation(simulationOutput = simu.resid,
#                                    x = ntits3$coord_x, y = ntits3$coord_y, plot = TRUE) # Ok for B, C and D.
# performance::check_autocorrelation(ttCy_comglmm1b) # Ok.
# performance::check_collinearity(ttCy_comglmm1b) # Ok-ish, but "urban_intensity" and "F" > 3 (for B,C)! For
# # the D improved model, VIF > 4 for "woody_area", "urban_intensity" and >5 for the "F-metric"!
#   stats::vcov(ttCy_comglmm1b) # But values of the covariance matrix seem ok.
#
# ## Heteroscedasticity and possible model misspecifications:
# par(.pardefault)
# DHARMa::plotResiduals(simu.resid, form = ntits3$logged_woodyveg)
# DHARMa::plotResiduals(simu.resid, form = ntits3$logged_Fmetric)
# DHARMa::plotResiduals(simu.resid, form = ntits3$urban_intensity)
# DHARMa::plotResiduals(simu.resid, form = ntits3$manag_intensity)
# DHARMa::plotResiduals(simu.resid, form = ntits3$light_pollution)
# DHARMa::plotResiduals(simu.resid, form = ntits3$noise_iq)
# DHARMa::plotResiduals(simu.resid, form = ntits3$cumdd_30)
# DHARMa::plotResiduals(simu.resid, form = ntits3$species)
# DHARMa::plotResiduals(simu.resid, form = ntits3$year)
# # All these plots are ok for B, C and D models.
#
#
#
# ### *** 1.1.3.2. Distribution (family, ZI, dispersion) ----
# ## Assessing over or under-dispersion:
# AER::dispersiontest(object = ttCy_glm1, alternative = c("less")) # Significant underdispersion!
# DHARMa::testDispersion(simu.resid, alternative = "less") # Ok.
#
# ## Theoretical count distribution:
# theo_count <- COMPoissonReg::rcmp(n = nrow(ntits3), lambda = mean(ntits3$clutch_size), nu = 1.1) # The 'nu'
# # parameter should be chosen by trial-and-errors.
# tc_df <- data.frame(theo_count)
#
# ggplot2::ggplot(ntits3, ggplot2::aes(clutch_size)) +
#   ggplot2::geom_bar(fill = "#1E90FF") +
#   ggplot2::geom_bar(data = tc_df, ggplot2::aes(theo_count, fill="#1E90FF", alpha=0.5)) +
#   ggplot2::theme_classic() +
#   ggplot2::theme(legend.position = "none") # Blue = observed counts; red = simulated.
# # This plot suggests that clutch_size could be following a COM-Poisson distribution of parameter nu~1.1!
#
# ## Distribution of the predicted counts:
# pred_counts <- stats::predict(object = ttCy_comglmm1b, type = "response") # Extract the predicted counts.
# par(mfrow= c(1,2))
# hist(pred_counts, main = "Predicted counts", xlab = "Number of laid eggs")
# hist(ntits3$clutch_size, main = "Observed counts", xlab = "Number of laid eggs") # The models' predictions
# # are very similar and relatively acceptable (although too narrow).
#
#
#
# ### *** 1.1.3.3. Linearity ----
# # For the sake of further exploration, I also plot variants of our predictors:
# ntits3 %>% dplyr::select(woodyveg_vw, woody_area, woodyveg_sd,
#                          F_metric_d2b0, F_metric_d1b0, F_metric_d3b0, F_metric_d1b1, F_metric_d2b1,
#                          urban_intensity, herbaceous_area, built_area, traffic,
#                          light_pollution, noise_m, noise_iq,
#                          cumdd_30, min_t_before) %>%
#   dplyr::mutate("Fmetric" = F_metric_d2b0,
#                 "Fmetric (sqrt)" = sqrt(F_metric_d2b0),
#                 "Fmetric (log)" = log10(F_metric_d2b0),
#                 "woodyveg_vw" = woodyveg_vw,
#                 "woodyveg_vw (sqrt)" = sqrt(woodyveg_vw),
#                 "woodyveg_vw (log)" = log10(woodyveg_vw), .keep = "unused") -> mydata
# predictors <- colnames(mydata)
# # Bind log(Y) and tidying the data for plot (ggplot2, so long format):
# mydata <- mydata %>%
#   dplyr::mutate(log_y = log(ntits3$clutch_size)) %>%
#   tidyr::gather(key = "predictors", value = "predictor.value", -log_y)
# # Create scatterplot
# ggplot2::ggplot(mydata, ggplot2::aes(y = log_y, x = predictor.value))+
#   ggplot2::geom_point(size = 0.5, alpha = 0.5) +
#   ggplot2::geom_smooth(method = "loess") +
#   ggplot2::theme_bw() +
#   ggplot2::facet_wrap(~predictors, scales = "free_x") # Linearity seems respected.
#
#
#
# ### *** 1.1.3.4. Model goodness-of-fit (GOF) and performances ----
# # GOF test of Pearson's Chi2 residuals:
# dat.resid <- sum(stats::resid(ttCy_comglmm1b, type = "pearson")^2)
# 1 - stats::pchisq(dat.resid, stats::df.residual(ttCy_comglmm1b)) # All p > 0.5, indicating that there is no
# # significant lack of fit. Keep in mind though that GOF measures for mixed models is an extremely complicated
# # topic and interpretations are not straightforward.
#
# # Computing a pseudo-R2:
# performance::r2_nakagawa(ttCy_comglmm1b) # [Additive model]: Marg_R2_glmm = 0.09; Cond_R2_glmm = 0.1.
# # Does not work for C and D models because it cannot account for the dispersion model.
#
# ## Likelihood-ration tests (LRT) of GOF:
# # For the "site" random-effects (RE):
# ttCy_comglmm2 <- glmmTMB::glmmTMB(clutch_size ~ logged_woodyveg + logged_Fmetric + species +
#                                     urban_intensity + manag_low + manag_high + light_pollution + noise_m +
#                                     cumdd_30 + year + (1|id_nestbox) + (1|site),
#                                   data = ntits2, family = glmmTMB::compois(link = "log"),
#                                   dispformula = ~1) # Rather long to fit (~3-4 min)!
# summary(ttCy_comglmm2) # AIC = 1628.7.
# # The non-mixed model gives AIC = 1624 so approximatively equal to the mixed-model (AIC = 1626.7) with only
# # "id_nestbox" as RE. The mixed model with only "site" as a RE gives AIC = 1626.7. The one with both RE gives
# # AIC = 1628.7. So it seems like the use of mixed models is here not supported by the data!
#
# ## For the whole model:
# ttCy_comglmm0 <- glmmTMB::glmmTMB(clutch_size ~ 1 + (1|id_nestbox),
#                                   data = ntits2, family = glmmTMB::compois(link = "log"),
#                                   dispformula = ~1)
# res.LRT_null <- stats::anova(object = ttCy_comglmm0, ttCy_comglmm1b, test = "LRT")
# # The test is significant, confirming that the model is useful to explain the data.
#
#
#
# ### *** 1.1.3.5. Posterior predictive simulations ----
# # Predicted counts:
# par(.pardefault)
# obsprop <- prop.table(table(ntits3$clutch_size))
# sims <- stats::simulate(ttCy_comglmm1b, nsim = 1000)
# nsim4 <- colSums(sims == 4) # Number of fours (min obs value)
# par(las=4,bty="l")
# plot(pt <- prop.table(table(nsim4)),
#      ylab="Probability", xlab="Number of fours")
# (obs4 <- sum(ntits3$clutch_size == 4))
# points(obs4, 0.005, col="red", pch=16, cex=2) # See y values in obsprop
#
# nsim9 <- colSums(sims == 9) # Number of nines (modal obs value).
# par(las=1,bty="l")
# plot(pt <- prop.table(table(nsim9)),
#      ylab="Probability", xlab="Number of nines")
# (obs9 <- sum(ntits3$clutch_size == 9))
# points(obs9, 0.21, col="red", pch=16, cex=2)
#
# nsim14 <- colSums(sims == 14) # Number of fourteens (max obs value).
# par(las=1,bty="l")
# plot(pt <- prop.table(table(nsim14)),
#      ylab="Probability", xlab="Number of fourteens")
# (obs14 <- sum(ntits3$clutch_size == 14))
# points(obs14, 0.013, col="red", pch=16, cex=2)
# # These three examples confirm that the model still predicts values that are too dispersed compared to the
# # true observed values, but it's not that bad.
#
#
#
#
#
# ### ** 1.1.4. Inference and predictions ----
# # __________________________________________
#
# ##### TO BE RUN §§§ ----
#
# ### *** 1.1.4.1. Hypotheses testing: LRT for the additive and interactive effect of the F-metric ----
# ## Parametric bootstrap to test the additive effect of the connectivity metric:
# ttCy_comglmm0 <- stats::update(ttCy_comglmm1, .~. -logged_Fmetric)
# ttCy_comglmm0b <- stats::update(ttCy_comglmm1b, .~. -logged_Fmetric_d2b1)
# ttCy_comglmm0c <- stats::update(ttCy_comglmm1c, .~. -logged_Fmetric_d2b1)
# ttCy_comglmm0d <- stats::update(ttCy_comglmm1d, .~. -logged_Fmetric_d2b1)
# summary(ttCy_comglmm0)$AIC # AIC = 1624.8 vs 1626.6 (hypothesis likely not validated)!
# summary(ttCy_comglmm0b)$AIC # AIC = 1392 vs 1391.3 (hypothesis likely not validated)!
# summary(ttCy_comglmm0c)$AIC # AIC = 1391.6 vs 1390.5 (hypothesis likely not validated)!
# summary(ttCy_comglmm0d)$AIC # AIC = 1392.4 vs 1388.1 (hypothesis likely validated)!
# # I do not run PB-based LRT for now as they take too long to run.
#
# # tictoc::tic("Parametric bootstrap LRT for the additive effect")
# # res.LRT_inteff <- DHARMa::simulateLRT(m0 = ttCy_comglmm0, m1 = ttCy_comglmm1b, n = 500, seed = 10)
# # tt <- as.data.frame(cbind(res.LRT_inteff$method,
# #                           res.LRT_inteff$data.name,
# #                           res.LRT_inteff$statistic,
# #                           res.LRT_inteff$p.value))
# # rownames(tt) <- NULL
# # tt %>% dplyr::rename("Method" = V1,
# #                      "Models" = V2,
# #                      "Log Likelihood (M1/M0)" = V3,
# #                      "p-value" = V4) -> tt
# # readr::write_csv2(x = tt, file = here::here("output", "tables", "res.ttCy_LRT_addeff.csv"))
# # tictoc::toc() # DISCLAIMER: took >25h to run!!!!
# # The PB-based LRT is ...
# # NOTE: initially, normally I would use the more efficient 'pbkrtest::PBmodcomp()' instead of the
# # 'DHARMa::simulateLRT()' function, but it doesn't work with {glmmTMB} objects.
#
#
# ## Parametric bootstrap to test the interactive effect of the connectivity metric:
# # To save some time, I don"t even bother computing the PB-based LRT for the interaction effect, it won't be
# # significant. I should improve my proxies and my models first.
#
#
#
# ### *** 1.1.4.2. Bootstrapped confidence intervals for estimated parameters ----
# tictoc::tic("Bootstrap CI for the additive COM-Poisson GLMM parameters")
# res.ttCy_addeff_CI_boot <- confint(ttCy_comglmm1b, method="boot")
# tt <- as.data.frame(res.ttCy_addeff_CI_boot)
# tt$parameters <- rownames(tt)
# readr::write_csv2(x = tt,
#                   file = here::here("output", "tables", "res.ttCy_bootCI_addeff.csv"))
# tictoc::toc() # DISCLAIMER: took ~2h10 to run!
#
#
#
# ### *** 1.1.4.3. Conclusion ----
# # For the initial model:
# summary(ttCy_comglmm1) # AIC = 1626.7 and both R2_glmm = 0.05.
# # Diagnostics ran for 'ttCy_comglmm1' (initial model) indicated that the model fit the data relatively well
# # although several modelling assumptions were slightly violated. They also confirmed that the RE were not
# # truly useful for this model while the use of a COM-Poisson distribution was relevant.
# # Importantly, diagnostics showed that the model was slightly off likely because there was true outliers
# # in the data as the very low clutch sizes observed were probably generated by another process: i.e. some
# # observations had surprisingly low clutch sizes with regards to their locations and adjacent broods.
# ## Significant variables: speciesCC (+), cumdd_30 (-), year2021 (-).
# ## Almost significant variables: logged_woodyveg (-), year2020 (-) and year2022 (-).
# ## Hypothesis 1 likely not validated!
#
# # For the exploratory improved models:
# summary(ttCy_comglmm1b) # AIC = 1391.3 and Marg_R2_glmm = 0.09; Cond_R2_glmm = 0.1.
# ## Significant variables: woodyveg (-), speciesCC (+), light_pollution (-), noise_iq (+), cumdd_30 (-), and
# # year2021 (-).
# ## Almost significant variables: Fmetric_d2b1 (+), year2020 (-).
# ## Hypothesis 1 likely not validated (AIC = 1392 vs 1391.3)!
# summary(ttCy_comglmm1c) # AIC = 1390.5 and no R2 for dispersion models.
# ## Significant variables: woodyveg (-), speciesCC (+), light_pollution (-), noise_iq (+), cumdd_30 (-),
# # year2020 (-), year2021 (-).
# ## Almost significant variables: Fmetric_d2b1 (+).
# ## Hypothesis 1 likely not validated (AIC = 1391.6 vs 1390.5)!
# summary(ttCy_comglmm1d) # AIC = 1388.1 and no R2 for dispersion models.
# ## Significant variables: woody_area (-), Fmetric_d2b1 (+), speciesCC (+), noise_iq (+), cumdd_30 (-),
# # year2020 (-), year2021 (-).
# ## Almost significant variables: light_pollution (-).
# ## Hypothesis 1 likely validated (AIC = 1392.4 vs 1388.1)! While hypothesis 2 (interaction) seems rejected for
# # all model specifications.
#
# # Diagnostics for these models were mostly ok, there was no outliers, deviations or residual autocorrelation.
# # However, as could be expected, some VIF values for the D model ('ttCy_comglmm1d') were rather high even
# # though the covariance values were ok.
# # It also appears that the data could be following a COM-Poisson distribution with a nu ~ 1.1.
# # Predictions are fairly ok but still too narrow (and extremely similar between B, C, D)!
#
#
#
#
#
# ########################## ************************************************* ###############################
# # -------------------------------------- #
# ##### 2. Modelling hatching success #####
# # -------------------------------------- #
#
# ##### * 2.1. Hatching success: Binomial GLMM -----------------------------------
# # ---------------------------------------------------------------------------- #
# ### ** 2.1.1. Initial model fit ----
# # __________________________________
#
# ## Fitting a regular binomial GLM:
# ttHSy_glm1 <- stats::glm(brood_size/clutch_size ~ logged_woodyveg + logged_Fmetric + species +
#                            urban_intensity + manag_intensity + light_pollution + noise_iq +
#                            cumdd_30 + year,
#                          weights = clutch_size, # Prior weights!
#                          data = ntits2, family = "binomial") # Weights should not be forgotten. Otherwise, the
# # formulation should be: cbind(brood_size, clutch_size-brood_size)!
#
# ## Fitting a binomial GLMM:
# ttHSy_glmm1 <- glmmTMB::glmmTMB(brood_size/clutch_size ~ logged_woodyveg + logged_Fmetric + species +
#                                   urban_intensity + manag_intensity + light_pollution + noise_iq +
#                                   cumdd_30 + year + (1|id_nestbox),
#                            weights = clutch_size, data = ntits2, family = "binomial")
#
# ## Fitting a zero-inflated (ZI) binomial GLMM:
# ttHSy_ziglmm1 <- glmmTMB::glmmTMB(brood_size/clutch_size ~ logged_woodyveg + logged_Fmetric + species +
#                                   urban_intensity + manag_intensity + light_pollution + noise_iq +
#                                   cumdd_30 + year + (1|id_nestbox),
#                                 weights = clutch_size, data = ntits2, family = "binomial",
#                                 ziformula = ~1) # Intercept only.
#
# summary(ttHSy_glm1) # AIC = 1698.3.
# summary(ttHSy_glmm1) # AIC = 1229.6.
# summary(ttHSy_ziglmm1) # AIC = 912.
# # It seems that, if the inclusion of a random effect (RE) strongly improves the fit and so does accounting
# # for the zero-inflation (ZI)! I will thus carry on with the last model to the diagnostic part and assess
# # whether the use of the RE is truly justified or not and if the model behaves as expected.
#
# # UPDATE: diagnostics ran for 'ttHSy_ziglmm1' and 'ttHSy_glmm1' (the initial models) indicated that the
# # models fit the data relatively well although some modelling assumptions were not fully met and the models
# # under-predicted. Overall, diagnostics suggested that observations with brood sizes of 0 were likely
# # outliers generated by another process than the one driving hatching rate. Incidentally, they were mostly
# # the same as the outliers of clutch_size!
# # Consequently, in a second step, we removed them and explored a few reasonable variations of the same
# # model by trying different proxies of the same variable (see below).
# # To test our 2nd hypothesis, I also fitted an interaction model in which the interaction effect turned
# # out significant, it will thus be diagnose as well.
#
# # Below, code and comments will show the diagnostics of several of these improved models (D, E, F), but you
# # can re-run the diagnostics for the initial models by replacing the model name in the code chunks and to
# # change ntits3 by ntits2 (i.e. the dataset with the deleted outliers).
#
#
#
#
#
# ### ** 2.1.2. Improved model (exploration) ----
# # _____________________________________________
#
# ## To remove probable outliers (see 'ttHSy_ziglmm1' diagnostics):
# ntits3 <- ntits2[-c(which(ntits2$brood_size == 0)),] # I delete the 28 observations for which no eggs
# # hatched as they were likely generated by another process than the one controlling overall hatching
# # success (e.g. desertion, predation).
#
# ## Fitting a binomial GLMM:
# ttHSy_glmm1a <- glmmTMB::glmmTMB(brood_size/clutch_size ~ logged_woodyveg + logged_Fmetric + species +
#                                   urban_intensity + manag_low + manag_high + light_pollution + noise_iq +
#                                   cumdd_30 + year + (1|id_nestbox),
#                                 weights = clutch_size, data = ntits3, family = "binomial")
#
# ## Replacement of the beta0 "F-metric" (by the beta1 version):
# ttHSy_glmm1b <- glmmTMB::glmmTMB(brood_size/clutch_size ~ logged_woodyveg + logged_Fmetric_d2b1 + species +
#                                    urban_intensity + manag_intensity + light_pollution + noise_iq +
#                                    cumdd_30 + year + (1|id_nestbox),
#                                  weights = clutch_size, data = ntits3, family = "binomial")
#
# ## Replacement of the woody vegetation volume (by its area) but not the "F-metric':
# ttHSy_glmm1c <- glmmTMB::glmmTMB(brood_size/clutch_size ~ logged_woody_area + logged_Fmetric + species +
#                                    urban_intensity + manag_intensity + light_pollution + noise_iq +
#                                    cumdd_30 + year + (1|id_nestbox),
#                                  weights = clutch_size, data = ntits3, family = "binomial")
#
# ## Replacement of both:
# ttHSy_glmm1d <- glmmTMB::glmmTMB(brood_size/clutch_size ~ logged_woody_area + logged_Fmetric_d2b1 + species +
#                                    urban_intensity + manag_intensity + light_pollution + noise_iq +
#                                    cumdd_30 + year + (1|id_nestbox),
#                                  weights = clutch_size, data = ntits3, family = "binomial")
# ## Replacement of "urban_intensity" by "logged_herby_area" but not the "F-metric':
# ttHSy_glmm1e <- glmmTMB::glmmTMB(brood_size/clutch_size ~ logged_woody_area + logged_Fmetric + species +
#                                    logged_herby_area + manag_intensity + light_pollution + noise_iq +
#                                    cumdd_30 + year + (1|id_nestbox),
#                                  weights = clutch_size, data = ntits3, family = "binomial")
# summary(ttHSy_glmm1a) # AIC = 709.9 vs 1229.6 (no-ZI) or 912 (ZI) for the initial models!
# summary(ttHSy_glmm1b) # AIC = 710.3.
# summary(ttHSy_glmm1c) # AIC = 701.5.
# summary(ttHSy_glmm1d) # AIC = 700.4.
# summary(ttHSy_glmm1e) # AIC = 701.2 (works also for clutch_size)!
#
# ## Fitting an interactive (mediated) GLMMs:
# ttHSy_glmm1f <- glmmTMB::glmmTMB(brood_size/clutch_size ~
#                           scale(logged_woody_area, scale = F) * scale(logged_Fmetric, scale = F) +
#                           species + logged_herby_area + manag_intensity + light_pollution + noise_iq +
#                           cumdd_30 + year + (1|id_nestbox),
#                         weights = clutch_size, data = ntits3, family = "binomial")
# summary(ttHSy_glmm1f) # AIC = 698.3.
# zzz <- glmmTMB::glmmTMB(brood_size/clutch_size ~
#                           scale(logged_woody_area, scale = F) * scale(logged_Fmetric_d2b1, scale = F) +
#                           species + logged_herby_area + manag_intensity + light_pollution + noise_iq +
#                           cumdd_30 + year + (1|id_nestbox),
#                         weights = clutch_size, data = ntits3, family = "binomial")
# summary(zzz) # AIC = 697.8.
#
#
#
#
#
# ### ** 2.1.3. Diagnostics and assumption checks ----
# # __________________________________________________
#
# ### *** 2.1.3.1. Residuals extraction, autocorrelation and collinearity ----
# ## Traditional residuals:
# par(.pardefault)
# resid <- stats::resid(ttHSy_glmm1d, type = 'response')
# plot(resid, id = 0.05, idLabels = ~.obs) # Very strange distribution and clear outliers!
# # performance::check_outliers(ttHSy_ziglmm1) # Does not work for this type of model.
# ntits3[which(resid < -0.2),] # Nestboxes with the lowest residuals = ~0% hatching success! Interestingly,
# # they may belong to the same nestbox, suggesting a strong year effect.
#
# # To further investigate patterns, I can plot the residuals against some predictors:
# plot(x = ntits3$noise_iq, y = resid) # Seems rather ok although we once again find patterns linked to the
# # sometimes odd distribution of some predictors. However, be reminded that simulated residuals will be
# # more useful).
# # plot(ttHSy_ziglmm1, id_nestbox~stats::resid(.)) # Does not work for this type of model.
# # plot(ttHSy_ziglmm1, site~stats::resid(.)) # Does not work for this type of model.
#
# ## Simulation-based scaled residuals computation ({DHARMa} method):
# simu.resid <- DHARMa::simulateResiduals(fittedModel = ttHSy_glmm1d, n = 1000, re.form = NULL) # The
# # 're.form' argument is to base simulations on the model unconditional of the random effects (and only works
# # for {lme4} formulations). It is useful for testing dispersion (see below) but can be omitted eventually.
# plot(simu.resid) # Ok for all 3 models (D,E,F).
# DHARMa::outliers(simu.resid) # Ok.
# # ntits3[c(156,170,181,210,227,314,362,367),] # They have surprisingly low clutch sizes with regards to their
# # # locations and their adjacent observations. They may well be true outliers (whose clutch sizes are function
# # # of other processes).
#
# ## Autocorrelation and collinearity:
# DHARMa::testSpatialAutocorrelation(simulationOutput = simu.resid,
#                                    x = ntits3$coord_x, y = ntits3$coord_y, plot = TRUE) # Ok.
# performance::check_autocorrelation(ttHSy_glmm1d) # Autocorrelated residuals detected, but adding a "site" RE
# # does not help, so there's not much I can do.
# performance::check_collinearity(ttHSy_glmm1d) # Too high for D, quite high for E and F but may be acceptable.
# stats::vcov(ttHSy_glmm1d) # But values of the covariance matrix seem ok.
#
# ## Heteroscedasticity and possible model misspecifications:
# par(.pardefault)
# DHARMa::plotResiduals(simu.resid, form = ntits3$logged_woody_area)
# DHARMa::plotResiduals(simu.resid, form = ntits3$logged_Fmetric)
# DHARMa::plotResiduals(simu.resid, form = ntits3$urban_intensity)
# DHARMa::plotResiduals(simu.resid, form = ntits3$logged_herby_area)
# DHARMa::plotResiduals(simu.resid, form = ntits3$manag_intensity)
# DHARMa::plotResiduals(simu.resid, form = ntits3$light_pollution)
# DHARMa::plotResiduals(simu.resid, form = ntits3$noise_iq)
# DHARMa::plotResiduals(simu.resid, form = ntits3$cumdd_30)
# DHARMa::plotResiduals(simu.resid, form = ntits3$species)
# DHARMa::plotResiduals(simu.resid, form = ntits3$year)
# # Ok for all models!
#
#
#
# ### *** 2.1.3.2. Distribution and dispersion ----
# ## Assessing over or under-dispersion:
# DHARMa::testDispersion(simu.resid) # Ok.
# performance::check_overdispersion(x = ttHSy_glmm1d) # Ok.
#
# ## Distribution of the predicted probabilities:
# probabilities <- stats::predict(object = ttHSy_glmm1d, type = "response") # Extract the predicted
# # probabilities.
# par(mfrow= c(1,2))
# hist(probabilities, main = "Predicted proportions", xlab = "Hatching success")
# hist(ntits3$brood_size/ntits3$clutch_size, main = "Observed proportions", xlab = "Hatching success")
# # All models seem to fit the observed proportions rather nicely although they still under-predict low
# # hatching rates.
#
# ## Zero-inflation:
# DHARMa::testZeroInflation(simu.resid) # Ok.
# # # Testing with the non-ZI GLMM:
# # simu.resid_nozi <- DHARMa::simulateResiduals(fittedModel = ttHSy_glmm1, n = 1000)
# # plot(simu.resid_nozi) # Clear deviations detected!
# # probabilities <- stats::predict(object = ttHSy_glmm1, type = "response") # Extract the predicted
# # # probabilities.
# # par(mfrow= c(1,2))
# # hist(probabilities)
# # hist(ntits3$brood_size/ntits3$clutch_size) # Surprisingly, the model seems to better fit the observed
# # # proportions, even though it still under-predicts the proportion of failures.
#
#
#
# ### *** 2.1.3.3. Linearity ----
# ## Plotting the response on the logit scale (= log odds) against predictors:
# # Format data:
# ntits3 %>% dplyr::select(logged_woodyveg, logged_woody_area, woodyveg_sd, logged_woodyvol,
#                          logged_Fmetric, logged_Fmetric_d1, logged_Fmetric_d1b1, logged_Fmetric_d2b1,
#                          urban_intensity, logged_herby_area, logged_built_area, logged_traffic,
#                          light_pollution, noise_m, noise_iq,
#                          cumdd_30, min_t_before, min_t_between) -> mydata
# predictors <- colnames(mydata)
# # Bind the logit and tidying the data for plot (ggplot2, so long format):
# mydata <- mydata %>%
#   dplyr::mutate(logit = log(probabilities/(1-probabilities))) %>%
#   tidyr::gather(key = "predictors", value = "predictor.value", -logit)
# # Create scatterplot:
# ggplot2::ggplot(mydata, ggplot2::aes(y = logit, x = predictor.value))+
#   ggplot2::geom_point(size = 0.5, alpha = 0.5) +
#   ggplot2::geom_smooth(method = "loess") +
#   ggplot2::theme_bw() +
#   ggplot2::facet_wrap(~predictors, scales = "free_x") # Ok.
#
#
#
# ### *** 2.1.3.4. Goodness-of-fit (GOF) and performances ----
# ## GOF test of Pearson's Chi2 residuals:
# dat.resid <- sum(stats::resid(ttHSy_glmm1d, type = "pearson")^2)
# 1 - stats::pchisq(dat.resid, stats::df.residual(ttHSy_glmm1d)) # p = 0.99 so not significant lack of fit!
#
# ## Computing a pseudo-R2:
# performance::r2_nakagawa(ttHSy_glmm1) # [Additive model]: Marg_R2_glmm = 0.05; Cond_R2_glmm = 0.61.
# performance::r2_nakagawa(ttHSy_glmm1d) # [Additive model]: Marg_R2_glmm = 0.11; Cond_R2_glmm = 0.31.
# performance::r2_nakagawa(ttHSy_glmm1e) # [Additive model]: Marg_R2_glmm = 0.11; Cond_R2_glmm = 0.31.
# performance::r2_nakagawa(ttHSy_glmm1f) # [Interactive model]: Marg_R2_glmm = 0.12; Cond_R2_glmm = 0.31.
#
# ## Likelihood-ration tests (LRT) of GOF:
# # Importance of the "id_nestbox" random-effect (RE):
# ttHSy_glm0e <- glmmTMB::glmmTMB(brood_size/clutch_size ~ logged_woody_area + logged_Fmetric + species +
#                                    logged_herby_area + manag_low + manag_high + light_pollution + noise_iq +
#                                    cumdd_30 + year,
#                                  weights = clutch_size, data = ntits3, family = "binomial")
# summary(ttHSy_glm0e) # The non-mixed model gives AIC = 741.1 while the mixed-model gave AIC = 701.2, so
# # the use of the mixed model seems warranted by the data!
#
# # Importance of the fixed effects:
# ttHSy_glmm0 <- glmmTMB::glmmTMB(brood_size/clutch_size ~ 1 + (1|id_nestbox),
#                                   weights = clutch_size, data = ntits3, family = "binomial")
# summary(ttHSy_glmm0) # AIC = 727 vs 701.2, so the model is likely slightly better but not that much!
#
#
#
#
#
# ### ** 2.1.4. Inference and predictions ----
# # __________________________________________
#
# ##### TO BE RUN §§§ ----
#
# ### *** 2.1.4.1. Hypotheses testing: LRT for the additive and interactive effect of the F-metric ----
# ## Parametric bootstrap to test the additive effect of the connectivity metric:
# ttHSy_glmm0d <- stats::update(ttHSy_glmm1d, .~. -logged_Fmetric_d2b1)
# ttHSy_glmm0e <- stats::update(ttHSy_glmm1e, .~. -logged_Fmetric)
# summary(ttHSy_glmm0d)$AIC # AIC = 702.8 vs 700.4 (hypothesis likely not validated)!
# summary(ttHSy_glmm0e)$AIC # AIC = 703.5 vs 701.2 (hypothesis likely not validated)! However, the AIC for
# # the interactive model is 698.3, so it might be significant in a LRT, suggesting that hypothesis 2 may be
# # validated!
# # I do not run PB-based LRT for now as they take too long to run.
#
# # tictoc::tic("Parametric bootstrap LRT for the interaction model")
# # res.LRT_inteff <- DHARMa::simulateLRT(m0 = ttHSy_ziglmm0, m1 = ttHSy_ziglmm1, n = 500, seed = 21)
# # tt <- as.data.frame(cbind(res.LRT_inteff$method,
# #                           res.LRT_inteff$data.name,
# #                           res.LRT_inteff$statistic,
# #                           res.LRT_inteff$p.value))
# # rownames(tt) <- NULL
# # tt %>% dplyr::rename("Method" = V1,
# #                      "Models" = V2,
# #                      "Log Likelihood (M1/M0)" = V3,
# #                      "p-value" = V4) -> tt
# # readr::write_csv2(x = tt, file = here::here("output", "tables", "res.ttHSy_LRT_addeff.csv"))
# # tictoc::toc() # DISCLAIMER: took ~3h35 to run!
# # # NOTE: initially, normally I would use the more efficient 'pbkrtest::PBmodcomp()' instead of the
# # # 'DHARMa::simulateLRT()' function, but it doesn't work with {glmmTMB} objects.
#
#
# ## Parametric bootstrap to test the interactive effect of the connectivity metric:
# # To be run (retrieve code from previous scripts)!
#
#
#
# ### *** 2.1.4.2. Bootstrapped confidence intervals for estimated parameters ----
# tictoc::tic("Bootstrap CI for additive GLMM parameters")
# res.ttHSy_addeff_CI_boot <- confint(ttHSy_glmm1e, method="boot")
# tt <- as.data.frame(res.ttHSy_addeff_CI_boot)
# tt$parameters <- rownames(tt)
# readr::write_csv2(x = tt,
#                   file = here::here("output", "tables", "res.ttHSy_bootCI_addeff.csv"))
# tictoc::toc() # DISCLAIMER: took ~2h10 to run!
#
#
#
# ### *** 2.1.4.3. Conclusion ----
# # For the initial model:
# summary(ttHSy_ziglmm1) # AIC = 912 and Marg_R2_glmm = 0.07; Cond_R2_glmm = 0.29.
# # Diagnostics ran for 'ttHSy_ziglmm1' (initial model) indicated that the model fit the data relatively well
# # although several problems have been detected:
# # - The raw residuals are very oddly distributed, showing a signs for the existence of several different
# #   processes and thus, possible outliers (albeit formal test did not find any).
# # - Some significant quantile deviations have been detected.
# # - A significant overdispersion has been detected.
# # - The model under-predicts total successes and failures and, surprisingly, the non-ZI model was better!
# # - Most importantly, "species" was not found significant (yet, as here we model a proportion and not raw
# #   counts, it is possible).
# # On the other hand, diagnostics also indicated that the use of a RE was appropriate.
# ## Significant variables: woodyveg (--), and all 3 years (+).
# ## Almost significant variables: none.
# ## Hypothesis 1 likely not validated (AIC = 910.5 vs 912)!
#
#
# # For the exploratory improved models:
# summary(ttHSy_glmm1d) # AIC = 700.4 and Marg_R2_glmm = 0.11; Cond_R2_glmm = 0.31.
# ## Significant variables: woody_area (---), F-metric_d2b1 (++), all 3 years (++).
# ## Almost significant variables: noise_iq (-).
# ## Hypothesis 1 likely not validated (AIC = 702.8 vs 700.4)!
# summary(ttHSy_glmm1e) # AIC = 701.2 and Marg_R2_glmm = 0.11; Cond_R2_glmm = 0.31.
# ## Significant variables: woody_area (---), F-metric (++), noise_iq (-), all 3 years (++).
# ## Almost significant variables: speciesCC (+).
# ## Hypothesis 1 likely not validated (AIC = 703.5 vs 701.2)!
# summary(ttHSy_glmm1f) # AIC = 698.3 and Marg_R2_glmm = 0.12; Cond_R2_glmm = 0.31.
# ## Significant variables: woody_area (---), Fmetric (++), speciesCC (+), all 3 years (++), and the
# # INTERACTION EFFECT (++)!
# ## Almost significant variables: noise_iq (-).
# ## Hypothesis 2 (and thus 1 as well) possibly validated!
# summary(zzz) # AIC = 697.8 and Marg_R2_glmm = 0.14; Cond_R2_glmm = 0.33.
# ## Significant variables: woody_area (---), Fmetric_d2b1 (++), all 3 years (++), and the INTERACTION
# # EFFECT (++)!
# ## Almost significant variables: speciesCC (+), noise_iq (-).
# ## Hypothesis 2 (and thus 1 as well) possibly validated!
#
# # Diagnostics for these models were mostly ok, there was no outliers, deviations, dispersion or
# # distributional problems, even though there was some residual autocorrelation. However, there was some
# # worrying collinearity for model E and F, and clearly problematic for model 'ttHSy_glmm1d' (and 'zzz').
# # Importantly, results for hypothesis 2 seem consistent whether we use "herby_area", "urban_intensity" or
# # none of these 2 variables, while the latter improves both VIF and AIC values.
# # Predictions are fairly ok but the models still under-predict low hatching rates (and predictions were
# # extremely similar among models)!
# # As for clutch_size, it is noteworthy that the models are not that better compared to a true null model!
#
#
#
#
#
# ########### *-----------------------------------------------------* ############
# ##### * 2.2. Brood size: COM-Poisson GLMM --------------------------------------
# # ---------------------------------------------------------------------------- #
# ### ** 2.2.1. Initial model fit ----
# # __________________________________
#
# # Given the previous diagnostics, I chose to directly use "woody_area" instead of "woodyveg_vw" and to
# # delete the observations for which brood_size = 0 since they likely are true outliers (see comments in
# # the previous sections):
# ntits3 <- ntits2[-c(which(ntits2$brood_size == 0)),]
# ntits3 <- ntits3[-c(44,105,249),] # I also delete the 3 outliers found by initial diagnostics.
# # Note also that I initially tried to include "clutch_size" (CS) as a covariate to focus on the variation
# # that is not due to variations in the number of eggs laid but, if that strongly lowered the AIC, diagnostics
# # were terribly off (strong deviations from uniformity). Therefore, I chose to remove it which means that
# # we are actually modelling a part of clutch size variability as well!
#
# ## Fitting a regular Poisson GLM:
# ttBSy_glm1 <- stats::glm(brood_size ~ logged_woody_area + logged_Fmetric + species +
#                            urban_intensity + manag_low + manag_high + light_pollution + noise_iq +
#                            cumdd_30 + year,
#                          data = ntits3, family = "poisson")
#
# ## Fitting a regular Poisson GLMM:
# ttBSy_glmm1 <- glmmTMB::glmmTMB(brood_size ~ logged_woody_area + logged_Fmetric + species +
#                                   urban_intensity + manag_low + manag_high + light_pollution + noise_iq +
#                                   cumdd_30 + year + (1|id_nestbox),
#                                 data = ntits3, family = "poisson")
#
# ## Fitting a COM-Poisson GLMM:
# ttBSy_comglmm1 <- glmmTMB::glmmTMB(brood_size ~ logged_woody_area + logged_Fmetric + species +
#                                      urban_intensity + manag_low + manag_high + light_pollution + noise_iq +
#                                      cumdd_30 + year + (1|id_nestbox),
#                                      data = ntits3, family = glmmTMB::compois(link = "log"),
#                                      dispformula = ~1) # Rather long to fit.
# summary(ttBSy_glm1) # AIC = 1581.9.
# summary(ttBSy_glmm1) # AIC = 1593.9.
# summary(ttBSy_comglmm1) # AIC = 1407.7.
#
# ## Fitting an interactive (mediated) COM-Poisson GLMM:
# ttBSy_comglmm2 <- glmmTMB::glmmTMB(brood_size ~
#                                      scale(logged_woody_area, scale = F) * scale(logged_Fmetric, scale = F) +
#                                      species +
#                                      urban_intensity + manag_low + manag_high + light_pollution + noise_iq +
#                                      cumdd_30 + year + (1|id_nestbox),
#                                    data = ntits3, family = glmmTMB::compois(link = "log"),
#                                    dispformula = ~1) # Rather long to fit.
# summary(ttBSy_comglmm2) # AIC = 1409.7, doesn't seem supported by the data.
# # Overall, it seems that, if the inclusion of a random effect (RE) did not improve the fit, accounting for
# # the likely underdispersion strongly improved the fit! I will thus carry on with the last model to the
# # diagnostic part and assess whether the use of the RE is truly justified or not and if the model behaves
# # as expected.
#
# # UPDATE: diagnostics ran for 'ttBSy_comglmm1' and 'ttBSy_comglmm2' (the initial models) indicated that the
# # models fit the data relatively well although the models still under-predicted low brood sizes.
# # In a 2nd step, we explored a few reasonable variations of the same model by trying different proxies of
# # the same variable (see below). While they mildly improved AIC, overall results were similar.
#
#
#
#
#
# ### ** 2.2.2. Improved model (exploration) ----
# # _____________________________________________
#
# ## Replacement of the "urban_intensity":
# ttBSy_comglmm1b <- glmmTMB::glmmTMB(brood_size ~ logged_woody_area + logged_Fmetric + species +
#                                       logged_herby_area + manag_low + manag_high + light_pollution + noise_iq +
#                                       cumdd_30 + year + (1|id_nestbox),
#                                     data = ntits3, family = glmmTMB::compois(link = "log"),
#                                     dispformula = ~1)
#
# ## Tuning the dispersion model:
# ttBSy_comglmm1c <- glmmTMB::glmmTMB(brood_size ~ logged_woody_area + logged_Fmetric + species +
#                                       logged_herby_area + manag_low + manag_high + light_pollution + noise_iq +
#                                       cumdd_30 + year + (1|id_nestbox),
#                                     data = ntits3, family = glmmTMB::compois(link = "log"),
#                                     dispformula = ~logged_Fmetric)
#
# ## Trying the beta1 version of the "F-metric":
# ttBSy_comglmm1d <- glmmTMB::glmmTMB(brood_size ~ logged_woodyvol + logged_Fmetric_d2b1 + species +
#                                       logged_herby_area + manag_low + manag_high + light_pollution + noise_iq +
#                                       cumdd_30 + year + (1|id_nestbox),
#                                     data = ntits3, family = glmmTMB::compois(link = "log"),
#                                     dispformula = ~1)
#
# ## Same as D but with the tuned dispersion model:
# ttBSy_comglmm1e <- glmmTMB::glmmTMB(brood_size ~ logged_woodyvol + logged_Fmetric_d2b1 + species +
#                                       logged_herby_area + manag_low + manag_high + light_pollution + noise_iq +
#                                       cumdd_30 + year + (1|id_nestbox),
#                                     data = ntits3, family = glmmTMB::compois(link = "log"),
#                                     dispformula = ~logged_Fmetric)
# summary(ttBSy_comglmm1b) # AIC = 1403.4 vs 1407.7.
# summary(ttBSy_comglmm1c) # AIC = 1402.5.
# summary(ttBSy_comglmm1d) # AIC = 1403.5.
# summary(ttBSy_comglmm1e) # AIC = 1402.5.
#
#
#
#
#
# ### ** 2.2.3. Diagnostics and assumption checks ----
# # __________________________________________________
#
# ### *** 2.2.3.1. Residuals extraction, autocorrelation and collinearity ----
# ## Traditional residuals:
# par(.pardefault)
# resid <- stats::resid(ttBSy_comglmm1, type = 'response')
# plot(resid, id = 0.05, idLabels = ~.obs) # Ok-ish but there are a few potential outliers.
# # performance::check_outliers(ttBSy_comglmm1b) # Does not work for this type of model.
# ntits3[which(resid < -4),] # Four potential outliers! Given their location (i.e. Port du Canal, Arquebuse,
# # and Allee du Parc), we can indeed consider their low brood size as rather surprising.
#
# # To further investigate patterns, I can plot the residuals against some predictors:
# plot(x = ntits3$logged_Fmetric, y = resid) # There may be signs of heteroscedasticity for the "F-metric".
# # Otherwise, it seems ok (but, once again, simulated residuals will be more useful).
# # plot(ttBSy_comglmm1b, id_nestbox~stats::resid(.)) # Does not work for this type of model.
# # plot(ttBSy_comglmm1b, site~stats::resid(.)) # Does not work for this type of model.
#
# ## Simulation-based scaled residuals computation ({DHARMa} method):
# simu.resid <- DHARMa::simulateResiduals(fittedModel = ttBSy_comglmm1, n = 1000, re.form = NULL)
# plot(simu.resid) # Very strong deviations detected (as well as outliers)!
# DHARMa::outliers(simu.resid) # Two potential outliers!
# ntits3[c(16,33),] # Not sure to see why...
#
# ## Autocorrelation and collinearity:
# DHARMa::testSpatialAutocorrelation(simulationOutput = simu.resid,
#                                    x = ntits3$coord_x, y = ntits3$coord_y, plot = TRUE) # Ok.
# performance::check_autocorrelation(ttBSy_comglmm1) # Ok.
# performance::check_collinearity(ttBSy_comglmm1) # Ok-ish, but some VIF > 4-5!
# stats::vcov(ttBSy_comglmm1) # But values of the covariance matrix seem ok.
#
# ## Heteroscedasticity and possible model misspecifications:
# par(.pardefault)
# DHARMa::plotResiduals(simu.residc, form = ntits3$logged_woody_area)
# DHARMa::plotResiduals(simu.residc, form = ntits3$logged_Fmetric)
# DHARMa::plotResiduals(simu.residc, form = ntits3$urban_intensity)
# DHARMa::plotResiduals(simu.residc, form = ntits3$logged_herby_area)
# DHARMa::plotResiduals(simu.residc, form = ntits3$manag_intensity)
# DHARMa::plotResiduals(simu.residc, form = ntits3$light_pollution)
# DHARMa::plotResiduals(simu.residc, form = ntits3$noise_iq)
# DHARMa::plotResiduals(simu.residc, form = ntits3$cumdd_30)
# DHARMa::plotResiduals(simu.residc, form = ntits3$min_t_between)
# DHARMa::plotResiduals(simu.residc, form = ntits3$species)
# DHARMa::plotResiduals(simu.residc, form = ntits3$year)
# DHARMa::plotResiduals(simu.residc, form = ntits3$clutch_size) # Very strong effect!
# # All these plots are ok, except those of missing predictors.
#
#
#
# ### *** 2.2.3.2. Distribution (family, ZI, dispersion) ----
# ## Assessing over or under-dispersion:
# aods3::gof(ttBSy_comglmm1) # Does not work for this type of model!
# AER::dispersiontest(object = ttBSy_comglmm1, alternative = c("less")) # Does not work for this model type!
# DHARMa::testDispersion(simu.resid) # Ok.
#
# ## Theoretical count distribution:
# theo_count <- COMPoissonReg::rcmp(n = nrow(ntits3), lambda = mean(ntits3$brood_size),
#                                     nu = 1.05)  # The 'nu' parameter should be chosen by trial-and-errors.
# tc_df <- data.frame(theo_count)
#
# ggplot2::ggplot(ntits3, ggplot2::aes(brood_size)) +
#   ggplot2::geom_bar(fill = "#1E90FF") +
#   ggplot2::geom_bar(data = tc_df, ggplot2::aes(theo_count, fill="#1E90FF", alpha=0.5)) +
#   ggplot2::theme_classic() +
#   ggplot2::theme(legend.position = "none") # Blue = observed counts; red = simulated.
# # This plot suggests that brood_size could be following a COM-Poisson distribution of parameter nu~1.1.
#
# ## Distribution of the predicted counts:
# pred_counts <- stats::predict(object = ttBSy_comglmm1, type = "response") # Extract the predicted counts.
# par(mfrow= c(1,2))
# hist(pred_counts, main = "Predicted counts", xlab = "Number of hatched eggs")
# hist(ntits3$brood_size, main = "Observed counts", xlab = "Number of hatched eggs") # Compared to the
# # predictions when CS is included, these ones are clearly worse. Still, there're not that bad.
#
# ## Zero-inflation (ZI):
# DHARMa::testZeroInflation(simu.resid) # Nope.
#
#
#
# ### *** 2.2.3.3. Linearity ----
# ## Plotting the response on the log scale against predictors:
# ntits3 %>% dplyr::select(logged_woodyveg, logged_woody_area, woodyveg_sd, logged_woodyvol,
#                          logged_Fmetric, logged_Fmetric_d1, logged_Fmetric_d1b1, logged_Fmetric_d2b1,
#                          urban_intensity, logged_herby_area, logged_built_area, logged_traffic,
#                          light_pollution, noise_m, noise_iq,
#                          cumdd_30, min_t_before, min_t_between) -> mydata
# predictors <- colnames(mydata)
# # Bind log(Y) and tidying the data for plot (ggplot2, so long format):
# mydata <- mydata %>%
#   dplyr::mutate(log_y = log(ntits3$brood_size)) %>%
#   tidyr::gather(key = "predictors", value = "predictor.value", -log_y)
# # Create scatterplot
# ggplot2::ggplot(mydata, ggplot2::aes(y = log_y, x = predictor.value))+
#   ggplot2::geom_point(size = 0.5, alpha = 0.5) +
#   ggplot2::geom_smooth(method = "loess") +
#   ggplot2::theme_bw() +
#   ggplot2::facet_wrap(~predictors, scales = "free_x") # Linearity seems respected.
#
#
#
# ### *** 2.2.3.4. Model goodness-of-fit (GOF) and performances ----
# # GOF test of Pearson's Chi2 residuals:
# dat.resid <- sum(stats::resid(ttBSy_comglmm1, type = "pearson")^2)
# 1 - stats::pchisq(dat.resid, stats::df.residual(ttBSy_comglmm1)) # p = 0.49, indicating that there is no
# # significant lack of fit. Keep in mind though that GOF measures for mixed models is an extremely complicated
# # topic and interpretations are not straightforward.
#
# # Computing a pseudo-R2:
# performance::r2_nakagawa(ttBSy_comglmm1) # [Additive model]: Marg_R2_glmm = 0.6; Cond_R2_glmm = 0.07.
#
#
# ## Likelihood-ration tests (LRT) of GOF:
# # For the random-effects (RE):
# ttBSy_comglm1 <- glmmTMB::glmmTMB(brood_size ~ logged_woody_area + logged_Fmetric + species +
#                                      urban_intensity + manag_low + manag_high + light_pollution + noise_iq +
#                                      cumdd_30 + year + (1|site),
#                                    data = ntits3, family = glmmTMB::compois(link = "log"),
#                                    dispformula = ~1) # Rather long to fit.
# summary(ttBSy_comglm1) # The non-mixed model gives AIC = XXX while the mixed-model with "id_nestbox"
# # as RE gives AIC = XXX The one with "site" as RE also gives XXX, so it seems that the use of RE is
# # not warranted by the data!
#
# ## For the whole model:
# ttBSy_comglmm0 <- glmmTMB::glmmTMB(brood_size ~ 1 + (1|id_nestbox),
#                                   data = ntits3, family = glmmTMB::compois(link = "log"),
#                                   dispformula = ~1) # Rather long to fit.
# res.LRT_null <- stats::anova(object = ttBSy_comglmm0, ttBSy_comglmm1, test = "LRT")
# # The test is significant, confirming that the model is useful to explain the data.
#
#
#
#
# ### *** 2.2.3.5. Posterior predictive simulations ----
# # Predicted counts:
# par(.pardefault)
# obsprop <- prop.table(table(ntits3$brood_size))
# sims <- stats::simulate(ttBSy_comglmm1, nsim = 1000)
#
# nsim3 <- colSums(sims == 3) # Number of threes (min obs value)
# par(las=1,bty="l")
# plot(pt <- prop.table(table(nsim3)),
#      ylab="Probability", xlab="Number of threes")
# (obs3 <- sum(ntits3$brood_size == 3))
# points(obs3, 0.11, col="red", pch=16, cex=2) # See the y values in 'obsprop'!
#
# nsim8 <- colSums(sims == 8) # Number of eights (modal obs value).
# par(las=1,bty="l")
# plot(pt <- prop.table(table(nsim8)),
#      ylab="Probability", xlab="Number of eights")
# (obs8 <- sum(ntits3$brood_size == 8))
# points(obs8, 0.22, col="red", pch=16, cex=2)
#
# nsim14 <- colSums(sims == 14) # Number of fourteens (max obs value).
# par(las=1,bty="l")
# plot(pt <- prop.table(table(nsim14)),
#      ylab="Probability", xlab="Number of fourteens")
# (obs14 <- sum(ntits3$brood_size == 14))
# points(obs14, 0.004, col="red", pch=16, cex=2)
# # These three examples indicate that the model is not that bad even though it tends to under-predict the
# # low brood sizes!
#
#
#
# ### ** 2.2.4. Inference and predictions ----
# # __________________________________________
#
# ##### TO BE RUN §§§ -----
#
# ### *** 2.2.4.1. Hypotheses testing: LRT for the additive and interactive effect of the F-metric ----
# ## Parametric bootstrap to test the additive effect of the connectivity metric:
# ttBSy_comglmm0 <- stats::update(ttBSy_comglmm1, .~. -logged_Fmetric)
# summary(ttBSy_comglmm0) # AIC = 1413.8 vs 1407.7 (hypothesis likely validated)!
# # I do not run PB-based LRT for now as they take too long to run.
#
# # tictoc::tic("Parametric bootstrap LRT for the additive effect")
# # res.LRT_inteff <- DHARMa::simulateLRT(m0 = ttBSy_zicomglmm0, m1 = ttBSy_comglmm1, n = 500, seed = 107)
# # tt <- as.data.frame(cbind(res.LRT_inteff$method,
# #                           res.LRT_inteff$data.name,
# #                           res.LRT_inteff$statistic,
# #                           res.LRT_inteff$p.value))
# # rownames(tt) <- NULL
# # tt %>% dplyr::rename("Method" = V1,
# #                      "Models" = V2,
# #                      "Log Likelihood (M1/M0)" = V3,
# #                      "p-value" = V4) -> tt
# # readr::write_csv2(x = tt, file = here::here("output", "tables", "res.ttBSy_LRT_addeff.csv"))
# # tictoc::toc() # DISCLAIMER: took ~??? to run!
# # # The PB-based LRT is non-significant, indicating that our connectivity metric does not improve the
# # # description of the data here.
# # # NOTE: initially, normally I would use the more efficient 'pbkrtest::PBmodcomp()' instead of the
# # # 'DHARMa::simulateLRT()' function, but it doesn't work with {glmmTMB} objects.
#
#
# ## Parametric bootstrap to test the interactive effect of the connectivity metric:
# # To save some time, I don"t even bother computing the PB-based LRT for the interaction effect, it won't be
# # significant. I should improve my proxies and my models first.
#
#
#
# ### *** 2.2.4.2. Bootstrapped confidence intervals for estimated parameters ----
# tictoc::tic("Bootstrap CI for the additive COM-Poisson GLMM parameters")
# res.ttBSy_addeff_CI_boot <- confint(ttBSy_comglmm1, method="boot")
# tt <- as.data.frame(res.ttBSy_addeff_CI_boot)
# tt$parameters <- rownames(tt)
# readr::write_csv2(x = tt,
#                   file = here::here("output", "tables", "res.ttBSy_bootCI_addeff.csv"))
# tictoc::toc() # DISCLAIMER: took ~2h10 to run!
#
#
#
# ### *** 2.2.4.3. Conclusion ----
# # For the initial model:
# summary(ttBSy_comglmm1) # AIC = 1407.7 and Marg_R2_glmm = 0.6; Cond_R2_glmm = 0.07.
# # Diagnostics ran for 'ttBSy_comglmm1' (initial model) indicated that the model fit the data relatively well
# # although the model tends to under-predict the low brood sizes (BS)! They also confirmed that the RE were
# # not truly useful for this model while the use of a COM-Poisson distribution was relevant. Once again, we
# # got some fairly high (yet possibly acceptable) VIF values.
# ## Significant variables: woody_area (-), F-metric (+), speciesCC (+) and cumdd_30 (-).
# ## Almost significant variables: manag_high (+), light_pollution (-).
# ## Hypothesis 1 likely validated (AIC = 1413.8 vs 1407.7)!
# ## Hypothesis 2 is likely not validated (interaction effect not significant)!
# # IMPORTANT NOTE: I initially tried to include "clutch_size" as a covariate to focus on the variation that
# # is not due to variations in the number of eggs laid but, if that strongly lowered the AIC, diagnostics
# # were terribly off (strong deviations from uniformity) and singular fit. Therefore, I chose to remove it
# # since I cannot fathom why the diagnostics are so bad while results and predictions seem ok enough.
# ## With CS included: only years (+), CS (+) and woody_area (-) significant (AIC ~ 949), but hypothesis 2 is
# # not far from being validated! Still, it suggests that our F-metric plays no part in explaining tits' BS
# # once variations of CS have been accounted for.
#
# # Exploratory improved models:
# # While these models mildly improved AIC, suggesting once again that "herby_area" may be a suitable proxy,
# # overall results were rather similar. Therefore, I quickly diagnosed these models but do not report them.
#
#
#
#
#
# ########################## ************************************************* ###############################
# # ------------------------------------- #
# ##### 3. Modelling fledging success #####
# # ------------------------------------- #
#
# ##### * 3.1. Fledging success: Binomial GLMM -----------------------------------
# # ---------------------------------------------------------------------------- #
# ### ** 3.1.1. Initial model fit ----
# # __________________________________
#
# # Given the previous diagnostics, I chose to directly use "woody_area" instead of "woodyveg_vw" and to
# # delete the observations for which brood_size = 0 since they likely are true outliers (see comments in
# # the previous sections):
# ntits3 <- ntits2[-c(which(ntits2$brood_size == 0)),]
# ntits3 <- ntits3[-c(44,105,249),] # I also delete the 3 outliers found by initial diagnostics.
# ntits3$id_obs <- as.factor(1:nrow(ntits3)) # To create an observation-level RE (OLRE) to account for
# # overdispersion.
#
# ## Fitting a regular binomial GLM:
# ttFSy_glm1 <- stats::glm(fledgling_nb/brood_size ~ logged_woody_area + logged_Fmetric +
#                            clutch_size +
#                            urban_intensity + manag_intensity + light_pollution + noise_iq +
#                            cumdd_30 + year,
#                          weights = clutch_size, # Prior weights!
#                          data = ntits3, family = "binomial") # Weights should not be forgotten. Otherwise, the
# # formulation should be: cbind(fledgling_nb, brood_size-fledgling_nb)!
#
# ## Fitting a binomial GLMM:
# ttFSy_glmm1 <- glmmTMB::glmmTMB(fledgling_nb/brood_size ~ logged_woody_area + logged_Fmetric +
#                                   clutch_size +
#                                   urban_intensity + manag_intensity + light_pollution + noise_iq +
#                                   cumdd_30 + year + (1|id_obs) + (1|id_nestbox),
#                                 weights = brood_size, data = ntits3, family = "binomial") # Note here that
# # we replaced the RE by an OLRE as overdispersion was detected during diagnostics.
#
# ## Fitting a zero-inflated (ZI) binomial GLMM:
# ttFSy_ziglmm1 <- glmmTMB::glmmTMB(fledgling_nb/brood_size ~ logged_woody_area + logged_Fmetric +
#                                     clutch_size +
#                                     urban_intensity + manag_intensity + light_pollution + noise_iq +
#                                     cumdd_30 + year + (1|id_obs) + (1|id_nestbox),
#                                   weights = brood_size, data = ntits3, family = "binomial",
#                                   ziformula = ~1) # Intercept only.
# # Note that a "site" RE has been added because spatial autocorrelation was detected.
#
# ## Fitting an interactive (mediated) GLMM:
# ttFSy_ziglmm2 <- glmmTMB::glmmTMB(fledgling_nb/brood_size ~
#                                     scale(logged_woody_area, scale = F) * scale(logged_Fmetric, scale = F) +
#                                     clutch_size +
#                                     urban_intensity + manag_intensity + light_pollution + noise_iq +
#                                     cumdd_30 + year + (1|id_obs) + (1|id_nestbox),
#                                   weights = brood_size, data = ntits3, family = "binomial",
#                                   ziformula = ~1)
# summary(ttFSy_glm1) # AIC = 2141.1.
# summary(ttFSy_glmm1) # AIC = 1419.5.
# summary(ttFSy_ziglmm1) # AIC = 1333.8.
# summary(ttFSy_ziglmm2) # AIC = 1332.7 and significant interaction effect!
# # It seems that, if the inclusion of a random effect (OLRE) strongly improves the fit and so does accounting
# # for the zero-inflation (ZI)! I will thus carry on with the ZI-models to the diagnostic part.
#
# # UPDATE: As before, we explored a few reasonable variations of the same model by trying different proxies
# # of the same variable (see below).
# # Below, code and comments will show the diagnostics of several of these improved models (D and F), but you
# # can re-run the diagnostics for the initial models by replacing the model name in the code chunks
# # (i.e. the dataset with the deleted outliers).
#
#
#
#
#
# ### ** 3.1.2. Improved model (exploration) ----
# # _____________________________________________
#
# ## Using the beta1 "F-metric":
# ttFSy_ziglmm1a <- glmmTMB::glmmTMB(fledgling_nb/brood_size ~ logged_woody_area + logged_Fmetric_d2b1 +
#                                      clutch_size +
#                                      urban_intensity + manag_intensity + light_pollution + noise_iq +
#                                      cumdd_30 + year + (1|id_obs) + (1|id_nestbox),
#                                   weights = brood_size, data = ntits3, family = "binomial",
#                                   ziformula = ~1) # Intercept only.
# # NOTE: convergence issues!
#
# ## Using "woodyveg_vw":
# ttFSy_ziglmm1b <- glmmTMB::glmmTMB(fledgling_nb/brood_size ~ logged_woodyveg + logged_Fmetric +
#                                      clutch_size +
#                                      urban_intensity + manag_intensity + light_pollution + noise_iq +
#                                      cumdd_30 + year + (1|id_obs) + (1|id_nestbox),
#                                    weights = brood_size, data = ntits3, family = "binomial",
#                                    ziformula = ~1) # Intercept only.
#
# ## Using both:
# ttFSy_ziglmm1c <- glmmTMB::glmmTMB(fledgling_nb/brood_size ~ logged_woodyveg + logged_Fmetric_d2b1 +
#                                      clutch_size +
#                                      urban_intensity + manag_intensity + light_pollution + noise_iq +
#                                      cumdd_30 + year + (1|id_obs) + (1|id_nestbox),
#                                    weights = brood_size, data = ntits3, family = "binomial",
#                                    ziformula = ~1) # Intercept only.
# # These models do not improve anything.
# ## Tuning the ZI part of the model:
# ttFSy_ziglmm1d <- glmmTMB::glmmTMB(fledgling_nb/brood_size ~ logged_woody_area + logged_Fmetric +
#                                     clutch_size +
#                                     urban_intensity + manag_intensity + light_pollution + noise_iq +
#                                     cumdd_30 + year + (1|id_obs) + (1|id_nestbox),
#                                   weights = brood_size, data = ntits3, family = "binomial",
#                                   ziformula = ~min_t_between + logged_Fmetric)
#
# ## With the beta1 "F-metric":
# ttFSy_ziglmm1e <- glmmTMB::glmmTMB(fledgling_nb/brood_size ~ logged_woody_area + logged_Fmetric_d2b1 +
#                                     clutch_size +
#                                     urban_intensity + manag_intensity + light_pollution + noise_iq +
#                                     cumdd_30 + year + (1|id_obs) + (1|id_nestbox),
#                                   weights = brood_size, data = ntits3, family = "binomial",
#                                   ziformula = ~min_t_between + logged_Fmetric_d2b1)
# summary(ttFSy_ziglmm1a) # AIC = 1331.9 vs 1331.8.
# summary(ttFSy_ziglmm1b) # AIC = 1333.8.
# summary(ttFSy_ziglmm1c) # AIC = 1334.4.
# summary(ttFSy_ziglmm1d) # AIC = 1327.3
# summary(ttFSy_ziglmm1e) # AIC = 1326.1.
# performance::check_collinearity(ttFSy_ziglmm1e)
# colnames(ntits3)
#
# ttFSy_ziglmm1f <- glmmTMB::glmmTMB(fledgling_nb/brood_size ~
#                                     scale(logged_woody_area, scale = F) * scale(logged_Fmetric, scale = F) +
#                                     clutch_size +
#                                      urban_intensity + manag_intensity + light_pollution + noise_iq +
#                                     cumdd_30 + year + (1|id_obs) + (1|id_nestbox),
#                                   weights = brood_size, data = ntits3, family = "binomial",
#                                   ziformula = ~min_t_between + logged_Fmetric)
# summary(ttFSy_ziglmm1f) # AIC = 1325.3.
#
#
#
#
#
# ### ** 3.1.3. Diagnostics and assumption checks ----
# # __________________________________________________
#
# ### *** 3.1.3.1. Residuals extraction, autocorrelation and collinearity ----
# ## Traditional residuals:
# par(.pardefault)
# resid <- stats::resid(ttFSy_ziglmm1, type = 'response')
# plot(resid, id = 0.05, idLabels = ~.obs) # Strange distribution of residuals with 2 groups.
# # performance::check_outliers(ttFSy_ziglmm1) # Does not work for this type of model.
# ntits3[which(resid < -0.4),] # Nestboxes with the lowest residuals = ~0% fledging success! Interestingly,
# # they may belong to the same nestbox, suggesting a strong year effect.
#
# # To further investigate patterns, I can plot the residuals against some predictors:
# plot(x = ntits3$noise_iq, y = resid) # Seems rather ok although we once again find patterns linked to the
# # sometimes odd distribution of some predictors. However, be reminded that simulated residuals will be
# # more useful).
# # plot(ttHSy_ziglmm1, id_nestbox~stats::resid(.)) # Does not work for this type of model.
# # plot(ttHSy_ziglmm1, site~stats::resid(.)) # Does not work for this type of model.
#
# ## Simulation-based scaled residuals computation ({DHARMa} method):
# simu.resid <- DHARMa::simulateResiduals(fittedModel = ttFSy_ziglmm1, n = 1000, re.form = NULL) # The
# # 're.form' argument is to base simulations on the model unconditional of the random effects (and only works
# # for {lme4} formulations). It is useful for testing dispersion (see below) but can be omitted eventually.
# plot(simu.resid) # Ok for all 3 models (D,E,F).
# DHARMa::outliers(simu.resid) # Ok.
#
# ## Autocorrelation and collinearity:
# DHARMa::testSpatialAutocorrelation(simulationOutput = simu.resid,
#                                    x = ntits3$coord_x, y = ntits3$coord_y, plot = TRUE) # Ok-ish.
# performance::check_autocorrelation(ttFSy_ziglmm1) # Ok-ish.
# performance::check_collinearity(ttFSy_ziglmm1) # Moderately high VIF for model1,D,F, ok for model2!
# stats::vcov(ttFSy_ziglmm1) # But values of the covariance matrix seem ok.
#
# ## Heteroscedasticity and possible model misspecifications:
# par(.pardefault)
# DHARMa::plotResiduals(simu.residd, form = ntits3$logged_woody_area) # Slightly curved for model1!
# DHARMa::plotResiduals(simu.residd, form = ntits3$logged_Fmetric)
# DHARMa::plotResiduals(simu.residd, form = ntits3$urban_intensity)
# DHARMa::plotResiduals(simu.residd, form = ntits3$logged_herby_area)
# DHARMa::plotResiduals(simu.residd, form = ntits3$manag_intensity)
# DHARMa::plotResiduals(simu.residd, form = ntits3$light_pollution)
# DHARMa::plotResiduals(simu.residd, form = ntits3$noise_iq)
# DHARMa::plotResiduals(simu.residd, form = ntits3$cumdd_30) # Slight quantile deviation (for model1 and 2).
# DHARMa::plotResiduals(simu.residd, form = ntits3$min_t_between)
# DHARMa::plotResiduals(simu.residd, form = ntits3$species)
# DHARMa::plotResiduals(simu.residd, form = ntits3$year)
# DHARMa::plotResiduals(simu.residd, form = ntits3$clutch_size) # Slight quantile deviation (only model1).
# # No deviations for the improved exploratory models!
#
#
#
# ### *** 3.1.3.2. Distribution and dispersion ----
# ## Assessing over or under-dispersion:
# DHARMa::testDispersion(simu.resid) # Ok.
# # performance::check_overdispersion(x = ttFSy_ziglmm1) # Overdispersion detected but irrelevant.
# # ATTENTION: Classical overdispersion tests cannot be used to detect overdispersion when OLRE is used to
# # account for it.
#
# ## Distribution of the predicted probabilities:
# probabilities <- stats::predict(object = ttFSy_ziglmm1, type = "response") # Extract the predicted
# # probabilities.
# par(mfrow= c(1,2))
# hist(probabilities, main = "Predicted proportions", xlab = "Fledging success")
# hist(ntits3$fledgling_nb/ntits3$brood_size, main = "Observed proportions", xlab = "Fledging success")
# # All models fail to adequately fit the data although model2 (interaction model) is slightly better. They
# # all make too narrow predictions and fail to predict correctly the ZI, even D and F.
#
# ## Zero-inflation:
# DHARMa::testZeroInflation(simu.resid) # Ok.
# # Testing with the non-ZI GLMM:
# simu.resid_nozi <- DHARMa::simulateResiduals(fittedModel = ttFSy_glmm1, n = 1000)
# plot(simu.resid_nozi) # Clear deviations detected!
# noziprobabilities <- stats::predict(object = ttFSy_glmm1, type = "response") # Extract the predicted
# # probabilities.
# par(mfrow= c(1,2))
# hist(noziprobabilities)
# hist(ntits3$fledgling_nb/ntits3$brood_size) # Surprisingly, the model seems to better fit the observed
# # proportions, even though it still under-predicts the proportion of failures.
#
#
#
# ### *** 3.1.3.3. Linearity ----
# ## Plotting the response on the logit scale (= log odds) against predictors:
# # Format data:
# ntits3 %>% dplyr::select(logged_woodyveg, logged_woody_area, woodyveg_sd, logged_woodyvol,
#                          logged_Fmetric, logged_Fmetric_d1, logged_Fmetric_d1b1, logged_Fmetric_d2b1,
#                          urban_intensity, logged_herby_area, logged_built_area, logged_traffic,
#                          light_pollution, noise_m, noise_iq,
#                          cumdd_30, min_t_before, min_t_between) -> mydata
# predictors <- colnames(mydata)
# # Bind the logit and tidying the data for plot (ggplot2, so long format):
# mydata <- mydata %>%
#   dplyr::mutate(logit = log(probabilities/(1-probabilities))) %>%
#   tidyr::gather(key = "predictors", value = "predictor.value", -logit)
# # Create scatterplot:
# ggplot2::ggplot(mydata, ggplot2::aes(y = logit, x = predictor.value))+
#   ggplot2::geom_point(size = 0.5, alpha = 0.5) +
#   ggplot2::geom_smooth(method = "loess") +
#   ggplot2::theme_bw() +
#   ggplot2::facet_wrap(~predictors, scales = "free_x") # Linearity is respected except for "min_t_between"
# # which is U-shaped (but is currently not in the models).
#
#
#
# ### *** 3.1.3.4. Goodness-of-fit (GOF) and performances ----
# ## GOF test of Pearson's Chi2 residuals:
# dat.resid <- sum(stats::resid(ttFSy_ziglmm1, type = "pearson")^2)
# 1 - stats::pchisq(dat.resid, stats::df.residual(ttFSy_ziglmm1)) # p = 0 (mistake?).
#
# ## Computing a pseudo-R2:
# performance::r2_nakagawa(ttFSy_ziglmm1) # [Additive model]: Marg_R2_glmm = 0.15; Cond_R2_glmm = NA
# performance::r2_nakagawa(ttFSy_ziglmm2) # [Interactive model]: Marg_R2_glmm = 0.16; Cond_R2_glmm = NA
# performance::r2_nakagawa(ttFSy_ziglmm1d) # [Additive model]: Marg_R2_glmm = 0.16; Cond_R2_glmm = NA
# performance::r2_nakagawa(ttFSy_ziglmm1f) # [Interactive model]: Marg_R2_glmm = 0.15; Cond_R2_glmm = NA
# # But strange warning saying that "fledgling_nb" could not be found in the data and singular fit!
#
# ## Likelihood-ration tests (LRT) of GOF:
# # Importance of the random-effects (RE):
# ttFSy_ziglm1 <- glmmTMB::glmmTMB(fledgling_nb/brood_size ~ logged_woody_area + logged_Fmetric +
#                                    clutch_size +
#                                    urban_intensity + manag_intensity + light_pollution + noise_iq +
#                                    cumdd_30 + year,
#                                  weights = brood_size, data = ntits3, family = "binomial",
#                                  ziformula = ~1)
# summary(ttFSy_ziglm1) # The non-mixed model gives AIC = 1406.4 while the mixed-model gave AIC = 1333.8, so
# # the use of the mixed model seems warranted by the data!
#
# # Importance of the fixed effects:
# ttFSy_ziglmm0 <- glmmTMB::glmmTMB(fledgling_nb/brood_size ~ 1 + (1|id_obs) + (1|id_nestbox),
#                                 weights = brood_size, data = ntits3, family = "binomial",
#                                 ziformula = ~1)
# summary(ttFSy_ziglmm0) # AIC = 1419.2 vs 1333.8, so the full model is clearly far better!
#
#
#
#
#
# ### ** 3.1.4. Inference and predictions ----
# # __________________________________________
#
# ##### TO BE RUN §§§ -----
#
# ### *** 3.1.4.1. Hypotheses testing: LRT for the additive and interactive effect of the F-metric ----
# ## For the additive effect of the connectivity metric:
# ttFSy_ziglmm0 <- stats::update(ttFSy_ziglmm1, .~. -logged_Fmetric)
# ttFSy_ziglmm0d <- stats::update(ttFSy_ziglmm1d, .~. -logged_Fmetric)
# summary(ttFSy_ziglmm0) # AIC = NA vs 1333.8 (convergence issues)!
# summary(ttFSy_ziglmm0d) # AIC = 1330.3 vs 1327.3 (hypothesis perhaps validated)!
# # I do not run PB-based LRT for now as they take too long to run.
#
# # res.LRT_addeff <- pbkrtest::PBmodcomp(ttFSy_ziglmm1,
# #                                       ttFSy_ziglmm0, nsim = 500, seed = 56) # Took ~??? to run!
# # readr::write_csv2(x = res.LRT_addeff$test, file = here::here("output", "tables",
# #                                                              "res.ntitsFSy_LRT_addeff.csv"))
# # # The LRT is not significant, indicating that our connectivity metric does not improve the description of
# # # the data here.
#
# ## For the interaction effect:
# # Since even the additive model is NOT SIGNIFICANT, there is no point in testing the effect of the
# # interactive (mediated) model.
#
#
#
# ### *** 3.1.4.2. Bootstrapped confidence intervals for estimated parameters ----
# tictoc::tic("Bootstrap CI for additive GLMM parameters")
# res.ntitsFSy_addeff_CI_boot <- confint(ntitsFSy_ziglmm1, method="boot")
# tt <- as.data.frame(res.ntitsFSy_addeff_CI_boot)
# tt$parameters <- rownames(tt)
# readr::write_csv2(x = tt,
#                   file = here::here("output", "tables", "res.ntitsFSy_bootCI_addeff.csv"))
# tictoc::toc() # DISCLAIMER: took ~1h45 to run!
#
#
#
# ### *** 3.1.4.3. Conclusion ----
# # For the initial model:
# summary(ttFSy_ziglmm1) # AIC = 1333.8 and Marg_R2_glmm = 0.15; Cond_R2_glmm = NA
# summary(ttFSy_ziglmm2) # AIC = 1332.7 and Marg_R2_glmm = 0.15; Cond_R2_glmm = NA
# # Diagnostics ran for 'ttFSy_ziglmm1' (initial model) indicated that the model fit the data relatively well
# # although several problems have been detected:
# # - The raw residuals are divided in two groups suggesting the existence of possibly two different
# #   processes and thus, possible outliers (albeit formal test did not find any).
# # - Initially, there was overdispersion so I added an OLRE.
# # - A slight heteroscedasticity has been found.
# # - Signs of possibly problematic multicollinearity have been found for model1 (moderately high VIF values),
# #   but the interaction model is fine!
# # - The model under-predicts total successes and failures.
# # On the other hand, diagnostics also indicated that the use of a RE was appropriate.
# ## Significant variables: F-metric (+), clutch_size (-), manag_high (-), year2022.
# ## Almost significant variables: cumdd_30, year2020, and the INTERACTION TERM!
# ## Hypothesis 1 is likely validated (but NA since convergence issues), but not hypothesis 2 (yet almost)!
#
#
# # For the exploratory improved models:
# summary(ttFSy_ziglmm1d) # AIC = 1327.3 and Marg_R2_glmm = 0.16; Cond_R2_glmm = NA.
# ## Significant variables: F-metric (+), clutch_size (-), manag_high (-), year2020 and 2022. And also
# # [min_t_between (++) for dispersion]!
# ## Almost significant variables: cumdd_30.
# ## Hypothesis 1 possibly validated (AIC = 1330.3 vs 1327.3)!
# summary(ttFSy_ziglmm1f) # AIC = 1325.3 and Marg_R2_glmm = 0.15; Cond_R2_glmm = NA.
# ## Significant variables: clutch_size (-), manag_high (-), year2020 and 2022, and the INTERACTION EFFECT!
# # And also [min_t_between (++) for dispersion]!
# ## Almost significant variables: [F-metric (-) for dispersion]!
# ## Hypothesis 2 likely validated!
#
# # Diagnostics for these models were mostly ok, there was no outliers, deviations, dispersion or
# # distributional problems, even though there was some residual autocorrelation. However, there was some
# # worrying collinearity for model D and F.
# # Importantly, switching to "traffic" instead of "urban_intensity" could lower VIF values.
# # Predictions are fairly ok but the models still under-predict low fledging rates. They all make too narrow
# # predictions and fail to predict correctly the ZI, even D and F.
# # Also, strange warning saying that "fledgling_nb" could not be found in the data + singular fit + frequent
# # convergence issues (also for the initial models)!
#
#
#
#
#
# ##### *-----------------------------------------------------------------* ######
# ##### * 3.2. Fledgling number: ZICOM-Poisson GLMM ------------------------------
# # ---------------------------------------------------------------------------- #
# ### ** 3.2.1. Initial model fit ----
# # __________________________________
#
# # Given the previous diagnostics, I chose to directly use "woody_area" instead of "woodyveg_vw" and to
# # delete the observations for which brood_size = 0 since they likely are true outliers (see comments in
# # the previous sections):
# ntits3 <- ntits2[-c(which(ntits2$brood_size == 0)),]
# ntits3 <- ntits3[-c(44,105,249),] # I also delete the 3 outliers found by initial diagnostics.
# ntits3$id_obs <- as.factor(1:nrow(ntits3)) # To create an observation-level RE (OLRE) to account for
# # overdispersion.
#
# ## Fitting a regular Poisson GLM:
# ttFNy_glm1 <- stats::glm(fledgling_nb ~ logged_woody_area + logged_Fmetric +
#                            species +
#                            urban_intensity + manag_intensity + light_pollution + noise_iq +
#                            cumdd_30 + year,
#                          data = ntits3, family = "poisson")
#
# ## Fitting a regular Poisson GLMM:
# ttFNy_glmm1 <- glmmTMB::glmmTMB(fledgling_nb ~ logged_woody_area + logged_Fmetric +
#                                   species +
#                                   urban_intensity + manag_intensity + light_pollution + noise_iq +
#                                   cumdd_30 + year + (1|site),
#                                 data = ntits3, family = "poisson")
#
# ## Fitting a COM-Poisson GLMM:
# ttFNy_comglmm1 <- glmmTMB::glmmTMB(fledgling_nb ~ logged_woody_area + logged_Fmetric +
#                                      species +
#                                      urban_intensity + manag_intensity + light_pollution + noise_iq +
#                                      cumdd_30 + year + (1|site),
#                                    data = ntits3, family = glmmTMB::compois(link = "log"),
#                                    dispformula = ~1) # Rather long to fit.
#
# ## Fitting a ZICOM-Poisson GLMM:
# ttFNy_zicomglmm1 <- glmmTMB::glmmTMB(fledgling_nb ~ logged_woody_area + logged_Fmetric +
#                                      species +
#                                      urban_intensity + manag_intensity + light_pollution + noise_iq +
#                                      cumdd_30 + year + (1|site),
#                                    data = ntits3, family = glmmTMB::compois(link = "log"),
#                                    dispformula = ~1,
#                                    ziformula = ~1) # Rather long to fit.
# summary(ttFNy_glm1) # AIC = 1889.9
# summary(ttFNy_glmm1) # AIC = 1888.3
# summary(ttFNy_comglmm1) # AIC = 1840.9.
# summary(ttFNy_zicomglmm1) # AIC = 1634.6.
#
# ## Fitting an interactive (mediated) COM-Poisson GLMM:
# ttFNy_zicomglmm2 <- glmmTMB::glmmTMB(fledgling_nb ~
#                                        scale(logged_woody_area, scale = F) * scale(logged_Fmetric, scale = F) +
#                                        species +
#                                        urban_intensity + manag_intensity + light_pollution + noise_iq +
#                                        cumdd_30 + year + (1|site),
#                                      data = ntits3, family = glmmTMB::compois(link = "log"),
#                                      dispformula = ~1,
#                                      ziformula = ~1) # Rather long to fit.
# summary(ttFNy_zicomglmm2) # AIC = 1549.4 (almost significant)!
# # Overall, it seems that, if the inclusion of a random effect (RE) only mildly improved the fit, accounting
# # for the likely underdispersion and the ZI strongly improved the fit! I will thus carry on with the last two
# # models to the diagnostic part.
# # Note also that I initially tried to include "clutch_size" (CS) or "brood_size" (BS) as a covariate to focus
# # on the variation that is not due to variations in the number of eggs laid or hatched but, if that strongly
# # lowered the AIC, diagnostics were once again quite bad (e.g. strong deviations from uniformity). Therefore,
# # I chose to remove it which means that we are actually modelling a part of CS and BS variability as well.
# # Diagnostics also showed that the "site" RE was to be preferred to the "id_nestbox".
#
# # UPDATE: as before, I explored a few variations and, in addition to the initial models ('ttFNy_zicomglmm1'
# # and 'ttFNy_zicomglmm2'), I will also diagnose models 1D and 2B (see below).
#
#
#
#
#
# ### ** 3.2.2. Improved model (exploration) ----
# # _____________________________________________
#
# ttFNy_zicomglmm1a <- glmmTMB::glmmTMB(fledgling_nb ~ logged_woody_area + logged_Fmetric +
#                            hatching_rate +
#                                        urban_intensity + manag_intensity + light_pollution + noise_iq +
#                                        cumdd_30 + year + (1|site),
#                                      data = ntits3, family = glmmTMB::compois(link = "log"),
#                                      dispformula = ~hatching_rate+logged_Fmetric,
#                                      ziformula = ~1)
# ttFNy_zicomglmm1b <- glmmTMB::glmmTMB(fledgling_nb ~ logged_woody_area + logged_Fmetric_d2b1 +
#                            hatching_rate +
#                                        urban_intensity + manag_intensity + light_pollution + noise_iq +
#                                        cumdd_30 + year + (1|site),
#                                      data = ntits3, family = glmmTMB::compois(link = "log"),
#                                      dispformula = ~hatching_rate+logged_Fmetric_d2b1,
#                                      ziformula = ~1)
# ttFNy_zicomglmm1c <- glmmTMB::glmmTMB(fledgling_nb ~ logged_woody_area + logged_Fmetric +
#                            hatching_rate +
#                                        urban_intensity + manag_intensity + light_pollution + noise_iq +
#                                        cumdd_30 + year + (1|site),
#                                      data = ntits3, family = glmmTMB::compois(link = "log"),
#                                      dispformula = ~hatching_rate+logged_Fmetric_d2b1,
#                                      ziformula = ~1)
# ttFNy_zicomglmm1d <- glmmTMB::glmmTMB(fledgling_nb ~ logged_woody_area + logged_Fmetric +
#                            hatching_rate +
#                                        urban_intensity + manag_intensity + light_pollution + noise_iq +
#                                        cumdd_30 + year + (1|site),
#                                      data = ntits3, family = glmmTMB::compois(link = "log"),
#                                      dispformula = ~hatching_rate+logged_Fmetric,
#                                      ziformula = ~min_t_between+logged_Fmetric)
# summary(ttFNy_zicomglmm1a) # AIC = 1601.2 vs 1634.6.
# summary(ttFNy_zicomglmm1b) # AIC = 1607.4.
# summary(ttFNy_zicomglmm1c) # AIC = 1604.2.
# summary(ttFNy_zicomglmm1d) # AIC = 1594.1.
#
# ttFNy_zicomglmm2a <- glmmTMB::glmmTMB(fledgling_nb ~
#                                        scale(logged_woody_area, scale = F) * scale(logged_Fmetric, scale = F) +
#                            hatching_rate +
#                                        urban_intensity + manag_intensity + light_pollution + noise_iq +
#                                        cumdd_30 + year + (1|site),
#                                      data = ntits3, family = glmmTMB::compois(link = "log"),
#                                      dispformula = ~hatching_rate+logged_Fmetric,
#                                      ziformula = ~1)
# ttFNy_zicomglmm2b <- glmmTMB::glmmTMB(fledgling_nb ~
#                                        scale(logged_woody_area, scale = F) * scale(logged_Fmetric, scale = F) +
#                            hatching_rate +
#                                        urban_intensity + manag_intensity + light_pollution + noise_iq +
#                                        cumdd_30 + year + (1|site),
#                                      data = ntits3, family = glmmTMB::compois(link = "log"),
#                                      dispformula = ~hatching_rate+logged_Fmetric,
#                                      ziformula = ~min_t_between+logged_Fmetric)
# summary(ttFNy_zicomglmm2a) # AIC = 1592.4 vs 1857.1.
# summary(ttFNy_zicomglmm2b) # AIC = 1585.3 vs 1857.1.
#
#
#
#
#
# ### ** 3.2.3. Diagnostics and assumption checks ----
# # __________________________________________________
#
# ### *** 3.2.3.1. Residuals extraction, autocorrelation and collinearity ----
# ## Traditional residuals:
# par(.pardefault)
# resid <- stats::resid(ttFNy_zicomglmm1, type = 'response')
# plot(resid, id = 0.05, idLabels = ~.obs) # Ok-ish but likely two groups.
# ntits3[which(resid < -4),] # As could have been guessed from the plot, the 2nd group (with the lowest
# # residuals) consist of all the observations where "fledgling_nb" ~ 0 or is low. It could be a sign that
# # the zero-part of the model should indeed be modelled with more relevant predictors.
#
# # To further investigate patterns, I can plot the residuals against some predictors:
# plot(x = ntits3$hatching_rate, y = resid,
#      xlab = "Hatching rate", ylab = "Raw residuals") # Heteroscedasticity for HS?
#
# ## Simulation-based scaled residuals computation ({DHARMa} method):
# simu.resid <- DHARMa::simulateResiduals(fittedModel = ttFNy_zicomglmm1, n = 1000, re.form = NULL)
# simu.resid2 <- DHARMa::simulateResiduals(fittedModel = ttFNy_zicomglmm2, n = 1000, re.form = NULL)
# simu.resid1d <- DHARMa::simulateResiduals(fittedModel = ttFNy_zicomglmm1d, n = 1000, re.form = NULL)
# simu.resid2b <- DHARMa::simulateResiduals(fittedModel = ttFNy_zicomglmm2b, n = 1000, re.form = NULL)
# # The 're.form' argument is to base simulations on the model unconditional of the random effects (and only
# # works for {lme4} formulations). It is useful for testing dispersion (see below) but can be omitted
# # eventually.
# plot(simu.resid) # Slight deviation for model2!
# DHARMa::outliers(simu.resid) # None.
#
# ## Autocorrelation and collinearity:
# DHARMa::testSpatialAutocorrelation(simulationOutput = simu.resid,
#                                    x = ntits3$coord_x, y = ntits3$coord_y, plot = TRUE) # Nope!
# performance::check_autocorrelation(ttFNy_zicomglmm1) # Ok.
# performance::check_collinearity(ttFNy_zicomglmm1) # Nope, moderate correlation for "species" for the
# # initial models! Ok for models 1D and 2B!
# stats::vcov(ttFNy_zicomglmm1) # Ok.
#
# ## Heteroscedasticity and possible model misspecifications:
# par(.pardefault)
# DHARMa::plotResiduals(simu.resid, form = ntits3$logged_woody_area)
# DHARMa::plotResiduals(simu.resid, form = ntits3$logged_Fmetric)
# DHARMa::plotResiduals(simu.resid, form = ntits3$urban_intensity)
# DHARMa::plotResiduals(simu.resid, form = ntits3$logged_herby_area)
# DHARMa::plotResiduals(simu.resid, form = ntits3$manag_intensity)
# DHARMa::plotResiduals(simu.resid, form = ntits3$light_pollution) # Slight quantile deviation (model1)!
# DHARMa::plotResiduals(simu.resid, form = ntits3$noise_iq) # Slight quantile deviation (model1 and 1D)!
# DHARMa::plotResiduals(simu.resid, form = ntits3$cumdd_30) # Slight quantile deviation (model1 and 2)!
# DHARMa::plotResiduals(simu.resid, form = ntits3$min_t_between)
# DHARMa::plotResiduals(simu.resid, form = ntits3$species)
# DHARMa::plotResiduals(simu.resid, form = ntits3$year)
# DHARMa::plotResiduals(simu.resid, form = ntits3$clutch_size) # Strong quantile deviation!
# DHARMa::plotResiduals(simu.resid, form = ntits3$brood_size) # Strong quantile deviation!
# DHARMa::plotResiduals(simu.resid, form = ntits3$hatching_rate) # Strong quantile deviation (models 1 and 2)!
# # Clearly, there are quite heavy deviation problems for models 1, 2, and some for model 1D. Model 2B however,
# # was fine for all variables!
#
#
#
# ### *** 3.2.3.2. Distribution (family, ZI, dispersion) ----
# ## Assessing over or under-dispersion:
# aods3::gof(ttFNy_zicomglmm1) # Does not work for this type of model!
# AER::dispersiontest(object = ttFNy_zicomglmm1, alternative = c("less")) # Does not work for this model type!
# DHARMa::testDispersion(simu.resid) # Ok.
#
# ## Theoretical count distribution:
# theo_count <- COMPoissonReg::rzicmp(n = nrow(ntits3), lambda = mean(ntits3$fledgling_nb),
#                                     nu = 1.1,  # The 'nu' parameter should be chosen by trial-and-errors.
#                                     p = 0.15) # And so does the probability of 0.
# tc_df <- data.frame(theo_count)
#
# ggplot2::ggplot(pm, ggplot2::aes(fledgling_nb)) +
#   ggplot2::geom_bar(fill = "#1E90FF") +
#   ggplot2::geom_bar(data = tc_df, ggplot2::aes(theo_count, fill="#1E90FF", alpha=0.5)) +
#   ggplot2::theme_classic() +
#   ggplot2::theme(legend.position = "none") # Blue = observed counts; red = simulated.
# # This plot suggests that fledgling_nb could be following a COM-Poisson distribution of parameter nu~0.95,
# # although that means that the dispersion is approximately equal to that of a regular Poisson.
#
# ## Distribution of the predicted counts:
# pred_counts <- stats::predict(object = ttFNy_zicomglmm2b, type = "response") # Extract the predicted counts.
# par(mfrow= c(1,2))
# hist(pred_counts, main = "Predicted counts", xlab = "Fledgling number")
# hist(ntits3$fledgling_nb, main = "Observed counts", xlab = "Fledgling number")
# # The "ttFNy_zicomglmm1" model yields quite poor predictions. Exploratory models yield better results but
# # all over-predict low counts and fail to properly model the ZI!
#
# ## Zero-inflation (ZI):
# simu.resid_woZI <- DHARMa::simulateResiduals(fittedModel = ttFNy_comglmm1, n = 1000) # Model without ZI.
# DHARMa::testZeroInflation(simu.resid) # Nope.
# DHARMa::testZeroInflation(simu.resid_woZI) # Yes, so there truly is a ZI. Yet, this model accounts for it but
# # cannot predict it properly.
#
#
#
# ### *** 3.2.3.3. Linearity ----
# ## Plotting the response on the log scale against predictors:
# ntits3 %>% dplyr::select(logged_woodyveg, logged_woody_area, logged_woodyvol,
#                          logged_Fmetric, logged_Fmetric_d1, logged_Fmetric_d1b1, logged_Fmetric_d2b1,
#                          urban_intensity, logged_herby_area, logged_built_area, logged_traffic,
#                          light_pollution, noise_m, noise_iq,
#                          cumdd_30, min_t_before, min_t_between,
#                          hatching_rate, brood_size, clutch_size) -> mydata
# predictors <- colnames(mydata)
# # Bind log(Y) and tidying the data for plot (ggplot2, so long format):
# mydata <- mydata %>%
#   dplyr::mutate(log_y = log(ntits3$fledgling_nb+1)) %>%
#   tidyr::gather(key = "predictors", value = "predictor.value", -log_y)
# # Create scatterplot
# ggplot2::ggplot(mydata, ggplot2::aes(y = log_y, x = predictor.value))+
#   ggplot2::geom_point(size = 0.5, alpha = 0.5) +
#   ggplot2::geom_smooth(method = "loess") +
#   ggplot2::theme_bw() +
#   ggplot2::facet_wrap(~predictors, scales = "free_x") # The linearity is respected.
#
#
#
# ### *** 3.2.3.4. Model goodness-of-fit (GOF) and performances ----
# # GOF test of Pearson's Chi2 residuals:
# dat.resid <- sum(stats::resid(ttFNy_zicomglmm1, type = "pearson")^2)
# 1 - stats::pchisq(dat.resid, stats::df.residual(ttFNy_zicomglmm1)) # p ~ 0.4-0.55 for all models, indicating
# # that there is no significant lack of fit. Keep in mind though that GOF measures for mixed models is an
# # extremely complicated topic and interpretations are not straightforward.
#
# # Computing a pseudo-R2:
# performance::r2_nakagawa(ttFNy_zicomglmm1) # [Additive model]: Marg_R2_glmm = 0.03; Cond_R2_glmm = 0.05.
# performance::r2_nakagawa(ttFNy_zicomglmm2) # [Interactive model]: Marg_R2_glmm = 0.04; Cond_R2_glmm = 0.05.
# performance::r2_nakagawa(ttFNy_zicomglmm1d) # [Additive model]: NA.
# performance::r2_nakagawa(ttFNy_zicomglmm2b) # [Interactive model]: NA.
#
#
# ## Likelihood-ration tests (LRT) of GOF:
# # For the random-effects (RE):
# ttFNy_zicomglm1 <- glmmTMB::glmmTMB(fledgling_nb ~ logged_woody_area + logged_Fmetric +
#                                       species +
#                                       urban_intensity + manag_intensity + light_pollution + noise_iq +
#                                       cumdd_30 + year,
#                                     data = ntits3, family = glmmTMB::compois(link = "log"),
#                                     dispformula = ~1,
#                                     ziformula = ~1) # Rather long to fit.
# summary(ttFNy_zicomglm1) # AIC = 1635 vs 1634.6, so the inclusion of the RE does not seem warranted by the
# # data. Still, we will keep using it as it is the originally intended model.
#
# ## For the whole model:
# ttFNy_zicomglm0 <- glmmTMB::glmmTMB(fledgling_nb ~ 1,
#                                     data = ntits3, family = glmmTMB::compois(link = "log"),
#                                     dispformula = ~1,
#                                     ziformula = ~1)
# res.LRT_null <- stats::anova(object = ttFNy_zicomglm0, ttFNy_zicomglm1, test = "LRT")
# # The test is significant, confirming that the model is useful to explain the data.
#
#
#
# ### *** 3.2.3.5. Posterior predictive simulations ----
# # Predicted counts:
# par(.pardefault)
# obsprop <- prop.table(table(ntits3$fledgling_nb))
# sims <- stats::simulate(ttFNy_zicomglmm1, nsim = 1000)
#
# nsim0 <- colSums(sims == 0) # Number of zeros (min obs value)
# par(las=1,bty="l")
# plot(pt <- prop.table(table(nsim0)),
#      ylab="Probability", xlab="Number of zeros (true = 42)")
# (obs0 <- sum(ntits3$fledgling_nb == 0))
# points(obs0, 0.12, col="red", pch=16, cex=2) # See the y (0.06) values in 'obsprop'!
#
# nsim8 <- colSums(sims == 8) # Number of eights (second modal obs value).
# par(las=1,bty="l")
# plot(pt <- prop.table(table(nsim8)),
#      ylab="Probability", xlab="Number of eights (true = 63)")
# (obs8 <- sum(ntits3$fledgling_nb == 8))
# points(obs8, 0.17, col="red", pch=16, cex=2)
#
# nsim12 <- colSums(sims == 12) # Number of twelves (max obs value).
# par(las=1,bty="l")
# plot(pt <- prop.table(table(nsim12)),
#      ylab="Probability", xlab="Number of twelves (true = 2)")
# (obs12 <- sum(ntits3$fledgling_nb == 12))
# points(obs12, 0.005, col="red", pch=16, cex=2)
# # These three examples confirm that the model still predicts values that are too wide and overestimated
# # compared to the true observed values. Small successes are not correctly predicted!
#
#
#
#
#
# ### ** 3.2.4. Inference and predictions ----
# # __________________________________________
#
# ##### TO BE RUN §§§ -----
#
# ### *** 3.2.4.1. Hypotheses testing: LRT for the additive and interactive effect of the F-metric ----
# ## Parametric bootstrap to test the additive effect of the connectivity metric:
# ttFNy_zicomglmm0 <- stats::update(ttFNy_zicomglmm1, .~. -logged_Fmetric)
# ttFNy_zicomglmm0d <- stats::update(ttFNy_zicomglmm1d, .~. -logged_Fmetric)
# summary(ttFNy_zicomglmm0) # AIC = 1634.3 vs 1634.6 (hypothesis likely not validated)!
# summary(ttFNy_zicomglmm0d) # AIC = 1596.5 vs 1594.1 (hypothesis likely not validated)!
# # I do not run PB-based LRT for now as they take too long to run.
#
# # tictoc::tic("Parametric bootstrap LRT for the additive effect")
# # res.LRT_inteff <- DHARMa::simulateLRT(m0 = ntitsFNy_zicomglmm0, m1 = ntitsFNy_zicomglmm1, n = 500, seed = 97)
# # tt <- as.data.frame(cbind(res.LRT_inteff$method,
# #                           res.LRT_inteff$data.name,
# #                           res.LRT_inteff$statistic,
# #                           res.LRT_inteff$p.value))
# # rownames(tt) <- NULL
# # tt %>% dplyr::rename("Method" = V1,
# #                      "Models" = V2,
# #                      "Log Likelihood (M1/M0)" = V3,
# #                      "p-value" = V4) -> tt
# # readr::write_csv2(x = tt, file = here::here("output", "tables", "res.ntitsFNy_LRT_addeff.csv"))
# # tictoc::toc() # DISCLAIMER: took ~??? to run!
# # # The PB-based LRT is XXX, indicating that our connectivity metric (does not?) improve the
# # # description of the data here.
# # # NOTE: initially, normally I would use the more efficient 'pbkrtest::PBmodcomp()' instead of the
# # # 'DHARMa::simulateLRT()' function, but it doesn't work with {glmmTMB} objects.
#
#
# ## Parametric bootstrap to test the interactive effect of the connectivity metric:
# # To save some time, I don"t even bother computing the PB-based LRT for the interaction effect, it won't be
# # significant. I should improve my proxies and my models first.
#
#
#
# ### *** 3.2.4.2. Bootstrapped confidence intervals for estimated parameters ----
# tictoc::tic("Bootstrap CI for the additive COM-Poisson GLMM parameters")
# res.ntitsFNy_addeff_CI_boot <- confint(ntitsFNy_zicomglmm1, method="boot")
# tt <- as.data.frame(res.ntitsFNy_addeff_CI_boot)
# tt$parameters <- rownames(tt)
# readr::write_csv2(x = tt,
#                   file = here::here("output", "tables", "res.ntitsFNy_bootCI_addeff.csv"))
# tictoc::toc() # DISCLAIMER: took ~??? to run!
#
#
#
# ### *** 3.2.4.3. Conclusion ----
# # For the initial model:
# summary(ttFNy_zicomglmm1) # AIC = 1634.6 and Marg_R2_glmm = 0.03; Cond_R2_glmm = 0.05.
# summary(ttFNy_zicomglmm2) # AIC = 1633.7 and Marg_R2_glmm = 0.04; Cond_R2_glmm = 0.05.
# # Diagnostics ran for 'ttFNy_zicomglmm1' and 2 (initial models) indicated that the models do not fit the data
# # very well. Moreover, several problems were detected:
# # - The raw residuals are divided in two groups suggesting the existence of possibly two different
# #   processes and thus, possible outliers (albeit formal test did not find any).
# # - Quite strong deviations from homogeneity have been found in the simulated residuals!
# # - Signs of possibly problematic multicollinearity have been found (moderately high VIF values), likely
# #   due to species and thus to missing variables such as CS, BS or HS!
# # - The models do not make accurate predictions, especially of the ZI.
# ## Significant variables: speciesCC (+), cumdd_30 (-), year2020 and 2022 (+).
# ## Almost significant variables: light_pollution and the interaction term (only for model2).
# ## Hypothesis 1 and 2 are probably not validated!
#
#
# # For the exploratory improved models:
# summary(ttFNy_zicomglmm1d) # AIC = 1594.1 and NA for R2.
# ## Significant variables: F-metric (-), hatching_rate (++), cumdd_30 (-), year2022 (++). And also
# # [min_t_between (+) for ZI; and HS (--) and F-metric (-) for dispersion]!
# ## Almost significant variables: year2020. And also [F-metric (-) for ZI]!
# ## Hypothesis 1 may be validated but really NOT SURE (AIC = 1596.5 vs 1594.1)!
# summary(ttFNy_zicomglmm2b) # AIC = 1585.3 and NA for R2.
# ## Significant variables: F-metric (-), hatching_rate (++), manag_high (-), cumdd_30 (-), year2022 (++), and
# # the INTERACTION EFFECT (-)! And also [min_t_between (+) for ZI; and HS (--) and F-metric (-) for dispersion]!
# ## Almost significant variables: year2020, light_pollution (-). And also [F-metric (-) for ZI]!
# ## Hypothesis 2 likely validated but hard to interpret.
#
# # Diagnostics for these models were mostly ok, there was no outliers or distributional problems, and only a
# # slight deviation for model 1D while 2B was fine. VIF values were ok for both models.
# # However, predictions were rather poor even though they were slightly better than for the initial models.
# # All models over-predicted low counts and fail to properly model the ZI!
# # Once again, it may be a sign of the need to better model the ZI or to consider these values as outliers that
# # should be removed. That could perhaps explain why the F-metric had a NEGATIVE EFFECT of fledgling numbers!
# # It could also be due to missing variables or interactions... Anyway, these models are encouraging but
# # not satisfying.
#
#
#
#
#
# ########################## ************************************************* ###############################
# # ----------------------------------------------- #
# ##### 4. Modelling the morphometric variables #####
# # ----------------------------------------------- #
#
# ##### * 4.1. Morphometry: LMM ---------------------------------------------------
# # ---------------------------------------------------------------------------- #
# ### ** 4.1.1. Initial model fit ----
# # __________________________________
#
#
#
#
# # DISCLAIMER: to gain some time, I do not run this section yet. Go to section 4.2. directly!
# # DISCLAIMER: to gain some time, I do not run this section yet. Go to section 4.2. directly!
#
#
#
#
# # ## Creating a synthetic morphometric variable:
# # ntits2 %>% dplyr::filter(is.na(wing_length) == FALSE) -> ntits3 # Only 141 observations left.
# # ntits3 %>% dplyr::select(id_nestbox, site, mass, tarsus_length, wing_length) -> xxx
# #
# # # Normed-PCA:
# # res.pca <- FactoMineR::PCA(X = xxx[, 3:ncol(xxx)], scale.unit = TRUE, graph = FALSE)
# # # To plot results:
# # morpho_pm.varplot <- factoextra::fviz_pca_var(res.pca, col.var = "contrib",
# #                                               gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
# #                                               repel = TRUE)
# # morpho_pm.indplot <- plot(res.pca, choix = "ind", autoLab = "yes")
# # #gridExtra::grid.arrange(morpho_pm.varplot, morpho_pm.indplot, ncol = 2)
# #
# # # As the first axis (PC) of my PCA satisfactorily synthesizes a large amount of the variance (84.5%)
# # # of my three variables, we can use the coordinates of observations on this axis as a synthetic variable:
# # zzz <- res.pca$ind$coord[,1]
# # ntits3$morphometry <- zzz # This variable opposes nestboxes that host "big" (potentially well-fed) nestlings.
# #
# #
# # ## Fitting a regular linear model:
# # ntitsMMy_lm1 <- stats::lm(morphometry ~ logged_woodyveg + logged_Fmetric +
# #                          urban_intensity + cumdd_30 + father_cond + mother_cond + year, data = ntits3)
# # # ntitsMMy_lm2 <- stats::lm(morphometry ~ scale(logged_woodyveg, scale = F) * scale(logged_Fmetric,
# # #                                                                                   scale = F) +
# # #                            urban_intensity + year, data = ntits3) # Interaction not significant!
# #
# #
# # ## Fitting an additive LMM:
# # ntitsMMy_lmm1 <- lme4::lmer(morphometry ~ logged_woodyveg + logged_Fmetric + urban_intensity +
# #                            cumdd_30 + year + (1|id_nestbox), data = ntits3)
# # # Gives a singular fit (RE variance = 0). I'll thus try setting a weak prior on the variance:
# # ntitsMMy_blmm1 <- blme::blmer(morphometry ~ logged_woodyveg + logged_Fmetric + urban_intensity +
# #                              cumdd_30 + year + (1|id_nestbox), data = ntits3)
# # # As there are convergence issues, I change the optimizer and increase iterations:
# # ntitsMMy_blmm2 <- stats::update(ntitsMMy_blmm1, control=lme4::lmerControl(optimizer="bobyqa",
# #                                                                     optCtrl=list(maxfun=2e5)))
# # # # Try all optimizers:
# # # ntitsMMy_blmm2_all <- lme4::allFit(ntitsMMy_blmm2)
# # # summary(ntitsMMy_blmm2_all) # Two optimizers failed to converge but give rather similar results, except the
# # # # "nloptwrap.NLOPT_LN_BOBYQA" optimizer that computes a larger RE variance and thus, lower coefficient
# # # # estimates. We will thus stick with "bobyqa".
# #
# # ## Fitting interactive (mediated) LMMs:
# # ntitsMMy_blmm3 <- blme::blmer(morphometry ~
# #                              scale(logged_woodyveg, scale = F) * scale(logged_Fmetric, scale = F) +
# #                              urban_intensity + cumdd_30 + year + (1|id_nestbox), data = ntits3,
# #                            control=lme4::lmerControl(optimizer="bobyqa",
# #                                                      optCtrl=list(maxfun=2e5)))
# # # # Test by removing possible overly influential observations:
# # # ntits2_wo <- ntits2[-c(49,58,50,143),]
# # # ntitsFSy_glmm3_wo <- stats::update(ntitsFSy_glmm3, data=ntits2_wo)
# # # summary(ntitsFSy_glmm3)$AIC
# # # summary(ntitsFSy_glmm3_wo)$AIC # Strongly improved AIC, BIC, and deviance. However, it yields lower R2_glmm!
# #
# #
# #
# #
# #
# # ### ** 4.1.2. Diagnostics and assumption checks ----
# # # __________________________________________________
# #
# # ### *** 4.1.2.1. Residuals extraction, autocorrelation and collinearity ----
# # ## Extracting residuals (with the {redres}):
# # raw_cond <- redres::compute_redres(ntitsMMy_blmm3) # Computes the raw conditional residuals (conditional on
# # # the random effects (RE)).
# # pearson_mar <- redres::compute_redres(ntitsMMy_blmm3, type = "pearson_mar") # Computes the Pearson marginal
# # # (not accounting for the RE) residuals.
# # std_cond <- redres::compute_redres(ntitsMMy_blmm3, type = "std_cond") # Computes the studentised cond. ones.
# # # Joins the residuals to the paprika data:
# # xxx <- cbind(ntits3, raw_cond, pearson_mar, std_cond)
# #
# # ## Simulation-based scaled residuals computation (DHARMa method):
# # simu.resid <- DHARMa::simulateResiduals(fittedModel = ntitsMMy_blmm3, n = 1000, plot = FALSE)
# # par(.pardefault)
# # plot(simu.resid) # Ok.
# #
# # ## Autocorrelation and collinearity:
# # DHARMa::testSpatialAutocorrelation(simulationOutput = simu.resid,
# #                                    x = ntits3$coord_x, y = ntits3$coord_y, plot = TRUE) # Ok.
# # performance::check_autocorrelation(ntitsMMy_blmm3) # Ok.
# # performance::check_collinearity(ntitsMMy_blmm3) # Ok.
# # stats::vcov(ntitsMMy_blmm3) # Ok, but "cumdd_30" has a slightly high covariance with the intercept.
# #
# #
# #
# # ### *** 4.1.2.2. Distribution and homoscedasticity ----
# # ## Assessing the normality of the residuals:
# # stats::shapiro.test(xxx$raw_cond) # Significant deviation from normality detected, but the Shapiro test is
# # # known to be extremely sensitive. So plotting would be better:
# # xxx %>%
# #   tidyr::gather(key = "type", value = "residual", 30:32) %>%
# #   ggplot2::ggplot(ggplot2::aes(x = residual)) +
# #   ggplot2::geom_histogram(bins = 20) +
# #   ggplot2::facet_grid(. ~ type, scales = "free") +
# #   ggplot2::theme_bw() # The residuals are indeed slightly left-skewed and possibly lack kurtosis but that
# # # could be acceptable.
# # redres::plot_resqq(ntitsMMy_blmm3) # As expected, the plot shows a substantial departure from Normality at the
# # # extreme ends of the quantiles, that is at the border of the parameters space. Overall, as almost all
# # # points stay within the 95% CI, we can say it is ok-ish.
# #
# # ## Assessing the normality if the random effect:
# # redres::plot_ranef(ntitsMMy_blmm3) # Same thing here.
# #
# # ## Assessing homogeneity of variance and influential observations:
# # plot(ntitsMMy_blmm3, type=c("p","smooth"), col.line = 2, id = 0.05, idLabels = ~.obs) # A slight curvature
# # # seem to exist and there are 5 possible outliers. Otherwise, there is no clear heteroscedasticity.
# # ntits3[c(10,86,46,97,61),] # RAS.
# #
# # # Residuals vs leverage:
# # plot(ntitsMMy_blmm3, stats::rstudent(.) ~ stats::hatvalues(.))
# # cd <- stats::cooks.distance(ntitsMMy_blmm3)
# # plot(cd)
# # ntits3[which(cd>0.4),] # Ok, all observations are < 0.5, so no overly influential points.
# # ntits3[which(cd>0.15),] # If we pick very conservative values, we find the same obs as before.
# #
# # ## Residuals vs predictors:
# # redres::plot_redres(ntitsMMy_blmm3, xvar = "scale(logged_Fmetric, scale = F)") +
# #   ggplot2::geom_smooth(method = "loess") +
# #   ggplot2::theme_classic() +
# #   ggplot2::labs(title = "Residual vs F-metric (log scale)") # Plotting residuals against the predictors
# # # does not give much odd results, but emphasized the incomplete sampling of the predictor
# # # space for some variables such as the F-metric.
# # # plot(ntits3$logged_Fmetric, stats::residuals(ntitsMMy_blmm3)) # Same plot (I should create a
# # # custom function).
# # redres::plot_redres(ntitsMMy_blmm3, type = "raw_mar", xvar = "year")
# #
# # ## Distribution of the predicted values:
# # par(.pardefault)
# # predictions <- stats::predict(object = ntitsMMy_blmm3, type = "response") # Extract the predicted values.
# # par(mfrow= c(1,2))
# # hist(predictions)
# # plot(ecdf(predictions))
# # fitdistrplus::plotdist(data = ntits3$morphometry, histo = TRUE, demp = TRUE) # Ok-ish...
# #
# #
# #
# # ### *** 4.1.2.3. Linearity ----
# # ## Plotting the response on the logit scale (= log odds) against predictors:
# # # Format data:
# # ntits3 %>% dplyr::select(woodyveg_vw, pmF_d60_beta0, urban_intensity, light_pollution, noise_iq, cumdd_30,
# #                       father_cond, mother_cond) %>%
# #   dplyr::mutate("Fmetric" = pmF_d60_beta0,
# #                 "Fmetric (log)" = log10(pmF_d60_beta0),
# #                 "woodyveg_vw" = woodyveg_vw,
# #                 "woodyveg_vw (log)" = log10(woodyveg_vw), .keep = "unused") -> mydata
# # predictors <- colnames(mydata)
# # # Bind 'morphometry' and tidying the data for plot (ggplot2, so long format):
# # mydata <- mydata %>%
# #   dplyr::mutate(morphometry = ntits3$morphometry) %>%
# #   tidyr::gather(key = "predictors", value = "predictor.value", -morphometry)
# # # Create scatterplot
# # ggplot2::ggplot(mydata, ggplot2::aes(y = morphometry, x = predictor.value))+
# #   ggplot2::geom_point(size = 0.5, alpha = 0.5) +
# #   ggplot2::geom_smooth(method = "loess") +
# #   ggplot2::theme_bw() +
# #   ggplot2::facet_wrap(~predictors, scales = "free_x") # We can see that the slight curvature seems to come
# # # from "urban_intensity" and it seems that log-transforming "woodyveg_vw" might not be such a good idea here
# # # as it enables an abnormal distortion effect of its lowest value (try without?). Otherwise ok!
# #
# #
# #
# # ### *** 4.1.2.4. Goodness-of-fit (GOF) and performances ----
# # ## Computing a pseudo-R2:
# # performance::r2_nakagawa(ntitsMMy_blmm2) # [Additive model]: Marg_R2_lmm = 0.31; Cond_R2_lmm = 0.38.
# # performance::r2_nakagawa(ntitsMMy_blmm3) # [Interact. model]: Marg_R2_lmm = 0.31; Cond_R2_lmm = 0.38.
# #
# # ## Likelihood-ration tests (LRT) of GOF:
# # # Importance of the "id_nestbox" random-effect (RE):
# # tictoc::tic("Parametric bootstrap LRT")
# # res.LRT_re <- DHARMa::simulateLRT(m0 = ntitsMMy_lm1, m1 = ntitsMMy_blmm2, n = 500, seed = 24)
# # tictoc::toc() # Took ~23s to run.
# # # The LRT is significant, suggesting that M1 better describes the data than M0, supporting the importance of
# # # the random effect!
# #
# # # Importance of the fixed effects (only using the LM):
# # ntitsMMy_lm0 <- stats::lm(morphometry ~ 1, data = ntits3)
# # res.LRT_null <- stats::anova(object = ntitsMMy_lm0, ntitsMMy_lm1, test = "LRT")
# # # The test is highly significant, confirming that the model is useful to explain the data.
# #
# #
# #
# #
# #
# # ### ** 4.1.3. Inference and predictions ----
# # # __________________________________________
# #
# # ### *** 4.1.3.1. Hypotheses testing: LRT for the additive and interactive effect of the F-metric ----
# # ## For the additive effect of the connectivity metric:
# # ntitsMMy_blmm1 <- stats::update(ntitsMMy_blmm2, .~. -logged_Fmetric)
# #
# # res.LRT_addeff <- pbkrtest::PBmodcomp(ntitsMMy_blmm2,
# #                                       ntitsMMy_blmm1, nsim = 1000, seed = 399) # Took ~85s to run!
# # readr::write_csv2(x = res.LRT_addeff$test, file = here::here("output", "tables",
# #                                                              "res.ntitsMMy_LRT_addeff.csv"))
# # # The LRT is significant, indicating that our connectivity metric does improve the description of the data.
# #
# #
# # ## For the interaction effect:
# # res.LRT_inteff <- pbkrtest::PBmodcomp(ntitsMMy_blmm3,
# #                                       ntitsMMy_blmm2, nsim = 1000, seed = 428) # Took ~67s to run!
# # readr::write_csv2(x = res.LRT_inteff$test, file = here::here("output", "tables",
# #                                                              "res.ntitsMMy_LRT_inteff.csv"))
# # # The LRT is NOT significant, indicating that our hypothesis of an interaction effect is not supported
# # # by the data.
# #
# #
# #
# # ### *** 4.1.3.2. Bootstrapped confidence intervals for estimated parameters ----
# # tictoc::tic("Bootstrap CI for additive LMM parameters")
# # res.ntitsMMy_addeff_CI_boot <- confint(ntitsMMy_blmm2, method="boot")
# # tt <- as.data.frame(res.ntitsMMy_addeff_CI_boot)
# # tt$parameters <- rownames(tt)
# # readr::write_csv2(x = tt,
# #                   file = here::here("output", "tables", "res.ntitsMMy_bootCI_addeff.csv"))
# # tictoc::toc() # DISCLAIMER: took ~17,7s to run!
# #
# #
# #
# # ### *** 4.1.3.3. Conclusion ----
# #
# # summary(ntitsMMy_blmm2)
# # # Our models only moderately fit the observed data. Nonetheless, the importance of the additive effect of
# # # connectivity is supported by both the parametric bootstrap LRT and the CI on the parameters.
# # # Diagnostics indicated that removing some influential observations as well as the lowest "woodyveg_vw"
# # # value (or un-loging it) could perhaps have an impact on the results.
# # # REMINDER: there are less variables because the sample size is smaller!
#
#
#
#
#
# ######################### *----------------------* #############################
# ##### * 4.2. Mass: LMM ---------------------------------------------------------
# # ---------------------------------------------------------------------------- #
# ### ** 4.2.1. Initial model fit ----
# # __________________________________
#
# ntits2 %>% dplyr::filter(is.na(mass) == FALSE) -> ntits3 # Only 309 observations left.
#
# ## Fitting a regular linear model:
# ttMAy_lm1 <- stats::lm(mass ~ logged_woody_area + logged_Fmetric +
#                          species + clutch_size +
#                          urban_intensity + manag_intensity + light_pollution + noise_iq +
#                          cumdd_30 + year, data = ntits3)
#
# ## Fitting an additive LMM:
# ttMAy_lmm1 <- glmmTMB::glmmTMB(mass ~ logged_woody_area + logged_Fmetric +
#                                  species + clutch_size +
#                                  urban_intensity + manag_intensity + light_pollution + noise_iq +
#                                  cumdd_30 + year + (1|id_nestbox),
#                                 data = ntits3, family = "gaussian")
# ttMAy_lmm1b <- lme4::lmer(mass ~ logged_woody_area + logged_Fmetric +
#                             species + clutch_size +
#                             urban_intensity + manag_intensity + light_pollution + noise_iq +
#                             cumdd_30 + year + (1|id_nestbox), data = ntits3,
#                             control=lme4::lmerControl(optimizer="bobyqa",
#                                                       optCtrl=list(maxfun=2e5))) # Same model but fitted
# # with {lme4} for comparison sake! Note however, that it is fitted by REML and, if not, it is singular!
#
# ## Fitting interactive (mediated) LMMs:
# ttMAy_lmm2 <- glmmTMB::glmmTMB(mass ~
#                            scale(logged_woody_area, scale = F) * scale(logged_Fmetric, scale = F) +
#                            species + clutch_size +
#                            urban_intensity + manag_intensity + light_pollution + noise_iq +
#                            cumdd_30 + year + (1|id_nestbox),
#                            data = ntits3, family = "gaussian")
# ttMAy_lmm2b <- lme4::lmer(mass ~
#                             scale(logged_woody_area, scale = F) * scale(logged_Fmetric, scale = F) +
#                             species + clutch_size +
#                             urban_intensity + manag_intensity + light_pollution + noise_iq +
#                             cumdd_30 + year + (1|id_nestbox), data = ntits3,
#                           control=lme4::lmerControl(optimizer="bobyqa",
#                                                     optCtrl=list(maxfun=2e5)))
# AIC(ttMAy_lm1) # AIC = 1128.3.
# summary(ttMAy_lmm1) # AIC = 1130.3.
# summary(ttMAy_lmm1b) # AIC = NA but likely very close.
# summary(ttMAy_lmm2) # AIC = 1132.1, does not seem supported by the data!
# # Note that for both LMM, RE variance is extremely low (nearly singular fit) which, with the AIC, suggests
# # that the use of a mixed-model is not warranted by the data.
# # OR hatching_rate/BS????????
# # OR hatching_rate/BS????????
# # OR hatching_rate/BS????????
# # OR hatching_rate/BS????????
# # OR hatching_rate/BS????????
#
#
#
#
#
#
# ### ** 4.2.2. Diagnostics and assumption checks ----
# # __________________________________________________
#
# ### *** 4.2.2.1. Residuals extraction, autocorrelation and collinearity ----
# ## Extracting residuals (with the {redres}):
# raw_cond <- redres::compute_redres(ttMAy_lmm1b) # Computes the raw conditional residuals (conditional on
# # the random effects (RE)).
# pearson_mar <- redres::compute_redres(ttMAy_lmm1b, type = "pearson_mar") # Computes the Pearson marginal
# # (not accounting for the RE) residuals.
# std_cond <- redres::compute_redres(ttMAy_lmm1b, type = "std_cond") # Computes the studentised cond. ones.
# # Joins the residuals to the data:
# xxx <- cbind(ntits3, raw_cond, pearson_mar, std_cond)
#
# ## Simulation-based scaled residuals computation (DHARMa method):
# simu.resid <- DHARMa::simulateResiduals(fittedModel = ttMAy_lmm1b, n = 1000, plot = FALSE)
# par(.pardefault)
# plot(simu.resid) # Ok.
#
# ## Autocorrelation and collinearity:
# DHARMa::testSpatialAutocorrelation(simulationOutput = simu.resid,
#                                    x = ntits3$coord_x, y = ntits3$coord_y, plot = TRUE) # Ok.
# performance::check_autocorrelation(ttMAy_lmm1b) # Ok.
# performance::check_collinearity(ttMAy_lmm1b) # Ok-ish but some VIF > 4-5 and moderate correlation for
# # "manag_intensity"!
# stats::vcov(ttMAy_lmm1b) # Ok-ish.
#
#
#
# ### *** 4.2.2.2. Distribution and homoscedasticity ----
# ## Assessing the normality of the residuals:
# stats::shapiro.test(xxx$raw_cond) # Ok. But plotting would be better:
# redres::plot_resqq(ttMAy_lmm1b) # As expected, the plot shows a substantial departure from Normality at the
# # extreme ends of the quantiles, that is at the border of the parameters space. Overall, as almost all
# # points stay within the 95% CI, we can say it is ok-ish.
# # Plotting them against each predictor:
# xxx %>%
#   tidyr::gather(key = "type", value = "residual",
#                 c(logged_woody_area, logged_Fmetric, clutch_size, urban_intensity, light_pollution,
#                   noise_iq, cumdd_30)) %>%
#   ggplot2::ggplot(ggplot2::aes(x = residual)) +
#   ggplot2::geom_histogram(bins = 20) +
#   ggplot2::facet_grid(. ~ type, scales = "free") +
#   ggplot2::theme_bw() # Residuals vs predictor plots look rather ok, even though some strange patterns can
# # be seen. I would not be too worried about them but they would require some further thinking.
#
# ## Assessing the normality in the random effect:
# redres::plot_ranef(ttMAy_lmm1b) # Same thing here.
#
# ## Assessing homogeneity of variance and influential observations:
# plot(ttMAy_lmm1b, type=c("p","smooth"), col.line = 2, id = 0.05, idLabels = ~.obs,
#      ylab = "Pearson's residuals", xlab = "Fitted values") # It's ok but there are a few possible outliers:
# ntits3[c(245,213,112,194,102,32,155),] # High residuals ~= heavy juveniles. RAS.
# ntits3[c(26,42,198,152,256,236,173,192,170),] # Low residuals ~= light juveniles. RAS.
#
# # Residuals vs leverage:
# plot(ttMAy_lmm1b, stats::rstudent(.) ~ stats::hatvalues(.))
# cd <- stats::cooks.distance(ttMAy_lmm1b)
# plot(cd, ylab = "Cook's distance")
# ntits3[which(cd>0.4),] # Ok, all observations are < 0.5, so no overly influential points.
# ntits3[which(cd>0.1),] # Even with very conservative values, it's ok!
#
# ## Residuals vs predictors:
# redres::plot_redres(ttMAy_lmm1b, xvar = "cumdd_30") +
#   ggplot2::geom_smooth(method = "loess") +
#   ggplot2::theme_classic() +
#   ggplot2::labs(title = "Residual vs predictor") # Globally ok, but strange pattern for CS?
# # plot(ntits3$logged_Fmetric, stats::residuals(ttMAy_lmm1b)) # Same plot (I should create a
# # custom function).
# redres::plot_redres(ttMAy_lmm1b, type = "raw_mar", xvar = "manag_intensity") # Ok.
#
# ## Distribution of the predicted values:
# par(.pardefault)
# predictions <- stats::predict(object = ttMAy_lmm1b, type = "response") # Extract the predicted values.
# par(mfrow= c(1,2))
# hist(predictions, main = "Predicted mass", xlab = "Nestling mass (g)")
# plot(ecdf(predictions), main = "Predicted CDF", xlab = "Nestling mass (g)")
# fitdistrplus::plotdist(data = ntits3$mass, histo = TRUE, demp = TRUE) # Rather ok.
#
#
#
# ### *** 4.2.2.3. Linearity ----
# ## Plotting the response on the logit scale (= log odds) against predictors:
# # Format data:
# ntits3 %>% dplyr::select(logged_woodyveg, logged_woody_area, logged_woodyvol,
#                          logged_Fmetric, logged_Fmetric_d1, logged_Fmetric_d1b1, logged_Fmetric_d2b1,
#                          urban_intensity, logged_herby_area, logged_built_area, logged_traffic,
#                          light_pollution, noise_m, noise_iq,
#                          cumdd_30, min_t_before, min_t_between,
#                          hatching_rate, brood_size, clutch_size) -> mydata
# predictors <- colnames(mydata)
# # Bind 'mass' and tidying the data for plot (ggplot2, so long format):
# mydata <- mydata %>%
#   dplyr::mutate(mass = ntits3$mass) %>%
#   tidyr::gather(key = "predictors", value = "predictor.value", -mass)
# # Create scatterplot
# ggplot2::ggplot(mydata, ggplot2::aes(y = mass, x = predictor.value))+
#   ggplot2::geom_point(size = 0.5, alpha = 0.5) +
#   ggplot2::geom_smooth(method = "loess") +
#   ggplot2::theme_bw() +
#   ggplot2::facet_wrap(~predictors, scales = "free_x") # Ok.
#
#
#
# ### *** 4.2.2.4. Goodness-of-fit (GOF) and performances ----
# ## Computing a pseudo-R2:
# performance::r2_nakagawa(ttMAy_lmm1b) # [Additive model]: Marg_R2_lmm = 0.79; Cond_R2_lmm = 79.
# performance::r2_nakagawa(ttMAy_lmm2) # [Interact. model]: Marg_R2_lmm = 0.79; Cond_R2_lmm = NA.
#
# ## Likelihood-ration tests (LRT) of GOF:
# # Importance of the "id_nestbox" random-effect (RE):
# tictoc::tic("Parametric bootstrap LRT")
# res.LRT_re <- DHARMa::simulateLRT(m0 = ttMAy_lm1, m1 = ttMAy_lmm1b, n = 1000, seed = 18)
# tictoc::toc() # Took ~24s to run.
# # The LRT is highly significant, suggesting that M1 better describes the data than M0, supporting the
# # importance of the random effect!
#
# # Importance of the fixed effects (only using the LM):
# ttMAy_lm0 <- stats::lm(mass ~ 1, data = ntits3)
# res.LRT_null <- stats::anova(object = ttMAy_lm0, ttMAy_lm1, test = "LRT")
# # The test is highly significant, confirming that the model is useful to explain the data.
#
#
#
#
#
# ### ** 4.2.3. Inference and predictions ----
# # __________________________________________
#
# ### *** 4.2.3.1. Hypotheses testing: LRT for the additive and interactive effect of the F-metric ----
# ## For the additive effect of the connectivity metric:
# ttMAy_lmm0b <- stats::update(ttMAy_lmm1b, .~. -logged_Fmetric)
#
# res.LRT_addeff <- pbkrtest::PBmodcomp(ttMAy_lmm1b,
#                                       ttMAy_lmm0b, nsim = 1000, seed = 7) # Took ~38s to run!
# readr::write_csv2(x = res.LRT_addeff$test, file = here::here("output", "tables",
#                                                              "res.ttMAy_LRT_addeff.csv"))
# # The LRT is significant, indicating that our connectivity metric does improve the description of the data.
#
#
# ## For the interaction effect:
# res.LRT_inteff <- pbkrtest::PBmodcomp(ttMAy_lmm2b,
#                                       ttMAy_lmm1b, nsim = 1000, seed = 444) # Took ~37s to run!
# readr::write_csv2(x = res.LRT_inteff$test, file = here::here("output", "tables",
#                                                              "res.ttMAy_LRT_inteff.csv"))
# # The LRT is NOT significant, indicating that our hypothesis of an interaction effect is not supported
# # by the data.
#
#
#
# ### *** 4.2.3.2. Bootstrapped confidence intervals for estimated parameters ----
# tictoc::tic("Bootstrap CI for additive LMM parameters")
# res.ttMAy_addeff_CI_boot <- confint(ttMAy_lmm1b, method="boot")
# tt <- as.data.frame(res.ttMAy_addeff_CI_boot)
# tt$parameters <- rownames(tt)
# readr::write_csv2(x = tt,
#                   file = here::here("output", "tables", "res.ttMAy_bootCI_addeff.csv"))
# tictoc::toc() # DISCLAIMER: took ~8s to run!
#
#
#
# ### *** 4.2.3.3. Conclusion ----
# # For the initial model:
# summary(ttMAy_lmm1b) # AIC = 1157.1 and Marg_R2_lmm = 0.79; Cond_R2_lmm = 79.
# summary(ttMAy_lmm2b) # AIC = 1157.5 and Marg_R2_lmm = 0.79; Cond_R2_lmm = NA.
# # Diagnostics ran for 'ttMAy_lmm1b' and 'ttMAy_lmm2b' (initial models) indicated that the models do fit the
# # data relatively well and that there are no major cause for concern:
# # - All sorts of residuals are globally fine. Even though some patterns exist and may require improvements.
# # - Assumptions all seem validated, although there is a mild multicollinearity with some VIF > 4-5 and
# #   moderate correlation for "manag_intensity".
# # - No true outliers but some with rather strange values (wide range for PM).
# ## Significant variables: F-metric (++), speciesCC (---), clutch_size (---), year2020 and 2022 (+).
# ## Almost significant variables: light_pollution (-) and noise_iq (-).
# ## Hypothesis 1 is validated (PB-based LRT; p = 0.043) but hypothesis 2 is rejected (p = 0.64)!
#
# # I did not run exploratory improved models yet, but improvements are likely possible.
#
#
#
#
#
# #################### *----------------------------------* ######################
# ##### * 4.3. Tarsus length: LMM ------------------------------------------------
# # ---------------------------------------------------------------------------- #
# ### ** 4.3.1. Initial model fit ----
# # __________________________________
#
# ## Fitting a regular linear model:
# ntits2 %>% dplyr::filter(is.na(tarsus_length) == FALSE) -> ntits3 # Only 246 observations left.
#
# ttTLy_lm1 <- stats::lm(tarsus_length ~ logged_woody_area + logged_Fmetric +
#                          species + clutch_size +
#                          urban_intensity + manag_intensity + light_pollution + noise_iq +
#                          cumdd_30 + year, data = ntits3)
#
# ## Fitting an additive LMM:
# ttTLy_lmm1 <- lme4::lmer(tarsus_length ~ logged_woody_area + logged_Fmetric +
#                            species + clutch_size +
#                            urban_intensity + manag_intensity + light_pollution + noise_iq +
#                            cumdd_30 + year + (1|id_nestbox), data = ntits3,
#                          control=lme4::lmerControl(optimizer="bobyqa",
#                                                    optCtrl=list(maxfun=2e5))) # Works even without
# # increasing the number of iterations or changing the optimizer.
#
# ## Fitting interactive (mediated) LMMs:
# ttTLy_lmm2 <- lme4::lmer(tarsus_length ~
#                            scale(logged_woody_area, scale = F) * scale(logged_Fmetric, scale = F) +
#                            species + clutch_size +
#                            urban_intensity + manag_intensity + light_pollution + noise_iq +
#                            cumdd_30 + year + (1|id_nestbox), data = ntits3,
#                          control=lme4::lmerControl(optimizer="bobyqa",
#                                                    optCtrl=list(maxfun=2e5)))
# AIC(ttTLy_lm1) # AIC = 593.7
# AIC(ttTLy_lmm1) # AIC = 635.2
# AIC(ttTLy_lmm2) # AIC = 635.5, these AIC are probably not comparable with the LM one.
#
#
#
#
#
# ### ** 4.3.2. Diagnostics and assumption checks ----
# # __________________________________________________
#
# ### *** 4.3.2.1. Residuals extraction, autocorrelation and collinearity ----
# ## Extracting residuals (with the {redres}):
# raw_cond <- redres::compute_redres(ttTLy_lmm1) # Computes the raw conditional residuals (conditional on
# # the random effects (RE)).
# pearson_mar <- redres::compute_redres(ttTLy_lmm1, type = "pearson_mar") # Computes the Pearson marginal
# # (not accounting for the RE) residuals.
# std_cond <- redres::compute_redres(ttTLy_lmm1, type = "std_cond") # Computes the studentised cond. ones.
# # Joins the residuals to the data:
# xxx <- cbind(ntits3, raw_cond, pearson_mar, std_cond)
#
# ## Simulation-based scaled residuals computation (DHARMa method):
# simu.resid <- DHARMa::simulateResiduals(fittedModel = ttTLy_lmm1, n = 1000, plot = FALSE)
# par(.pardefault)
# plot(simu.resid) # Ok.
#
# ## Autocorrelation and collinearity:
# DHARMa::testSpatialAutocorrelation(simulationOutput = simu.resid,
#                                    x = ntits3$coord_x, y = ntits3$coord_y, plot = TRUE) # Ok.
# performance::check_autocorrelation(ttTLy_lmm1) # Ok.
# performance::check_collinearity(ttTLy_lmm2) # Ok-ish but some VIF > 4-5 and moderate correlation for
# # "species" and "light_pollution" (only for 'ttTLy_lmm2')!
# stats::vcov(ttTLy_lmm1) # Ok-ish.
#
#
#
# ### *** 4.3.2.2. Distribution and homoscedasticity ----
# ## Assessing the normality of the residuals:
# stats::shapiro.test(xxx$raw_cond) # Significant! But plotting would be better:
# redres::plot_resqq(ttTLy_lmm1) # As expected, the plot shows a substantial departure from Normality at the
# # extreme ends of the quantiles, that is at the border of the parameters space. Overall, as almost all
# # points stay within the 95% CI, we can say it is ok-ish.
# # Plotting them against each predictor:
# xxx %>%
#   tidyr::gather(key = "type", value = "residual",
#                 c(logged_woody_area, logged_Fmetric, clutch_size, urban_intensity, light_pollution,
#                   noise_iq, cumdd_30)) %>%
#   ggplot2::ggplot(ggplot2::aes(x = residual)) +
#   ggplot2::geom_histogram(bins = 20) +
#   ggplot2::facet_grid(. ~ type, scales = "free") +
#   ggplot2::theme_bw() # Residuals vs predictor plots look rather ok, even though some strange patterns can
# # be seen. I would not be too worried about them but they would require some further thinking.
#
# ## Assessing the normality in the random effect:
# redres::plot_ranef(ttTLy_lmm1) # Same thing here.
#
# ## Assessing homogeneity of variance and influential observations:
# plot(ttTLy_lmm1, type=c("p","smooth"), col.line = 2, id = 0.05, idLabels = ~.obs,
#      ylab = "Pearson's residuals", xlab = "Fitted values") # It's ok but there are a few possible outliers:
# ntits3[c(27),] # High residuals ~= long tarsus juveniles. RAS.
# ntits3[c(21,73,13,20,193,126),] # Low residuals ~= long tarsus juveniles. RAS.
#
# # Residuals vs leverage:
# plot(ttTLy_lmm1, stats::rstudent(.) ~ stats::hatvalues(.))
# cd <- stats::cooks.distance(ttTLy_lmm1)
# plot(cd, ylab = "Cook's distance")
# ntits3[which(cd>0.4),] # Ok, all observations are < 0.5, so no overly influential points.
# ntits3[which(cd>0.1),] # Even with very conservative values, only: DIJ-016_2021 and DIJ-147_2022.
#
# ## Residuals vs predictors:
# redres::plot_redres(ttTLy_lmm1, xvar = "noise_iq") +
#   ggplot2::geom_smooth(method = "loess") +
#   ggplot2::theme_classic() +
#   ggplot2::labs(title = "Residual vs predictor") # Globally ok, but strange pattern for CS?
# # plot(ntits3$logged_Fmetric, stats::residuals(ttTLy_lmm1)) # Same plot (I should create a
# # custom function).
# redres::plot_redres(ttTLy_lmm1, type = "raw_mar", xvar = "year") # Ok.
#
# ## Distribution of the predicted values:
# par(.pardefault)
# predictions <- stats::predict(object = ttTLy_lmm1, type = "response") # Extract the predicted values.
# par(mfrow= c(1,2))
# hist(predictions, main = "Predicted tarsus length", xlab = "Nestling tarsus length (mm)")
# plot(ecdf(predictions), main = "Predicted CDF", xlab = "Nestling tarsus length (mm)")
# fitdistrplus::plotdist(data = ntits3$tarsus_length, histo = TRUE, demp = TRUE) # Could be better.
#
#
#
# ### *** 4.3.2.3. Linearity ----
# ## Plotting the response on the logit scale (= log odds) against predictors:
# # Format data:
# ntits3 %>% dplyr::select(logged_woodyveg, logged_woody_area, logged_woodyvol,
#                          logged_Fmetric, logged_Fmetric_d1, logged_Fmetric_d1b1, logged_Fmetric_d2b1,
#                          urban_intensity, logged_herby_area, logged_built_area, logged_traffic,
#                          light_pollution, noise_m, noise_iq,
#                          cumdd_30, min_t_before, min_t_between,
#                          hatching_rate, brood_size, clutch_size) -> mydata
# predictors <- colnames(mydata)
# # Bind 'tarsus_length' and tidying the data for plot (ggplot2, so long format):
# mydata <- mydata %>%
#   dplyr::mutate(tarsus_length = ntits3$tarsus_length) %>%
#   tidyr::gather(key = "predictors", value = "predictor.value", -tarsus_length)
# # Create scatterplot
# ggplot2::ggplot(mydata, ggplot2::aes(y = tarsus_length, x = predictor.value))+
#   ggplot2::geom_point(size = 0.5, alpha = 0.5) +
#   ggplot2::geom_smooth(method = "loess") +
#   ggplot2::theme_bw() +
#   ggplot2::facet_wrap(~predictors, scales = "free_x") # Rather ok, but spline functions could yield better
# # results.
#
#
#
# ### *** 4.3.2.4. Goodness-of-fit (GOF) and performances ----
# ## Computing a pseudo-R2:
# performance::r2_nakagawa(ttTLy_lmm1) # [Additive model]: Marg_R2_lmm = 0.78; Cond_R2_lmm = 0.79.
# performance::r2_nakagawa(ttTLy_lmm2) # [Interact. model]: Marg_R2_lmm = 0.78; Cond_R2_lmm = 0.79.
#
# ## Likelihood-ration tests (LRT) of GOF:
# # Importance of the "id_nestbox" random-effect (RE):
# tictoc::tic("Parametric bootstrap LRT")
# res.LRT_re <- DHARMa::simulateLRT(m0 = ttTLy_lm1, m1 = ttTLy_lmm1, n = 1000, seed = 39)
# tictoc::toc() # Took ~24s to run.
# # The LRT is highly significant, suggesting that M1 better describes the data than M0, supporting the
# # importance of the random effect!
#
# # Importance of the fixed effects (only using the LM):
# ttTLy_lm0 <- stats::lm(tarsus_length ~ 1, data = ntits3)
# res.LRT_null <- stats::anova(object = ttTLy_lm0, ttTLy_lm1, test = "LRT")
# # The test is highly significant, confirming that the model is useful to explain the data.
#
#
#
#
#
# ### ** 4.3.3. Inference and predictions ----
# # __________________________________________
#
# ### *** 4.3.3.1. Hypotheses testing: LRT for the additive and interactive effect of the F-metric ----
# ## For the additive effect of the connectivity metric:
# ttTLy_lmm0 <- stats::update(ttTLy_lmm1, .~. -logged_Fmetric)
#
# res.LRT_addeff <- pbkrtest::PBmodcomp(ttTLy_lmm1,
#                                       ttTLy_lmm0, nsim = 1000, seed = 771) # Took ~38s to run!
# readr::write_csv2(x = res.LRT_addeff$test, file = here::here("output", "tables",
#                                                              "res.ttTLy_LRT_addeff.csv"))
# # The LRT is NOT significant, indicating that our connectivity metric does improve the description of the data.
#
#
# ## For the interaction effect:
# res.LRT_inteff <- pbkrtest::PBmodcomp(ttTLy_lmm2,
#                                       ttTLy_lmm1, nsim = 1000, seed = 102) # Took ~37s to run!
# readr::write_csv2(x = res.LRT_inteff$test, file = here::here("output", "tables",
#                                                              "res.ttTLy_LRT_inteff.csv"))
# # The LRT is NOT significant, indicating that our hypothesis of an interaction effect is not supported
# # by the data.
#
#
#
# ### *** 4.3.3.2. Bootstrapped confidence intervals for estimated parameters ----
# tictoc::tic("Bootstrap CI for additive LMM parameters")
# res.ttTLy_addeff_CI_boot <- confint(ttTLy_lmm1, method="boot")
# tt <- as.data.frame(res.ttTLy_addeff_CI_boot)
# tt$parameters <- rownames(tt)
# readr::write_csv2(x = tt,
#                   file = here::here("output", "tables", "res.ttTLy_bootCI_addeff.csv"))
# tictoc::toc() # DISCLAIMER: took ~8s to run!
#
#
#
# ### *** 4.3.3.3. Conclusion ----
# # For the initial model:
# summary(ttTLy_lmm1) # AIC = 635.2 and Marg_R2_lmm = 0.78; Cond_R2_lmm = 0.79.
# summary(ttTLy_lmm2) # AIC = 635.5 and Marg_R2_lmm = 0.78; Cond_R2_lmm = 0.79.
# # Diagnostics ran for 'ttTLy_lmm1' and 'ttTLy_lmm2' (initial models) indicated that the models do fit the
# # data rather averagely even though the models do not present major problems:
# # - All sorts of residuals are globally fine. Even though some patterns exist and may require improvements.
# # - Assumptions all seem validated, although there is a mild multicollinearity with some VIF > 4-5 and
# #   moderate correlation for "species" and "light_pollution" (but only for model2).
# # - Linearity is globally respected but the use of spline functions could certainly better represent the data.
# # - No true outliers but some with rather extreme values.
# # - No overly influential observations. Even with very conservative values for Cook's distance, only:
# #   DIJ-016_2021 and DIJ-147_2022.
# # Otherwise, LRT showed that the RE and the models are still more useful than reduced models.
# ## Significant variables: speciesCC (---), clutch_size (-), year2022 (+).
# ## Almost significant variables: woody_area (+), noise_iq (-), manag_mid/high (-), urban_intensity (+).
# ## Hypothesis 1 is rejected (PB-based LRT; p = 0.69) and hypothesis 2 is rejected (p = 0.27)!
#
#
#
#
#
# ##################### *--------------------------------* #######################
# ##### * 4.4. Wing length: LMM --------------------------------------------------
# # ---------------------------------------------------------------------------- #
# ### ** 4.4.1. Initial model fit ----
# # __________________________________
#
# ## Fitting a regular linear model:
# ntits2 %>% dplyr::filter(is.na(wing_length) == FALSE) -> ntits3 # Only 194 observations left.
#
# ttWLy_lm1 <- stats::lm(wing_length ~ logged_woody_area + logged_Fmetric +
#                             species + clutch_size +
#                             urban_intensity + manag_intensity + light_pollution + noise_iq +
#                             cumdd_30 + year, data = ntits3)
#
# ## Fitting an additive LMM:
# ttWLy_lmm1 <- lme4::lmer(wing_length ~ logged_woody_area + logged_Fmetric +
#                            species + clutch_size +
#                            urban_intensity + manag_intensity + light_pollution + noise_iq +
#                            cumdd_30 + year + (1|id_nestbox), data = ntits3,
#                          control=lme4::lmerControl(optimizer="bobyqa",
#                                                    optCtrl=list(maxfun=2e5))) # Singular fit!
#
# ## Fitting an interactive LMM:
# ttWLy_lmm2 <- lme4::lmer(wing_length ~
#                            scale(logged_woody_area, scale = F) * scale(logged_Fmetric, scale = F) +
#                            species + clutch_size +
#                            urban_intensity + manag_intensity + light_pollution + noise_iq +
#                            cumdd_30 + year + (1|id_nestbox), data = ntits3,
#                          control=lme4::lmerControl(optimizer="bobyqa",
#                                                    optCtrl=list(maxfun=2e5))) # Singular fit!
#
# # # As there are singular fits (RE variance = 0). I'll thus try setting a weak prior on the variance:
# # ttWLy_blmm1 <- blme::blmer(wing_length ~ logged_woody_area + logged_Fmetric +
# #                              species + clutch_size +
# #                              urban_intensity + manag_intensity + light_pollution + noise_iq +
# #                              cumdd_30 + year + (1|id_nestbox), data = ntits3,
# #                            control=lme4::lmerControl(optimizer="bobyqa",
# #                                                      optCtrl=list(maxfun=2e5))) # Convergence issue.
# # # Try all optimizers:
# # ttWLy_blmm1_all <- lme4::allFit(ttWLy_blmm1)
# # summary(ttWLy_blmm1_all) # Two optimizers failed to converge but give rather similar results, except the
# # # "nloptwrap.NLOPT_LN_BOBYQA" optimizer that computes a larger RE variance and thus, lower coefficient
# # # estimates. We will thus stick with "bobyqa".
# #
# # ## Fitting interactive (mediated) LMMs:
# # ttWLy_blmm3 <- blme::blmer(wing_length ~
# #                              scale(logged_woodyveg, scale = F) * scale(logged_Fmetric, scale = F) +
# #                              species + clutch_size +
# #                              urban_intensity + manag_intensity + light_pollution + noise_iq +
# #                              cumdd_30 + year + (1|id_nestbox), data = ntits3,
# #                            control=lme4::lmerControl(optimizer="bobyqa",
# #                                                      optCtrl=list(maxfun=2e5))) # Convergence issue.
# AIC(ttWLy_lm1) # AIC = 1098.5
# AIC(ttWLy_lmm1) # AIC = 1093.1
# AIC(ttWLy_lmm2) # AIC = 1089.2, these AIC are probably not comparable with the LM one.
#
#
#
#
#
# ### ** 4.4.2. Diagnostics and assumption checks ----
# # __________________________________________________
#
# ### *** 4.4.2.1. Residuals extraction, autocorrelation and collinearity ----
# ## Extracting residuals (with the {redres}):
# raw_cond <- redres::compute_redres(ttWLy_lmm1) # Computes the raw conditional residuals (conditional on
# # the random effects (RE)).
# pearson_mar <- redres::compute_redres(ttWLy_lmm1, type = "pearson_mar") # Computes the Pearson marginal
# # (not accounting for the RE) residuals.
# std_cond <- redres::compute_redres(ttWLy_lmm1, type = "std_cond") # Computes the studentised cond. ones.
# # Joins the residuals to the data:
# xxx <- cbind(ntits3, raw_cond, pearson_mar, std_cond)
#
# ## Simulation-based scaled residuals computation (DHARMa method):
# simu.resid <- DHARMa::simulateResiduals(fittedModel = ttWLy_lmm1, n = 1000, plot = FALSE)
# par(.pardefault)
# plot(simu.resid) # Slight deviation for model1!
#
# ## Autocorrelation and collinearity:
# DHARMa::testSpatialAutocorrelation(simulationOutput = simu.resid,
#                                    x = ntits3$coord_x, y = ntits3$coord_y, plot = TRUE) # Ok.
# performance::check_autocorrelation(ttWLy_lmm1) # Ok.
# performance::check_collinearity(ttWLy_lmm1) # Ok-ish but some VIF > 4-5 and moderate correlation for
# # "species" and "light_pollution" (for 'ttWLy_lmm2') and "manag_intensity" (for model1)!
# stats::vcov(ttWLy_lmm1) # High covariances!
#
#
#
# ### *** 4.4.2.2. Distribution and homoscedasticity ----
# ## Assessing the normality of the residuals:
# stats::shapiro.test(xxx$raw_cond) # Significant! But plotting would be better:
# redres::plot_resqq(ttWLy_lmm1) # As expected, the plot shows a substantial departure from Normality at the
# # extreme ends of the quantiles, that is at the border of the parameters space. Overall, as almost all
# # points stay within the 95% CI, we can say it is ok-ish.
# # Plotting them against each predictor:
# xxx %>%
#   tidyr::gather(key = "type", value = "residual",
#                 c(logged_woody_area, logged_Fmetric, clutch_size, urban_intensity, light_pollution,
#                   noise_iq, cumdd_30)) %>%
#   ggplot2::ggplot(ggplot2::aes(x = residual)) +
#   ggplot2::geom_histogram(bins = 20) +
#   ggplot2::facet_grid(. ~ type, scales = "free") +
#   ggplot2::theme_bw() # Residuals vs predictor plots look rather ok, even though some strange patterns can
# # be seen. I would not be too worried about them but they would require some further thinking.
#
# ## Assessing the normality in the random effect:
# redres::plot_ranef(ttWLy_lmm1) # Same thing here.
#
# ## Assessing homogeneity of variance and influential observations:
# plot(ttWLy_lmm1, type=c("p","smooth"), col.line = 2, id = 0.05, idLabels = ~.obs,
#      ylab = "Pearson's residuals", xlab = "Fitted values") # It's ok but there are a few possible outliers:
# ntits3[c(162,25,7,11),] # High residuals ~= long wing juveniles. RAS.
# ntits3[c(10,127,17,42,77,92,190),] # Low residuals ~= short wing juveniles. RAS.
#
# # Residuals vs leverage:
# plot(ttWLy_lmm1, stats::rstudent(.) ~ stats::hatvalues(.))
# cd <- stats::cooks.distance(ttWLy_lmm1)
# plot(cd, ylab = "Cook's distance")
# ntits3[which(cd>0.4),] # Ok, all observations are < 0.5, so no overly influential points.
# ntits3[which(cd>0.1),] # Even with very conservative values, nothing.
#
# ## Residuals vs predictors:
# redres::plot_redres(ttWLy_lmm1, xvar = "cumdd_30") +
#   ggplot2::geom_smooth(method = "loess") +
#   ggplot2::theme_classic() +
#   ggplot2::labs(title = "Residual vs predictor") # Ok.
# redres::plot_redres(ttWLy_lmm1, type = "raw_mar", xvar = "manag_intensity") # Ok.
#
# ## Distribution of the predicted values:
# par(.pardefault)
# predictions <- stats::predict(object = ttWLy_lmm1, type = "response") # Extract the predicted values.
# par(mfrow= c(1,2))
# hist(predictions, main = "Predicted wing length", xlab = "Nestling wing length (mm)")
# plot(ecdf(predictions), main = "Predicted CDF", xlab = "Nestling wing length (mm)")
# fitdistrplus::plotdist(data = ntits3$wing_length, histo = TRUE, demp = TRUE) # Too narrow predictions!
#
#
#
# ### *** 4.4.2.3. Linearity ----
# ## Plotting the response on the logit scale (= log odds) against predictors:
# # Format data:
# ntits3 %>% dplyr::select(logged_woodyveg, logged_woody_area, logged_woodyvol,
#                          logged_Fmetric, logged_Fmetric_d1, logged_Fmetric_d1b1, logged_Fmetric_d2b1,
#                          urban_intensity, logged_herby_area, logged_built_area, logged_traffic,
#                          light_pollution, noise_m, noise_iq,
#                          cumdd_30, min_t_before, min_t_between,
#                          hatching_rate, brood_size, clutch_size, mass) -> mydata
# predictors <- colnames(mydata)
# # Bind 'wing_length' and tidying the data for plot (ggplot2, so long format):
# mydata <- mydata %>%
#   dplyr::mutate(wing_length = ntits3$wing_length) %>%
#   tidyr::gather(key = "predictors", value = "predictor.value", -wing_length)
# # Create scatterplot
# ggplot2::ggplot(mydata, ggplot2::aes(y = wing_length, x = predictor.value))+
#   ggplot2::geom_point(size = 0.5, alpha = 0.5) +
#   ggplot2::geom_smooth(method = "loess") +
#   ggplot2::theme_bw() +
#   ggplot2::facet_wrap(~predictors, scales = "free_x") # Rather ok, but spline functions could yield better
# # results.
#
#
#
# ### *** 4.4.2.4. Goodness-of-fit (GOF) and performances ----
# ## Computing a pseudo-R2:
# performance::r2_nakagawa(ttWLy_lmm1) # [Additive model]: Marg_R2_lmm = 0.6; Cond_R2_lmm = NA.
# performance::r2_nakagawa(ttWLy_lmm2) # [Interact. model]: Marg_R2_lmm = 0.61; Cond_R2_lmm = NA.
#
# ## Likelihood-ration tests (LRT) of GOF:
# # Importance of the "id_nestbox" random-effect (RE):
# tictoc::tic("Parametric bootstrap LRT")
# res.LRT_re <- DHARMa::simulateLRT(m0 = ttWLy_lm1, m1 = ttWLy_lmm1, n = 1000, seed = 5)
# tictoc::toc() # Took ~18s to run.
# # The LRT is highly significant, suggesting that M1 better describes the data than M0, supporting the
# # importance of the random effect!
#
# # Importance of the fixed effects (only using the LM):
# ttWLy_lm0 <- stats::lm(wing_length ~ 1, data = ntits3)
# res.LRT_null <- stats::anova(object = ttWLy_lm0, ttWLy_lm1, test = "LRT")
# # The test is highly significant, confirming that the model is useful to explain the data.
#
#
#
#
#
# ### ** 4.4.3. Inference and predictions ----
# # __________________________________________
#
# ### *** 4.4.3.1. Hypotheses testing: LRT for the additive and interactive effect of the F-metric ----
# ## For the additive effect of the connectivity metric:
# ttWLy_lmm0 <- stats::update(ttWLy_lmm1, .~. -logged_Fmetric)
#
# res.LRT_addeff <- pbkrtest::PBmodcomp(ttWLy_lmm1,
#                                       ttWLy_lmm0, nsim = 1000, seed = 753) # Took ~38s to run!
# readr::write_csv2(x = res.LRT_addeff$test, file = here::here("output", "tables",
#                                                              "res.ttWLy_LRT_addeff.csv"))
# # The LRT is NOT significant, indicating that our connectivity metric does improve the description of the data.
#
#
# ## For the interaction effect:
# res.LRT_inteff <- pbkrtest::PBmodcomp(ttWLy_lmm2,
#                                       ttWLy_lmm1, nsim = 1000, seed = 90) # Took ~37s to run!
# readr::write_csv2(x = res.LRT_inteff$test, file = here::here("output", "tables",
#                                                              "res.ttWLy_LRT_inteff.csv"))
# # The LRT is NOT significant, indicating that our hypothesis of an interaction effect is not supported
# # by the data.
#
#
#
# ### *** 4.4.3.2. Bootstrapped confidence intervals for estimated parameters ----
# tictoc::tic("Bootstrap CI for additive LMM parameters")
# res.ttWLy_addeff_CI_boot <- confint(ttWLy_lmm1, method="boot")
# tt <- as.data.frame(res.ttWLy_addeff_CI_boot)
# tt$parameters <- rownames(tt)
# readr::write_csv2(x = tt,
#                   file = here::here("output", "tables", "res.ttWLy_bootCI_addeff.csv"))
# tictoc::toc() # DISCLAIMER: took ~8s to run!
#
#
#
# ### *** 4.4.3.3. Conclusion ----
# # For the initial model:
# summary(ttWLy_lmm1) # AIC = 1093.1 and Marg_R2_lmm = 0.6; Cond_R2_lmm = NA.
# summary(ttWLy_lmm2) # AIC = 1089.2 and Marg_R2_lmm = 0.61; Cond_R2_lmm = NA.
# # Diagnostics ran for 'ttWLy_lmm1' and 'ttWLy_lmm2' (initial models) indicated that the models do fit the
# # data rather averagely (predictions are too narrow) and do present some problems:
# # - Some quantile deviations for model1 (to be further diagnosed).
# # - Assumptions all seem validated, although there is a mild multicollinearity with some VIF > 4-5 and
# #   moderate correlation for "species" and "light_pollution" (but only for model2) and "manag" (model1).
# #   The covariance is rather high too.
# # Otherwise, LRT showed that the RE and the models are still more useful than reduced models.
# ## Significant variables: speciesCC (---), year2021 (-).
# ## Almost significant variables: noise_iq (-).
# ## Hypothesis 1 is rejected (PB-based LRT; p = 0.31) and hypothesis 2 is rejected (p = 0.15)!
#
#
#
#
#
# ########################## ************************************************* ###############################
# par(.pardefault)
# ############################################ MAJJJJJJJ§§§§§§§§ todolist ####################################################
# # - Tester avec ou sans outliers (noise_m, connectivity???); si ça change beaucoup les résultats, rapporter
# #   les deux??? Tester aussi patch_perim + traffic + choisir RE définitifs??? (e.g. id_patch + site???)
# # - Refaire tourner tous les modèles avec NTITS --> Utiliser clutch_size et brood_size comme prédicteur, ou
# #   la date de ponte??????? ASK JC??????????? Tester????
# # +++++ Voir pk EDA_report bug! + Voir si centrage change quelque chose (interprétation interaction)?????
# # - Explorer chaque modèle pour voir qu'est-ce qui marche le mieux et s'il y a une spécification unique qui
# #   va bien!!! ATTENTION à la gamme des variables explorées (transformations???????)!!!!
# # - Si rien de bien concluant, essayer en fusionnant les années pour supprimer les RE nichoirs.
#
# # 3) Re-diagsnose models with inputs from the DHARMa vignette (including conditional simu)!!! Then:
# # 4) Improve sub-conclusions! Saying that quasi is not a good option??? Or try anyway with a package that
# #    does it OR BETA-BINOMIAL? --> But too many parameters (ZI+OI)!!! I should wait for the MERGE!
# #    Or simply try modelling the counts with ZI+Comreg avec RE??? And/or PM+CC and/or MERGING years and
# #    nestboxes and hope that it alleviates these problems?????
# # 5) Move on to another Y: i) LMM_morpho; ii) LMM_mass, wing...; iii) COM-Poisson pour clutch_size; iv) ZI!
# # 6) Try the Conway-Maxwell Poisson (Shmueli et al, 2005*) avec {COMPoissonReg} (Sellers & Lotze, 2015*),
# #    but search first if that exist in Mixed Model! (Same for Zero-Inflated models)! Or quasi-likelihood,
# #    or generalised-Poisson (but {VGAM} does not do it anymore). I could also try it without REs...
# #    The problem with all that is that quasi-MLE, GP or COM-Poisson prevent mixed-models and possibly
# #    LR-tests, right? At least the quasi-MLE does. Is bird breeding a Poisson process???
#
# # 7) Reunite PM & CC while keeping other predictors (for exploratory research)! But beware of coding,
# #    what does the intercept mean? Which reference group?
#
# # 1) Consider removing overly influential observations?
# # 2) Consider merging years and averaging nestboxes??? Some of the GLMs gave interesting results, sometimes
# #    even more when "year" was removed.
# # 8) Compare all methods of estimation and inference (cf. inference bolker example) for the **same
# #    model** to see if any is making a difference?
# # 9) Explore other predictors (and different scales)! E.g. AICc-based model selection?
# ########################## ************************************************* ###############################
