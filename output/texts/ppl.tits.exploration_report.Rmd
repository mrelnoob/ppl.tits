---
title: "Exploratory data analyses and preparation report - Tits reproduction study, PubPrivLands project (Martin *et al.*, *in prep.*)"
author: "Fran√ßois-Marie Martin"
date: "`r format(Sys.time(), '%d %B, %Y')`"
bibliography: ppl.tits_biblio.bib
csl: fanf_style.csl
output: rmdformats::readthedown
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)

# IMPORTANT NOTE: if you read this, then you should know that this RMarkdown report has been written as a 'target' in a {targets} pipeline (https://books.ropensci.org/targets/). If you simply want to knit this report, you need to do it using using 'targets::tar_make()' (provided that you did not altered the structure of the "ppl.tits" folder to which this report belongs), otherwise it won't work! Alternatively, you can paste this .Rmd at the root of the "ppl.tits" folder. If you want to run the code contained within the code chunks of this document WITHOUT knitting, then you need to set the working directory of this .Rmd document at the root of the "ppl.tits" folder using the global options of RStudio, 'setwd()', or 'knitr::opts_knit$set(root.dir = '~/')'. That is because R, RStudio or {knitr} do not seem to be able to find the "_targets" folder containing the targets that are called by my code chunks otherwise... By default, RMarkdown sets the working directory where the .Rmd file is stored, not at the root of the R project the report is a part of.
# Still, note that theoretically, you do not need to knit or modify this document as it is meant for reproducibility and you can simply read the .html file for that.
```

# 1. Introduction
## 1.1. Regarding reproductibility


In order to facilitate any attempt at reproducing this study, here is a depiction of the system information used to prepare and analyse the data from the PubPrivLands tits reproduction study (Martin *et al.* , *in prep.*).

```{r session information}
rm(list=ls())
sessionInfo()
```

All codes used in this study can furthermore be found here: https://github.com/mrelnoob/ppl.tits
\
\

## 1.2. What is this document about?  
### 1.2.1. Presentation of the data processing methodology

In the context of the *tits reproduction study* of the PubPrivLands project, we undertook a complex data processing methodology that can be divided into **five stages**:

1. **Raw data acquisition and preparation** - This initial stage consists of all *raw* data acquisition through fieldwork, GIS or remote-sensing-based data generation, and database extractions as well as their initial *cleaning* and *formatting* to produce **raw datasets** (e.g. tits reproduction observations, environmental variables). This stage is globally described in the *Materials & Methods* section of the manuscript, and is thoroughly detailed in the **ppl_log.pdf** document (French only, see Supplementary Materials).
2. **Clean dataset generation** - This stage includes all basic *cleaning*, *wrangling*, *computing* and *formatting* required to obtain a **clean exploitable dataset**. This stage is documented in the `R` files of the `{ppl.tits}` package openly accessible at: https://github.com/mrelnoob/ppl.tits.
3. **Intermediate analyses** - This stage encompasses all analyses performed to enable the landscape scale habitat connectivity modelling for both tits species and compute connectivity metrics using the [Graphab](https://sourcesup.renater.fr/www/graphab/fr/home.html) software [@graphab2021]. Through this stage, the **final dataset** is generated (`ndata_complete`; i.e. the *clean exploitable dataset* completed with *connectivity metrics*). This stage is described in the *Intermediate analyses report*.
4. **Exploratory Data Analyses** (EDA) - This stage describes all *EDA* and preliminary *assumption checks* made on the *final dataset* that are required to plan proper statistical analyses for hypotheses testing. This stage is described in the *Exploratory data analyses and preparation report* (the present document).
5. **Statistical analyses** - This last stage includes all statistical procedures meant to *test* our study hypotheses, *produce results* and *assess their reliability*. This stage is described in the *Statistical analyses report*.


### 1.2.2. Content of this report

This document outlines all the important data preparation and exploration steps undertaken to test our research hypotheses. In other words, it presents all **exploratory data analyses** and preliminary **assumption checks** performed on the *final* version of our dataset. Actually, it also presents the last step of the dataset generation process, that is **missing values imputation** because it is a highly sensitive part of the process and thus deserves the utmost transparency.
\
\

******

# 2. Missing data imputation process

```{r data import, include=FALSE}
library(ppl.tits) # To be able to use pipes.
tits_priorimp <- targets::tar_read(pimp_tdata)
tits <- targets::tar_read(tdata_clean)
pm_imp_error <- targets::tar_read(imp_ooberror_pm)
cc_imp_error <- targets::tar_read(imp_ooberror_cc)
# As you can see, I import my data using 'targets'! If you are reading this report and don't know what it is or how I created and stored them, you should read the README or the _devhistory.R files available at https://github.com/mrelnoob/ppl.tits. 
```

Similarly to many datasets in ecology, some of our variables contained missing values. As most of them were MAR or MCAR (missing [completely] at random) and since deleting observations containing missing values can lead to biased coefficient estimates [@harrell2015], we decided to impute the missing values in some of our *response variables* as well as in all *independent variables* (IV) containing missing values instead of deleting observations. For our morphometric *response variables*, however, missing values were not MAR as many were due to the fact that reproduction events failed. In such a case, it was impossible to measure morphometric variables as nestlings were either dead or missing. These *response variables* were thus excluded from the following imputation process.  
Now, since the proportion of missing values is clearly higher for our Blue Tits (*Cyanistes caeruleus*) observations than for our Great Tits (*Parus major*) data and as the former has a lower sample size, we chose to split our data into two subsets, one for each species. Consequently, the Blue Tits one contains less variables as some were discarded to prevent overoptimistic imputations. Furthermore, we actually performed 4 runs of imputation, one for each buffer size used to extract our IVs (i.e. one for each sub-dataset: 50, 100, 150 and 200 metres-based datasets).

To impute missing values, we used the `missForest()` function from the `{missForest}` package [@stekhoven2011]. This functions initially imputes all missing data using the mean/mode, then for each variable with missing values, it fits a *Random Forest* on the observed part to predict the missing part. This process of training and predicting repeats iteratively until a stopping criterion is met or a maximum number of user-specified iterations is reached. This algorithm has been shown to have higher predictive performances than other widely used imputation methods, including MICE or KNNimpute [@stekhoven2011].  
Another advantage is that this function can return an assessment of the imputation error based on the out-of-bag (OOB) samples, for each variable individually. For continuous predictors, the *Mean Squared Error* (MSE) of imputed values is computed while the *proportion of falsely classified* (PFC) is returned for categorical missing ones.  
To avoid overfitting, no hyperparameters tuning was performed but I applied a three-fold increase in the number of trees and maximum iterations with respect to the default values to favour predictive accuracy. 



## 2.1. Great Tits dataset
### 2.1.1. Dataset prior to imputation

Here is a summary of the *Great Tits 150m-based dataset* prior to data imputation (for the meaning of the variables, readers are referred to **Table S1** - cf. Supplementary Materials):

```{r pm before imputation, message=FALSE}
tits_priorimp %>% dplyr::filter(dist == 150,
                                species == "PM") -> pm_pimp
summary(pm_pimp)
```

### 2.1.2. Dataset after imputation

Below, you may find a summary table of the OOB error for all imputed variables and for each sub-dataset, expressed in variables original scales (the blue variable is a future *response variable* while the green ones are meant to be *independent variables*): 

```{r pm imput error, message=FALSE}
data.frame(Variable = rownames(pm_imp_error), 
           Nb_imputed_values = pm_imp_error$Nb_imputed_values, 
           Oob_RMSE_50m = pm_imp_error$Oob_RMSE_50m,
           Oob_RMSE_100m = pm_imp_error$Oob_RMSE_100m,
           Oob_RMSE_150m = pm_imp_error$Oob_RMSE_150m,
           Oob_RMSE_200m = pm_imp_error$Oob_RMSE_200m) %>%
  dplyr::mutate(Variable = kableExtra::cell_spec(
    Variable, color = "white", background = ifelse(
      Variable == "brood_size", "deepskyblue", "mediumseagreen"))) %>%
  knitr::kable(escape = FALSE) %>% 
  kableExtra::kable_styling(full_width = FALSE)
```

You can see that imputation errors are, in this case, fairly negligible compared to variables' ranges of variation. Consequently, we deemed these imputations acceptable and used them for the subsequent analyses.
Here is a summary of the *Great Tits 150m-based dataset* AFTER imputation:
```{r pm after imputation, message=FALSE}
tits %>% dplyr::filter(dist == 150,
                       species == "PM") -> pm
summary(pm)
```
\
\

## 2.2. Blue Tits dataset
### 2.2.1. Dataset prior to imputation

Here is a summary of the *Blue Tits 150m-based dataset* prior to data imputation (for the meaning of the variables, readers are referred to **Table S1** - cf. Supplementary Materials):

```{r cc before imputation, message=FALSE}
tits_priorimp %>% dplyr::filter(dist == 150,
                                species == "CC") -> cc_pimp
summary(cc_pimp)
```

### 2.2.2. Dataset after imputation

Below, you may find a summary table of the OOB error for all imputed variables and for each sub-dataset, expressed in variables original scales (the blue variable is a future *response variable* while the green ones are meant to be *independent variables*): 

```{r cc imput error, message=FALSE}
data.frame(Variable = rownames(cc_imp_error), 
           Nb_imputed_values = cc_imp_error$Nb_imputed_values, 
           Oob_RMSE_50m = cc_imp_error$Oob_RMSE_50m,
           Oob_RMSE_100m = cc_imp_error$Oob_RMSE_100m,
           Oob_RMSE_150m = cc_imp_error$Oob_RMSE_150m,
           Oob_RMSE_200m = cc_imp_error$Oob_RMSE_200m) %>%
  dplyr::mutate(Variable = kableExtra::cell_spec(
    Variable, color = "white", background = ifelse(
      Variable == "brood_size", "deepskyblue", "mediumseagreen"))) %>%
  knitr::kable(escape = FALSE) %>% 
  kableExtra::kable_styling(full_width = FALSE)
```

Here again, you can see that imputation errors are, in this case, fairly negligible compared to variable variances. Consequently, these imputations were used for the subsequent analyses.
Here is a summary of the *Blue Tits 150m-based dataset* AFTER imputation:
```{r cc after imputation, message=FALSE}
tits %>% dplyr::filter(dist == 150,
                       species == "CC") -> cc
summary(cc)
```
\
\

******

# 3. Exploratory data analyses

Various univariate or multivariate aspects of our data (e.g. outliers, variables distribution, potential multicollinearity, homogeneity of variances, linearity, etc.) were explored and are presented in this section, mostly following @bolker2009, @zuur2010, and @harrell2015.  
Naturally, most actual models assumptions were checked during or after model building. Our intention here was simply to improve our knowledge of the data and identify potential problems upstream. As our global dataset contained many potential predictor proxies (*p* ~ 40 - including interest variables, covariates and random factors), much effort was indeed directed toward reducing their number and keeping only the most reliable and important variables and proxies relative to our hypotheses. In other words, we tried to reduce the dimensionality of our data. 

```{r BLABLA}
.pardefault <- par() # To save the default graphical parameters (in case I want to restore them: e.g. with
# par(.pardefault)).



```


\
\

******
# 4. References
