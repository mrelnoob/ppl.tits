---
title: "Exploratory data analyses and preparation report - Tits reproduction study, PubPrivLands project (Martin *et al.*, *in prep.*)"
author: "François-Marie Martin"
date: "`r format(Sys.time(), '%d %B, %Y')`"
bibliography: ppl.tits_biblio.bib
csl: fanf_style.csl
output:
   html_document:
     theme: darkly
     number_sections: yes
     toc: yes
     toc_depth: 5
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

# - Introduction
## - Regarding reproductibility


In order to facilitate any attempt at reproducing this study, here is a depiction of the system information used to prepare and analyse the data from the PubPrivLands tits reproduction study (Martin *et al.* , *in prep.*).

```{r session information}
rm(list=ls())
sessionInfo()
```

All codes used in this study can furthermore be found here: https://github.com/mrelnoob/ppl.tits
\
\

## - What is this document about?  

```{r data import and summary, include=FALSE}
library(magrittr) # To be able to use pipes.
tits <- ppl.tits::tdata_upD_parcond()$dataset
.pardefault <- par() # To save the default graphical parameters (in case I want to restore them).
```
\

This document outlines all the important data preparation and exploration steps necessary to test our research hypotheses. In other words, it presents all **exploratory data analyses** and basic **assumption checks** performed on the *final* version of our dataset. Actually, it also presents the last step of the dataset generation process, that is **missing values imputation** because it is a highly sensitive part of the process and thus deserves the utmost transparency.
For more details regarding the dataset generation process (i.e. creation of the *final* dataset), readers are referred to the scripts and documents stored at: https://github.com/mrelnoob/ppl.tits as well as to the manuscript and other Supplementary Materials.


+ Small SUMMARY of data preparations ?????? §§§§§§§§§§§§§§§§§§§§§§§§§§§§
+ Small SUMMARY of data preparations ?????? §§§§§§§§§§§§§§§§§§§§§§§§§§§§
+ Small SUMMARY of data preparations ?????? §§§§§§§§§§§§§§§§§§§§§§§§§§§§
+ Small SUMMARY of data preparations ?????? §§§§§§§§§§§§§§§§§§§§§§§§§§§§
+ Small SUMMARY of data preparations ?????? §§§§§§§§§§§§§§§§§§§§§§§§§§§§
\
\

******

# - Missing data imputation

Similarly to many datasets in ecology, some of our variables contained missing values. As they were MAR or MCAR (missing [completely] at random) and since deleting observations containing missing values can lead to biased coefficient estimates [@harrell2015], we decided to impute the missing values in both our response and independent variables instead of deleting observations. However, as the proportion of missing values is clearly higher for our Blue Tits (*Cyanistes caeruleus*) observations than for our Great Tits (*Parus major*) ones and as it had a lower sample size, we chose to split our data into two subsets, one for each species, where the Blue Tits one will contain less variables as some will be discarded to prevent overoptimistic imputations. 


SAY that for Y it's not always MAR/MCAR so we use them to imput X but we will restore them§§§§§§§§§
SAY that for Y it's not always MAR/MCAR so we use them to imput X but we will restore them§§§§§§§§§
SAY that for Y it's not always MAR/MCAR so we use them to imput X but we will restore them§§§§§§§§§
SAY that for Y it's not always MAR/MCAR so we use them to imput X but we will restore them§§§§§§§§§
SAY that for Y it's not always MAR/MCAR so we use them to imput X but we will restore them§§§§§§§§§
But I'll perhaps impute them later (after filtering successful reproduction)



## - Great Tits dataset
### - Dataset prior to imputation

Here is a summary of the Great Tits dataset prior to data imputation (for the meaning of the variables, readers are referred to table **XXX_A_FAIRE!_XXX**):

```{r pm before imputation, message=FALSE}
tits %>% dplyr::filter(species == "PM", success_manipulated == "0") -> pm
summary(pm)
```

### - Dataset after imputation

To impute missing values, we used the `missForest()` function from the {missForest} package [@stekhoven2011]. This functions initially imputes all missing data using the mean/mode, then for each variable with missing values, it fits a *Random Forest* on the observed part and then predicts the missing part. This process of training and predicting repeats iteratively until a stopping criterion is met or a maximum number of user-specified iterations is reached. This algorithm has been shown to have higher predictive performances than other widely used imputation methods, including MICE or KNNimpute [@stekhoven2011].
Another advantage is that this function returns an assessment of the imputation error based on the out-of-bag (OOB) samples, possibly for each variable individually. For continuous predictors, the Mean Squared Error (MSE) of imputed values is computed while the proportion of falsely classified (PFC) is used for categorical missing ones.
To avoid overfitting, no hyperparameters tuning was performed but I applied a three-fold increase in the number of trees and maximum iterations with respect to the default values to favour predictive accuracy. Below, you may find a summary table of the OOB error for all imputed variables, expressed in the original variable scales (i.e. RMSE): 

# +nice table with colour as in KAGGLE???
# +nice table with colour as in KAGGLE???
# +nice table with colour as in KAGGLE???


You can see that imputation errors are, in this case, fairly negligible. Values of exactly 0 means that no missing values were imputed:

CHANGE DICtionary§§§§§ British english§§§§??????,



Various aspects of our data (e.g. outliers, variables distribution, multicollinearity among predictors, homogeneity of variances, independence, potential interactions, multivariate relationships, linearity etc.) were explored in this document, mostly following Bolker (2007), Zuur *et al.* (2010), and Harrell (2015). However, as the response variables were of different nature (e.g. binary, continuous), they would be modelled using different types of models with varying assumptions:

* The *efficiency* and *high_eff* variables shared the same sub-dataset because we decided to analyse them using the same set of candidate *a priori* models. The former variable is a sort of *satisfaction score* estimated by the managers and can modelled as a percentage using **beta regressions** while the latter, which relates to cases of knotweed (near-)eradication, is a binary variable that should be modelled using some type of **logistic regression**.
* The other three response variables indicated the presence of knotweed regrowths at various key locations of the tarping set-ups, and should thus also be modelled using methods of the *logistic regression family*.

Naturally, most actual models assumptions were checked after model building and fitting. Our intention here was simply to improve our knowledge of the data and identify potentially problematic variables upstream. As our global dataset contained many potential predictors (*p* = 85), much effort was indeed directed toward reducing their number and keeping only the most reliable and important ones relative to our hypotheses. In other words, we tried to reduce the dimensionality of the data. 

For the meaning of all variables, the reader is referred to Appendix §§§ *** §§§ !!!!!!
\
\

******
# - References
