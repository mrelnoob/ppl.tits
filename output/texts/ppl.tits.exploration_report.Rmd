---
title: "Exploratory data analyses and preparation report - Tits reproduction study, PubPrivLands project (Martin *et al.*, *in prep.*)"
author: "François-Marie Martin"
date: "`r format(Sys.time(), '%d %B, %Y')`"
bibliography: ppl.tits_biblio.bib
csl: fanf_style.csl
output:
   html_document:
     theme: darkly
     number_sections: yes
     toc: yes
     toc_depth: 5
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
# knitr::opts_knit$set(root.dir = '~/') # This option is ABSOLUTELY REQUIRED if I want this .Rmd report to work well with {target}! It sets the working directory to the root of the project and not to the folder where the .Rmd document is stored (by default, that is what RMarkdown does). So if I don't do that, RMarkdown and knitr won't be able to find de the 'target' objects I'm calling in my functions! Another solution would be to used 'setwd()' for each code chunk where I call for external files. 
```

# - Introduction
## - Regarding reproductibility


In order to facilitate any attempt at reproducing this study, here is a depiction of the system information used to prepare and analyse the data from the PubPrivLands tits reproduction study (Martin *et al.* , *in prep.*).

```{r session information}
rm(list=ls())
sessionInfo()
```

All codes used in this study can furthermore be found here: https://github.com/mrelnoob/ppl.tits
\
\

## - What is this document about?  

```{r data import, include=FALSE}
library(ppl.tits) # To be able to use pipes.
tits_priorimp <- targets::tar_read(pimp_tdata)
tits <- targets::tar_read(final_tdata)
pm_imp_error <- targets::tar_read(imp_ooberror_pm)
cc_imp_error <- targets::tar_read(imp_ooberror_cc)
# As you can see, I import my data using 'targets'! If you are reading this report and don't know what it is or how I created and stored them, you should read the README or the _devhistory.R files available at https://github.com/mrelnoob/ppl.tits. 

.pardefault <- par() # To save the default graphical parameters (in case I want to restore them).
```
\

This document outlines all the important data preparation and exploration steps undertaken to test our research hypotheses. In other words, it presents all **exploratory data analyses** and basic **assumption checks** performed on the *final* version of our dataset. Actually, it also presents the last step of the dataset generation process, that is **missing values imputation** because it is a highly sensitive part of the process and thus deserves the utmost transparency.
For more details regarding the dataset generation process (i.e. creation of the *final* dataset), readers are referred to the scripts and documents stored at: https://github.com/mrelnoob/ppl.tits as well as to the manuscript and other Supplementary Materials.
\
\

******

# - Missing data imputation process

Similarly to many datasets in ecology, some of our variables contained missing values. As most of them were MAR or MCAR (missing [completely] at random) and since deleting observations containing missing values can lead to biased coefficient estimates [@harrell2015], we decided to impute the missing values in some of our response variables as well as in all independent variables containing missing values instead of deleting observations. However, as the proportion of missing values is clearly higher for our Blue Tits (*Cyanistes caeruleus*) observations than for our Great Tits (*Parus major*) data and as the former has a lower sample size, we chose to split our data into two subsets, one for each species, where the Blue Tits one will contain less variables as some will be discarded to prevent overoptimistic imputations. 
For our morphometric response variables on the other hand, missing values were not MAR as many were due to the fact that the reproduction event failed. It was then impossible to measure morphometric variables on dead or missing bird nestlings. These variables were thus excluded from the following imputation process but will perhaps be imputed later if required.

To impute missing values, we used the `missForest()` function from the {missForest} package [@stekhoven2011]. This functions initially imputes all missing data using the mean/mode, then for each variable with missing values, it fits a *Random Forest* on the observed part and then predicts the missing part. This process of training and predicting repeats iteratively until a stopping criterion is met or a maximum number of user-specified iterations is reached. This algorithm has been shown to have higher predictive performances than other widely used imputation methods, including MICE or KNNimpute [@stekhoven2011].
Another advantage is that this function can return an assessment of the imputation error based on the out-of-bag (OOB) samples, for each variable individually. For continuous predictors, the Mean Squared Error (MSE) of imputed values is computed while the proportion of falsely classified (PFC) is used for categorical missing ones.
To avoid overfitting, no hyperparameters tuning was performed but I applied a three-fold increase in the number of trees and maximum iterations with respect to the default values to favour predictive accuracy. 



## - Great Tits dataset
### - Dataset prior to imputation

Here is a summary of the Great Tits dataset prior to data imputation (for the meaning of the variables, readers are referred to table **XXX_A_FAIRE!_XXX**):

```{r pm before imputation, message=FALSE}
tits_priorimp %>% dplyr::filter(species == "PM") -> pm_pimp
summary(pm_pimp)
```

### - Dataset after imputation

Below, you may find a summary table of the OOB error for all imputed variables, expressed in the original variable scales (the blue variable is a future response variable while the green ones are meant to be predictors): 

```{r pm imput error, message=FALSE}
data.frame(Variable = rownames(pm_imp_error), 
           Nb_imputed_values = pm_imp_error$Nb_imputed_values, 
           Oob_RMSE = pm_imp_error$Oob_RMSE) %>%
  dplyr::mutate(Variable = kableExtra::cell_spec(
    Variable, color = "white", background = ifelse(
      Variable == "brood_size", "deepskyblue", "mediumseagreen"))) %>%
  knitr::kable(escape = FALSE) %>% 
  kableExtra::kable_styling(full_width = FALSE)
```

You can see that imputation errors are, in this case, fairly negligible compared to the variable ranges of variation. Consequently, we deemed these imputations acceptable and used them for the subsequent analyses.
Here is a summary of the same data AFTER imputation:
```{r pm after imputation, message=FALSE}
tits %>% dplyr::filter(species == "PM") -> pm
summary(pm)
```



## - Blue Tits dataset
### - Dataset prior to imputation

Here is a summary of the Blue Tits dataset prior to data imputation (for the meaning of the variables, readers are referred to table **XXX_A_FAIRE!_XXX**):

```{r cc before imputation, message=FALSE}
tits_priorimp %>% dplyr::filter(species == "CC") -> cc_pimp
summary(cc_pimp)
```

### - Dataset after imputation

Below, you may find a summary table of the OOB error for all imputed variables, expressed in the original variable scales (the blue variable is a future response variable while the green ones are meant to be predictors): 

```{r cc imput error, message=FALSE}
data.frame(Variable = rownames(cc_imp_error), 
           Nb_imputed_values = cc_imp_error$Nb_imputed_values, 
           Oob_RMSE = cc_imp_error$Oob_RMSE) %>%
  dplyr::mutate(Variable = kableExtra::cell_spec(
    Variable, color = "white", background = ifelse(
      Variable == "brood_size", "deepskyblue", "mediumseagreen"))) %>%
  knitr::kable(escape = FALSE) %>% 
  kableExtra::kable_styling(full_width = FALSE)
```

Here again, you can see that imputation errors are, in this case, fairly negligible compared to the variable ranges of variation. Consequently, we deemed these imputations acceptable and used them for the subsequent analyses.
Here is a summary of the same data AFTER imputation:
```{r cc after imputation, message=FALSE}
tits %>% dplyr::filter(species == "CC") -> cc
summary(cc)
```
\
\

******

# - Data exploration

Various aspects of our data (e.g. outliers, variables distribution, multicollinearity among predictors, homogeneity of variances, independence, potential interactions, multivariate relationships, linearity etc.) were explored and are presented in this document, mostly following Bolker (2007), Zuur *et al.* (2010), and Harrell (2015). However, as the response variables were of different nature (e.g. binary, continuous), they would be modelled using different types of models with varying assumptions:

* The *efficiency* and *high_eff* variables shared the same sub-dataset because we decided to analyse them using the same set of candidate *a priori* models. The former variable is a sort of *satisfaction score* estimated by the managers and can modelled as a percentage using **beta regressions** while the latter, which relates to cases of knotweed (near-)eradication, is a binary variable that should be modelled using some type of **logistic regression**.
* The other three response variables indicated the presence of knotweed regrowths at various key locations of the tarping set-ups, and should thus also be modelled using methods of the *logistic regression family*.

Naturally, most actual models assumptions were checked after model building and fitting. Our intention here was simply to improve our knowledge of the data and identify potentially problematic variables upstream. As our global dataset contained many potential predictors (*p* = 85), much effort was indeed directed toward reducing their number and keeping only the most reliable and important ones relative to our hypotheses. In other words, we tried to reduce the dimensionality of the data. 

For the meaning of all variables, the reader is referred to Appendix §§§ *** §§§ !!!!!!
\
\

******
# - References
